P2P
	Peer-Assisted File Distribution: The Minimum Distribution Time
		Kumar, Rakesh, and Keith W. Ross. "Peer-assisted file distribution: The minimum distribution time." 2006 1st IEEE Workshop on Hot Topics in Web Systems and Technologies. IEEE, 2006.
		
		112 viittausta
		
		Paperi näyttäisi olevan sisällötään suurimmaksi osaksi sama kuin yllä oleva
			-Yllä olevaan artikkeliin lisätty osio "eriarvoisuudesta", jossa tutkitaan suorituskykyä kun vertaiset jaettu kahteen eri prioriteettiryhmään
		
		Abstract
			With the emergence of BitTorrent, Swarm-cast, and CDNs, peer-assisted file distribution has become a prominent Internet application, both in terms of user popularity and 
			traffic volumes. We consider the following fundamental problem for peer-assisted file distribution. 
			-There are seed nodes, each of which has a copy of the file, and leecher nodes, each of which wants a copy the file. 
			-The goal is to distribute the file to all the leechers - with the assistance of the upload capacity of the leechers - in order to minimize the time to get the file to all 
			the leechers (the distribution time). 
			-We obtain explicit expressions for the minimum distribution time of a general heterogeneous peer-assisted file distribution system. 
			-Derived with fluid-flow arguments, the expressions are in terms of the file size, the seeds' upload rates and the leechers' upload and download rates. 
			-We demonstrate the utility of the result by comparing the optimal distribution time with the measured distribution time when BitTorrent is used to distribute a file from a 
			seed to ten leechers
			
		Introduction
			-Clearly, peer-assisted file distribution has become an important application paradigm in the Internet.
			-But, quantitatively, just how good is it at distributing afile?
				-Can it be significantly better than client/serverdistribu-tion?
				-How well can it scale as the number of receiving nodes becomes very large?
				-How does the interaction of server upload bandwidth, receiving node upload bandwidth, and receiving node download bandwidth impact the overall distribution time?
				
			-In this paper, we address fundamental questions like these lying at the core of peer-assisted file distribution.
			
	Peer-to-Peer Systems
		Rodrigues, Rodrigo, and Peter Druschel. "Peer-to-peer systems." Communications of the ACM 53.10 (2010): 72-82.
		
		Communications of the ACM
			H-index: 189
			JUFO-taso: 3
		
		189 viittausta
		
		Artikkelin pointit
			-Määrittelee P2P seuraavat ominaisuudet
				-Suuren tason hajautus
				-Itse-organisaatio
				-Multiple administrative domains
				
			-P2P mielenkiintoisia ominaisuuksia
				-Pieni käyttöönottokynnys
					-Ei tarvitse infrastruktuurihankintoja
					
				-Orgaaninen kasvu
					-P2P-järjestelmä voi kasvaa mielivaltaisesti, sillä uudet vertaiset tuovat lisää resursseja
					-Ei tarvitse uusia infrastruktuurihankintoja skaalautumiseen
					
				-Vastustuskyky hyökkäyksiin (ja flash crowdeihin)
					-Jaettu usean käyttäjän kesken, yhden vertaisen kaataminen ei kaada koko verkkoa
					
				
			-P2P-käyttötarkoitukset
				-Tiedostojen jako
				-Internet-puhelin
				-Stramaus
				-Vapaaehtoislaskenta
				
			-P2P ja ISP
				-P2P syy käyttäjille ostaa parempia yhteyksiä
				-Internetmaksut usein kiinteitä
					-Alkuperä: ennen client-server malli dominoivampi
						-Palvelimien ylläpittäjät maksoivat ISPille käytetun kaistan mukaan
						-Keskivertokäyttäjä ei ylläpidä palvelinta joita muut käyttävät sisällön lataamiseen
							-Otaksuttiin että upstream liikennettä ei syntyisi paljon, joten voidaan tarjota kiinteitä hintoja
				
				-P2P käyttäjät rupesivat uploadaamaan sisältöä muille
					-Usein uploadattava data menee ISPn verkon ulkopuolelle, mistä aiheutuu näille maksuja joita se ei voinut siirtää käyttäjille maksettavaksi
					
				-Täten ISPt rupesivat estämään/katottamaan P2P-liikennettä
				-ISP näkee P2P myös kilpailijana
					-ISPt tarjoavat puhelin liittymiä; P2P puhelinpalvelut kuten skype
						-IPTV ja P2P IPTV

P2P tunnistus/esto
	Accurate, scalable in-network identification of p2p traffic using application signatures
		Sen, Subhabrata, Oliver Spatscheck, and Dongmei Wang. "Accurate, scalable in-network identification of p2p traffic using application signatures." Proceedings of the 13th international conference on World Wide Web. 2004.
		
		1144 viittausta
		
		A widely used ISP approach is to use traffic shaping devices to
		rate limit P2P (e.g., [6, 7, 19, 20, 28, 33]). These devices rely on
		deep packet inspection or other P2P traffic identification schemes
		(e.g., [11, 31]) (P4P: Provider Portal for Applications)
		
		Artikkelin pointit
			-Artikkeli tehty sen jälkeen kun P2P sovellukset ruveneet implementoimaan piilotusmekanismeja
			-P2P halutaan rajoittaa jotta ne eivät aiheuttaisi liikaa ulkoliikennettä ja takaamaan reiluus muille sovelluksille
				-Tätä varten täytyy pystyä tunnistamaan P2P-paketit
				
			-Aikaisemmin P2P-sovelluksia havaittiin niiden käyttämien porttien avulla
				-Sittemin nämä sovellukset rupesivat käyttämään satunnaisia portteja laajalta väliltä (muotoile ehkä vähän toisin)
				
			-Vaatimukset liikenteen tunnistamiselle
				-Tarkkuus
					-Pieni määrä false positiveja (jotta ei haittaa muita sovelluksia)
					-Pieni määrä false negativeja (jotta P2P-liikennettä ei pääse livahtamaan ohi)
					
				-Skaalautuvuus
					-Tunnistustekniikan tulee pystyä käsittelemään erittäin suuria liikennemääriä (luokkaa sadat tuhannet ja miljoona eri yhteyttä)
						-Tarkkuus ei saa kärsiä
						-Tulee olla riittävän halpa
						
				-Robustness
					-Trafc measurement in the middle of the network has
					to deal with the effects of asymmetric routing (2 directions
					of a connection follow different paths), packet losses and reordering.
					
				-Näiden välillä on tradeoffeja
		
			-Porttinumeroiden pohjalta tehty tunnistus oli hyvä keino
				-Oli hyvin skaalautuva kun tarvitsi tarkastaa pelkät porttinumerot, ja P2P-sovelluksen tunnistamiseen riitti yhdenkin paketin havaitseminen
					-Ei enää toimi kun käytetään satunnaisia portteja
		
			-Paperin havaitsemiskeinot
				-Yritetään havaita P2P-liikenne eri soveluksille/protokollille tyypillisten TCP/UDP-käytäntöjen avulla
					-Esim. BitTorrent-pakettien TCP-sisällön (payload) ensimmäinen tavu sisältää luvun 19, ja sitä seuraavat 19 tavua sisältävät merkkijonon 'BitTorrent protocol'
						-Huom, merkkijono 19 merkin pituinen
						
					-Huom tää vissiin ennen kuin ruvettu salaamaan P2P?
					
	Identification and Analysis of Peer-to-Peer Traffic
		Perényi, Marcell, et al. "Identification and analysis of peer-to-peer traffic." Journal of Communications 1.7 (2006): 36-46.
		
		87 viittausta
	
		-Artikkelin pointit	
			-ISPt estävät P2P myös sen takia koska niillä usein levitetään tekijänoikeuksia rikkovaa materiaalia
			-Vastauksena ongelmiin ISPt estivät/rajoittivat P2P-liikennettä
				-P2P-sovellukset rupesivat käyttämään satunnaisia portteja (tässä vaiheessa ei vissiin vielä salausta?)
				
			-Pakettien kaappaaminen ja suora tarkastelu voi olla laillisesti/yksityisyydensuojan puolesta kyseenalaista
				-Dunno laillisuudesta, mutta yksityisyydensuoja ihan relevanttia
				
			-P2P havaitsemisella kaksi lupaavaa tapaa
				-P2P traffic identification based on payload information
					+Tarkempi
					-high processor claim (for payload check)
					-Riippuvainen tarkasta toteutuksesta, P2P-sovellusten jatkuva muutos (etenkin salauksen jälkeen)
					-Laillisuuteen ja yksityisyyteen liittyvät ongelmat
					
				-P2P traffic identification based on flow dynamics
					+Yksinkertaisempi toteuttaa
					+Ei ole riippuvainen P2P-protokollien tarkoista toteutuksista
					-Heuristisista metodeista johtuen vähemmän tarkka
					
			-Heuristiikassa käytetyt menetelmät
				-P2P protokollat käyttävät sekä UDP että TCP
					-UDP viestintään vertaisille ja trackkereille
					-TCPllä varsinainen tiedonsiirto
					-Eli kahden IP:n välillä tapahtuva molempia protokollia käyttävä rinnakkainen (eli molempia samaan aikaan) tiedonsiirto on melko varmasti P2P
					
				-On myös muita, mutta en kirjoita tarkemmin
				
	Transport Layer Identification of P2P Traffic
		Karagiannis, Thomas, et al. "Transport layer identification of P2P traffic." Proceedings of the 4th ACM SIGCOMM conference on Internet measurement. 2004.
		
		1066 viittausta
		
		Abstract
			Since the emergence of peer-to-peer (P2P) networking in the
			late ’90s, P2P applications have multiplied, evolved and es-
			tablished themselves as the leading ‘growth app’ of Internet
			traffic workload.  In contrast to first-generation P2P net-
			works which used well-defined port numbers, current P2P
			applications have the ability to disguise their existence through
			the use of arbitrary ports. As a result, reliable estimates of
			P2P traffic require examination of packet payload, a method-
			ological landmine from legal, privacy, technical, logistic, and
			fiscal perspectives. Indeed, access to user payload is often
			rendered impossible by one of these factors, inhibiting trust-
			worthy estimation of P2P traffic growth and dynamics. In
			this paper, we develop a systematic methodology to identify
			P2P flows at the transport layer, i.e., based on connection
			patterns of P2P networks, and without relying on packet
			payload. We believe our approach is the first method for
			characterizing P2P traffic using only knowledge of network
			dynamics rather than any user payload.  To evaluate our
			methodology, we also develop a payload technique for P2P
			traffic identification, by reverse engineering and analyzing
			the nine most popular P2P protocols, and demonstrate its
			efficacy with the discovery of P2P protocols in our traces
			that were previously unknown to us.  Finally, our results
			indicate that P2P traffic continues to grow unabatedly, con-
			trary to reports in the popular media
			
		Artikkelin pointit
			-In contrast to first-generation P2P networks
			which used well-defined port numbers, current P2P
			applications have the ability to disguise their existence through
			the use of arbitrary ports. As a result, reliable estimates of
			P2P traffic require examination of packet payload, a methodological
			landmine from legal, privacy, technical, logistic, and
			fiscal perspectives.
			
			-Pakettien sisällön tarkastelu ongelmallista
				-Laillisesti kyseenalaista
				-Rikkoo yksityisyydensuojaa
				-Vaativampi toteuttaa
				-Monet P2P-protollat huonosti dokumentoituja
					-Vaikea reverse engineerata
					-Päivittyivät siihen aikaan (2000-luvulla) semi usein, joten pakettientarkastelumenetelmiä piti myös tiheästi päivittää			
				
				-Kappaleessa 4 lueteltut haasteet
					-Monet P2P-sovellukset käyttävät HTTP tiedostonsiirrossa, jolloin niitä ei voida erottaa websivujen paketeista mikäli tarkastelu on pinnallisempaa (nopeuden vuoksi)
					-Jos P2P salaa paketit niin ei voi suoraan katsella
					
			-Paperissa tunnistetaan P2P-paketteja kuljetustasolla
				-P2P-liiketeen profilointia identifioimalla flow patterneja ja P2P-liikenteelle tyypillistä käyttäytymistä
				-Pystyy tunnistamaan P2P-paketteja tietämättä niiden protokollien tarkempaa toteutusta
					-Pystyy täten huomaan myös päivitysten jälkeen
			
				-Kahdella heuristiikalla
					-Kaksi IP-paria käyttävät sekä UDP että TCP keskenään
						-Huom. ei päde kaikille p2p protokollille
						-Huom. myös jotkin sovellustason sovellukset kuten DNS ja multimedia streamaus tekee näin
							-Nämä muut sovellukset kuitenkin käyttävät vakioportteja, joten niiden perusteella voidaan karsia pois muut sovellukset
						
					-The second is based on how P2P peers connect to each other by studying connection characteristics of fIP, portg pairs
						-In summary,
						web traffic will have a higher ratio than P2P traffic of
						the number of distinct ports versus number of distinct IPs
						connected to the fIP, portg pair fW,80g.
			
			
	
Ongelmat
	Can ISPs Take the Heat from Overlay Networks? 2004
		Keralapura, Ram, et al. "Can ISPs take the heat from overlay networks." ACM SIGCOMM Workshop on Hot Topics in Networks (HotNets). 2004.
		
		126 viittausta
		
		Abstract
			-ISPs manage performance of their networks in the presence of failures or congestion by employing common traffic engineering techniques such as link weight set-tings, 
			load balancing and routing policies. 
			-Overlay net-works attempt to take control over routing in the hopethat they might achieve better performance for suchfailures or high load episodes. 
			-In this paper, we examinesome of the interaction dynamics between the two layersof control from an ISP’s view. 
			-With the help of simpleexamples, we illustrate how an uncoordinated effort ofthe two layers to recover from failures may cause per-formance degradation for both overlay 
			and non-overlaytraffic.  
			-We also show how current traffic engineeringtechniques are inadequate to deal with emerging over-lay network services.
			
		Introduction
			-Can overlay networks and underlying IP networks form a synergistic co-existence?
			-Using simple illustrations, we identify numerous is-sues that result in potentially harmful interactions andmake the case for future research in this direction
			-Note that this paper is not about performance issue smeasured by the classic metrics such as loss, delay orthroughput. Instead we are interested in understanding how the 
			network management techniques currently de-ployed by ISPs are impacted by overlay networks
			
		Discussions
			-We have identified five problematic interactions that can occur between IP networks and overlay networks:
			-(i) traffic matrices become more dynamic and more am-biguous, making them harder to estimate; 
			-(ii) sometypes of load balancing policies can be bypassed; 
			-(iii)multiple overlays can get synchronized, which in turnleads to traffic oscillations that can last for varyingamounts of time; 
			-(iv) oscillations can impact non-overlaytraffic; and 
			-(v) different ASes can get coupled due toper-domain events		
			
			
		-Artikkelin pointit
			-ISPt tekevät oletuksia verkkoliikenteestä, hoitavat reitityksen
				-Jos päällysverkot mielivaltaisesti reitittvät voivat hankaloittaa ISPn omaa reititystä
				
			-Ongelmallista jos kahdella eri tasolla tehdään reititystä (sovellus = Päällysverkot, verkko = palveluntarjoajat), kun molemmat eivät ole tietoisia toisistaan
				Voivat luoda traffic oscillaatioita
				
				If overlay networks react to events in the IP
				network (e.g., failures or congestion) independently of
				an ISP, race conditions could occur and lead to traf-
				¯c oscillations. Such tra±c oscillations not only a®ect
				the overlay tra±c but also impact the background (non-
				overlay) tra±c in the network. We also show that such
				reactions by overlay networks that span multiple do-
				mains could threaten the e®ectiveness of BGP in isolat-
				ing di®erent domains in the Internet
				
			-ISPt tekevät kaksi oletusta (jotka eivät päde päällysverkkoihin) tehdessään traffic engineeringiä
				-(i) liikennevaatimukset eivät vaihtele suuresti lyhyillä aikaväleillä
				-(ii) Muutokset reiteissä (path) domainin sisällä eivät vaikuta liikennevaatimuksiin

			-Haasteet traffic engineeringille
				-3.1 Traffic Matrixin estimointi
					-Liikennematriisi pitää sisällään tiedon verkkoliikenteen määrästä jokaisen kahden solmun välillä
					-Kaksi eri ongelmaa
						-Duplikaatio
							-Päällysverkoissa pakettien lopullinen päämäärä usein salataan, ja ne määrittävät päämääräkseen reitin välisolmut
								-Jos päällysverkkoliikenne kiertää yhden tai useamman solmun kautta lyhyemmän viiveen yms. takia
									-ISP ei tiedä lopullista päämäärä, joten päällysverkon reititys vääristää matriisia jakamalla liikenteen usean solmuparin välille, ja alkuperäisen 
									lähde- ja maalisolmuparin väliseen liikenteeseen ei tapahdu muutoksia vaikka näin pitäisit
								
								-Verkkoliikennettä joudutaan täten tiuhasti uudelleenestimoimaan ylläpitääkseen matriisin oikeellisuutta
								
						-Shift
							-Päällysverkot voivat määrittää eri ulostulopisteen verkolle kuin palveluntarjoajat
								-Aiheuttaa myös muutoksia matriisiin		
					
					-There are many °ows whose ultimate destination lies
					outside the ISPs' domain; the tra±c from these °ows
					traverses the ISP and thus appears inside the TM. The
					tra±c matrix will specify an exit router within the ISP's
					domain for such °ows. If this tra±c belongs to an
					overlay network that spans multiple domains, and uses
					its own path selection mechanism, then the exit point
					within a single ISP domain could change, resulting in a
					shift in TM entry.
					
				-3.2 Kuorman tasaus (load balancing)
					-ISP voi priorisoida kahden solmun välisen reitin näiden käytettäväksi
						-Ohjaa muiden liikenteen kulkemaan muiden solmujen kautta
						-Päällysverkot eivät välitä ISPn kuormantasauksesta ja reitittävät liikenteen kulkemaan näiden kahden solmun kautta
							-ISP saa vääristyneen kuvan solmujen välillä kulkevasta omasta liikenteestä
					
			-Race conditions in multiple overlay networks
				-Jos alusverkolla on useampi päällysverkko, niin performanssin heikkeneminen laukaisee niissä kaikissa reitityksen muutoksia
					-Two or more overlays reacting at moments that are
					close in time can result in race conditions. Having rout-
					ing control in two layers in the network is equivalent to
					having two closed loop systems reacting simultaneously
					yet independently to the same set of events. This is a
					classic situation for race conditions that lead to tra±c
					oscillations.
					
					-esim. päällysverkot huomaavat reitin sammuneen samaanaikaan ja päätyvät samaan reititysratkaisuun niin nopeasti että eivät kerkeä havaitsemaan toistensa ratkaisujen 
					vaikutusta
						-johtaa tilanteeseen jossa uusi reitti kärsii molempien päällysverkkojen liikenteestä
						-Verkot huomaavat taas tämän tilanteet ja muuttavat samanaikaisesti liikenteensä kulkemaan toisen saman reitin kautta
							-Syntyy oskillatiota (=toistuva tilanne?) kunnes toinen päällysverkoista on nopeampi, rikkoen deadlocking
								-Deadlockin rikkoutuminen = disentangling
							
						-Verkot siis synkronoituvat
						
					-Oskillaatio vaikuttaa selvästi myös muuhun liikenteeseen, ei pelkästään päällysverkkojen liikenteeseen
						-Koska päällysverkot ruuhkauttavat reittejä
					
				-Oskillaatioita laukaisevia tekijöitä
					-Link or node failure
					-IGP convergence
					-Congestion (high loads)
					
				-Oskillaation lopettavat tekijät
					-Self-disentangling
					-Failure restoration
					
				-Monien eri laukasevien ja lopettavien tekijöiden kombinaatio mahdollistaa monenlaisia oskillaatioskenaarioita ja niille eri pituuksia
				
			-Coupling of multiple domains
				-1) Kun päällysverkko ylttää useamman ISPn domainin päälle, aiheuttaa yhden domainin tilanne muiden domainien tilanteeseen
				-2) Yksi BGPn tavoitteesta on decouplaa eri domaineja jotta yhden domainin tapahtumat eivät vaikuttaisi toiseen
					-Päällysverkot haittaavat tätä tavoitetta kun ne päällystävät useampaa domainia
						-Tällöin tapahtuma yhdessä domainissa aiheuttaa vaikutuksia muissa
						
			-Loppupohdinnat
				-ISPiden on tärkeää ottaa huomioon päällysverkot jotta voisivat antaa parempaa palvelua kaikille
					-Tutkimuksen skenaariot osoittavat että mikäli näin ei tehdä, mainitut ongelmat laajenevat päällysverkkojen yleistyessä
				
				-ISP voisivat miettiä miten kannustaa päällysverkkoja välttämään ongelmallista reitityskäytöstä
					-Myös tärkeää että päällysverkot tiedostavat aiheuttamansa ongelmat ja pyrkivät myös itse välttämään niitä
			
				
				
		-Artikkeli ei käsittele ongelmia suoraan performanssin näkökulmasta, vaan miten päällysverkot vaikuttavat ISPiden verkonhallintatekniikoihin
			
		-Oletus, että ISPt eivät ottaisi P2P liikennettä mitenkään erityisesti huomioon (ei vissiin päde enään, mutta teoreettinen lähtökohta jota voisi tarkastella)
		-Huom! On workshop (mutta semisti viittauksia)
		
		For instance, Keralapura et al. [9]
		show that P2P systems could have an adverse impact on
		the stability of traffic engineering techniques currently used
		by ISPs in the absence of cooperation. (Pitfalls for ISP-Friendly P2P Design)
	
Paikallisuus
	Should internet service providers fear peer-assisted content distribution? 2005
		Karagiannis, Thomas, Pablo Rodriguez, and Konstantina Papagiannaki. "Should internet service providers fear peer-assisted content distribution?." Proceedings of the 5th ACM 
		SIGCOMM conference on Internet Measurement. 2005.

		477 viittausta
		
		Abstract
			-In this work, we explore the potential impact of future P2P file delivery mechnanisms as seen from three perspectives
				-i) The content providers
				-ii) the ISPs
				-iii) Individual content consumers
						
			-We quantify the impact of peer-assisted file delivery on end-user experience and resource consumption
				-We further compare it with the performance expected from traditional distribution mechanisms based on large server farms and Content Distribution Networks (CDN)
				
			-While existing P2P content distribution solutions may provide significant benefits for content providers and end-consumers in terms of cost and performance, our results 
			demonstrate that they have an adverse impact on ISPs’costs by shifting the associated capacity requirements from the content providers and CDNs to the ISPs themselves.
				-Further, we highlight how simple “locality-aware” P2P de-livery solutions can significantly alleviate the induced costat the ISPs, while providing an overall performance that 
				ap-proximates that of a perfect world-wide caching infrastruc-ture.
				
		Introduction
			-The highlights of our work can be summarized in thefollowing points:
				•We provide a detailed study that sheds light on andquantifies the impact of peer-assisted content distrib-ution solutions on ISPs based on real Internet traces.
				•We present evidence that establish the potential forlocality-aware “peer-assisted” solutions. 
					-We estimateand quantify file-availability and user-overlap in timewhere such solutions are feasible.
				
				•We describe easily deployable architectures for effi-cient peer-assisted content distribution. 
					-For each case,we quantify the benefits and highlight potential sav-ings.

		Related works:
			-Analyysejä p2p-järjestelmistä kuten BitTorrent, Gnutella, KaZaA
			
			J. Chu, K. Labonte, , and B. Levine. Availability and locality mea-surements of peer-to-peer file systems. InITCom: Scalability andTraffic Control in IP Networks, 2002

			C. Gkantsidis and P. Rodriguez. Network Coding for Large ScaleContent Distribution. InIEEE/INFOCOM, 2005
			
		Conclusion
			-Based on payload packet traces as well as tracker-basedlogs, we have studied the impact that local-aware peer-assisted content distribution solutions can have on ISPs, 
			content providers,  and end-users.   
				-In particular, wehave identified that current P2P solutions are very ISP-unfriendly, generating large amount of unnecessary trafficboth downstream as well as upstream.
			
			-We studied locality in the context of BitTorrent.  
				-Ourtraces indicate that BitTorrent is locality-unaware, severelyincreasing ISPs’ bandwidth requirements. 
				In particular, upto 70-90% ofexisting localcontent was found to be down-loaded from external peers

			-Peer-assisted content distribution incurs significant up-stream capacity costs for the transit links (roughly dou-bling the bandwidth requirements). 
				-However, simple local-ity based mechanisms can rectify this effect, approximatingthe performance of a perfect caching architecture. 
				-Overall,locality-aware peer-assisted algorithms decrease the band-width of the content provider’s egress link by more than afactor of two. 
				-Strategies such as those used by BitTorrenttrying to match users with similar capacities provide littlelocality benefits.
				
			-The benefits of a peer-assisted locality solution increasewith the logarithm of the number of active users. 
				-Our find-ings show that as soon as there are more than 30 activeusers within an ISP, a peer-assisted locality solution pro-vides more than 60% savings in terms of ISP’s 
				ingress traf-fic compared to a client/server distribution.
				
			-On the contrary, a peer-assisted locality-aware solutiongenerates five times more traffic on average through theISP’s link than a perfect caching solution.  
				-However, inabsolute terms this represents only a small fraction of thetraffic generated by a client/server solution
				
			-The benefits of a peer-assisted solution are always muchmore pronounced in terms of95thpercentile, thus, absorb-ing peak loads and reducing the monetary impact on ISPsand 
			content providers. 
				-Simple locality-aware mechanismsbased on domain-name grouping, or prefix grouping pro-vide roughly 50% of the potential benefits.
				
			-Our study shows that while current peer-assisted contentdistribution solutions are ISP-unfriendly, this is not a fun-damental limitation and that minor modifications can 
			in-deed significantly reduce the costs of all parties involvedin the content distribution process. 
				-Such simple modifica-tions to peer-assisted protocols can provide a cost-effectivesolution that can be exploited by content providers to scaleand accelerate the delivery 
				of content to millions of userswithout pushing ISPs towards regulating or blocking suchtraffic.
				
				
		Artikkelin pointit
			-Tutkimusmenetelmät
				-1. tutkimus: tarkastellaan 20k käyttäjän yliopistoverkon pääsylinkkiä kolmena eri päivänä
				-2. tutkimus: tarkastellaan yksittäisen bittorrentilla jaettavan tiedoston seurantalokia viiden kuukauden ajan
				
			-1. tutkimuksen tulokset
				-Huom! Skaala on aika pieni, lukumäärältään käyttäjiä tiedostoja yms. on aika vähän (n. ~10 luokkaa)
					-Lisäksi osa tuloksista (ainakin 1. tutkimuksen) on laskelmoitu eikä testauksen tulosta
					
				-Tiedostoja ladataan keskimäärin vain lyhyen aikaan
					-Potentiaalinen välimuistiratkaisu ei siis veisi välttämättä kovinkaan paljoa tilaa
					
				-70-90% ladatusta datasta (pieces) jo verkon sisäpuolella olevasta sisällöstä ladataan turhaan uudelleen ulkopuolelta
					-Luku on 50-90% jos otetaan huomioon vain aktiiviset käyttäjät
					-Jos puhutaan kokonaisista tiedostoista niin määrä on n. 1/10 kaikista ladatuista tiedostoista (per päivä)
					-Kun puhutaan tavuista luvut ovat 20% (paikallisten aktiivisten käyttäjien keskuudesta) ja 40% (kaikkien paikallisten käyttäjien keskuudesta)
					
				-Noin 30% ajasta tiedostoille löytyisi verkon sisältä aktiivisia vertaisia
					
				-70% käyttäjistä hyötyisi paikallisuudesta nopeammilla latausajoilla
				
			-2. tutkimusken tulokset
				-Vertaisverkkojen käyttö puolittaa ISPn downlink kaistaa
				-Lokaali vertaisvalinta vaatisi vain 1.5 kertaisen määrän peak kapaisteettia verrattuna välimuistiratkaisuun
				-Lokaalissa vertaisvalinnassa ISPt joutuisivat keskimäärin lähettämään hieman yli yhden täysinäisen kopion kokonaisesta tiedostosta verkon ulkopuolelle
				-ISPn säästöt lokaalissa vertaisvalinnassa kasvavat aktiivisten käyttäjien logaritmin mukaan
				-Lokaalin vertaisvallinan aiheuttama overhead on minimaalinen ja saattaa joissain tapauksissa olla jopa pienempi kuin välimuistiratkaisussa
		
		
	Can ISPs and P2P users cooperate for improved performance?
		Aggarwal, Vinay, Anja Feldmann, and Christian Scheideler. "Can ISPs and P2P users cooperate for improved performance?." ACM SIGCOMM Computer Communication Review 37.3 (2007): 29-40.
		
		562 viittausta
		
		Abstract
			-Peer-to-peer  (P2P) systems,  which are  realized  as overlayson top of theunderlying Internet routing architecture, contribute a significant portion oftoday’s Internet 
			traffic.  
			-While the P2P users are a good source of revenuefor the Internet Service Providers (ISPs), the immense P2P traffic also posesa significant traffic engineering challenge 
			to the ISPs.  
				-Thisis because P2Psystems either implement their own routing in the overlay topology or mayuse a P2P routing underlay [1], both of which are largely independent  
				ofthe Internet routing, and thus impedes the ISP’s traffic engineering capabil-ities.  
				
			-On the other hand, P2P users are primarily interestedin finding theirdesired content quickly, with good performance. 
			-But as the P2P system hasno access to the underlying network, it either has to measurethe path per-formance itself or build its overlay topology agnostic of the underlay.  
			Thissituation is disadvantageous for both the ISPs and the P2P users.
			-To overcome this, we propose and evaluate the feasibility ofa solutionwhere  the  ISP  offers  an  “oracle”  to  the  P2P  users.   
				-When  the  P2Pusersupplies the oracle with a list of possible P2P neighbors, the oracle ranksthem according to certain criteria, like their proximity tothe user or 
				higherbandwidth links.  
				-This can be used by the P2P user to choose appropriateneighbors,  and  therefore  improve  its  performance.   
				-The ISP  can  use thismechanism to better manage the immense P2P traffic, e.g., to keep it insideits  network,  or to  direct  it  along  a  desired  path.   
				-The  improved  networkutilization will also enable the ISP to provide better service to its customers
				
		Introduction
			-However, the wide-spread use of such P2P systems has put ISPsin a dilemma!  
				-On the one hand, P2P system applications have re-sulted in an increase in revenue for ISPs, as they are one of the ma-jor reasons cited by Internet users for 
				upgrading their Internet ac-cess to broadband [6]. 
				-On the other hand, ISPs find that P2P trafficposes a significant traffic engineering challenge [4, 7]. 
					-P2Ptrafficoften starves other applications like Web traffic of bandwidth [8],and swamps the ISP network.  
						-This is because most P2P systemsrely on application layer routing based on an overlay topology ontop of the Internet, which is largely independent of the 
						Internet rout-ing and topology [9]
						-To  construct  an  overlay  topology,  unstructured  P2P  networksusually employ an arbitrary neighbor selection procedure [5]. 
							-Thiscan  result  in  a  situation  where  a  node  in  Frankfurt  downloadsalarge content file from a node in Sydney, while the same informa-tion may be 
							available at a node in Berlin
							
			-We, in this paper, propose and evaluate the feasibility of a sim-pler solution where ISPs help P2P systems by offering anoracleservice.   
				-The oracle acts like an abstract  routing  underlay  to theoverlay network but as it is a service offered by the ISP it hasdi-rect access to the relevant information 
				and does not have to inferor measure it. 
				-For example, an ISP knows whether a customer hasa DSL broadband or a modem connection, its link delay, etc.  
				-Thebenefit  to the ISP is twofold:  first,  it can now influence the P2Prouting decisions via the oracle and so regain its ability toperformtraffic engineering  
				(control  the  traffic flow)  and  second,  theP2Pmeasurement traffic to infer network distances is omitted. 
				-The P2Pusers benefit as explained below
				
		Artikkelin pointit
			-Oraakkeli
				-ISP tarjoama palvelu kaikille kaikille päällysverkkosovelluksille, paperissa testataan Gnutellan avulla
				-Suora pääsy verkon ominaisuuksien tietoihin
				-Oraakkeli vastaanottaa (kaappaa?) käyttäjien vertaislistan, ja asettaa ne paremmuusjärjestykseen
					-ISP voi pitää liikenteen verkon sisällä ja myös ehdottaa vertaisia jotka sijaitsevat ispillä joiden kanssa vertaissopimus
					-Lisäksi voi määrittää sellaisia vertaisia jotka kulkevat halutun pääsylinkin kautta
					
			-Oraakkeli avoin kaikille päällysverkkosovelluksille
				-Koska käy yleisesti kaikille, ei tarvita jokaiselle sovellukselle omaa oraakkelia
				-Koska ei kytköksissä pelkästään tiedostonjakeluun, pitäisi vähentää tekijänoikeusongelmia
					-Voisi lisäksi anonymisoida kyselyt oraakkelille varmuuden vuoksi
					
			-Ei lähetä riskialtista tietoa, jota pahantahtoiset tekijät voisivat käyttä hyväkseen
				
				
			-Tutkimukset ja tulokset
				-3. Simuloidaan oraakkelin vaikutusta yksinkertaistettuun geneeriseen päällysverkkosvellukseen oikeihin Internetin topologiatietoihin perustuvilla graafisimulaatiolla
					-Päällysverkko säilyttää eheytensä
					-Paikallisuus kasvoi merkittävästi päällysverkossa
				
				-4. Simuloidaan SSFNetillä oraakkelin vaikutusta oikeaan P2P-sovellukseen, tässä tapauksessa Gnutellaan.
					-Päällysverkon eheys säilyy
					-Gnutella normaalisti valitsee vertaiset satunnaisesti, joten siitä muodostuva verkko on hyvin sekava
						-Oraakkelin avulla verkko on selkeä ja koostuu paikallisista rypäistä
							-Paikallisuus siis kasvaa
							
					-Keskimääräinen AS etäisyys vähenee vertaisten välillä
						-Pysyy 1. tienoilla, alle 1 jos on 1000 vertaisen lista käytettävissä
						
					-Vähentää gnutellan aiheuttaman overheadin määrää (queryt, pingit yms.)
					
				-5 Testataan gnutellaa ja oraakkelia pienessä hallitussa testiympäristössä
					-45 gnutellasolmua 15 eri koneellas
					-Overhead vähenee, ja overheadviestit pysyvät pääasiallisesti verkkojen sisällä
		
		References
			[5]  R. Steinmetz and K. Wehrle,P2P Systems and Applications, SpringerLecture Notes in CS, 2005 (kirja)
			[7]  R. Keralapura, N. Taft, C. Chuah, and G. Iannaccone, “Can ISPs Take the Heat from Overlay Networks?,” inHotNets, 2004
				-Overlay network = computer network that is layered on top of another network
					-Nodes in the overlay network can be thought of as being connected by virtual or logical links, each of which corresponds to a path, perhaps through many physical 
					links, in the underlying network. 
					-For example, distributed systems such as peer-to-peer networks and client-server applications are overlay networks because their nodes run on top of the 
					Internet
					https://en.wikipedia.org/wiki/Overlay_network
					
			[8]  G. Shen, Y. Wang, Y. Xiong, B. Zhao, and Z. Zhang, “HPTP:Relieving the Tension between ISPs and P2P,” inIPTPS, 2007.
		
	P4P: Provider portal for applications 2008
		Xie, Haiyong, et al. "P4P: Provider portal for applications." ACM SIGCOMM Computer Communication Review 38.4 (2008): 351-362
		
		894 viittausta
		
		The P4P [10] research project has developed a framework
		which ISPs can use to convey network information to P2P
		applications [10] [11]. The framework of the P4P project
		is based on two main architectural entities: the itracker
		and the p-distance. P4P envisions each network provider
		to operate a so-called itracker. This itracker serves as the
		portal to be used by P2P applications within this network
		provider’s network to acquire network layer information.
		Such an itracker can either communicate with the P2P-client
		directly or indirectly via a P2P-application tracker. At the
		heart of the P4P framework lies the notion of the p-distance.
		An itracker can be queried by P2P applications about
		the p-distance between peers. This p-distance is computed
		by the network provider (e.g., based on routing policies,
		topology information, inter-ISP cost agreements, etc.). For
		instance, an ISP could compute p-distances in such a way
		that connections with higher financial costs for the ISP
		result in a higher p-distance. (Traffic Localization for P2P-Applications: The ALTO Approach)
		
		Abstract
			-As peer-to-peer (P2P) emerges as a major paradigm for scalable network application design, it also exposes significant new challenges in achieving efficient and fair 
			utilization of Internet network resources. 
			-Being largely network-oblivious, many P2P applications may lead to inefficient network resource usage and/or low application performance. 
			-In this paper, we propose a simple architecture called P4P to allow for more effective cooperative traffic control between applications and network providers. 
			-We conducted extensive simulations and real-life experiments on the Internet to demonstrate the feasibility and effectiveness of P4P. 
			-Our experiments demonstrated that P4P either improves or maintains the same level of application performance of native P2P applications, while, at the same time, it 
			substantially reduces network provider cost compared with either native or latency-based localized P2P 

		Introduction
			-This paper focuses on the Internet traffic control problem – how network applications (i.e., network resource consumers) efficientlyand fairly utilize the network resources 
			owned by network providers.
			-In the current Internet, traffic control is largely the responsibil-ity of only the network providers (i.e.,  Internet service providersor ISPs).
				-Applications specify only the destinations of traffic
				
			-The emerging P2P applications, however, expose significant new challenges to Internet traffic control
				-Given that a P2P client interested in a piece of data can download it from a number of loca-tions, there is much flexibility in choosing the data sources. 
					-Thisflexibility is one of the key factors contributing to the robustnessand scalability of the P2P paradigm. 
						
				-However, this flexibility also fundamentally changes the network traffic control problem:  
					-in thetraditional setting, the traffic control problem is typically solved inthe context of a given traffic demand pattern
					-in the new setting,there are multiple ways of satisfying the data demands of an ap-plication, each resulting in a different demand pattern and therebynetwork 
					efficiency
					
				-Being largely network-oblivious, many P2P ap-plications may lead to substantial network inefficiency
				
		Conclusion
			-We presented P4P, a simple andflexible framework to enable ex-plicit cooperation between P2P and network providers. 
			-Our evalu-ations demonstrate that it can be a promising approach to improveboth application  performance  and  provider  efficiency.   
			-There  aremany avenues for further study.  
			-In particular, we are conductingmore experiments on interdomain traffic control. 
			-Improving scala-bility using virtual coordinate embedding and evaluating the effectsof caching are topics under study.  
			-Our overall objective is to inte-grate fairness, congestion management, and efficiency control
			
			
		Artikkelin pointit
			-P4P-arkkitehtuuri (Provider Portal for aPPlications)
				-Rajapinta verkolle jotta voi kommunikoida sovellusten kanssa
				-Keskuksena p4p-distance rajapinta
					-through which a network provider can communicate to applications the current “application costs” on its intradomain and interdomain links
					-Sovellukset voivat paikallistaa reittejänsä mikäli se on optimaalista
					-ISPt saavat vastaavasti tietoa esim. mitä interdomain linkkiä p4p suosivat
				
				-Ei pelkästään p2p-sovelluksille, mutta papru keskittyy niihin
				-Koostuu eri osista
					-Control plane (Paperi keskittyy tähän)
						-iTrackers
							-Portals operated by ISPs
							-Näiden avulla P4P pystyy jakamaan liikenteenhallinnan sovellusten ja ispn välille
							-Jokaiselle verkolle oma
							
					-Management plane
						-Tarkkailee control planen käytöstä
					
					-Data plane
						-Optional
				
			-P4P-ongelmat:
				-Yleinen rajapinta
					-Pitää tukea yhä enemmän luotuja P2P sovelluksia
					
				-Haluavatko ISPt ja P2P-sovellukset käyttää sitä
			
			-Testattu simulaatioilla ja planetlabilla
				-In addition, we
				have conducted large-scale test deployment with a major commercial
				P2P vendor, Pando Networks, Inc. on networks of major ISPs.
				
				-Paperissa real internet = planetlab
				
			-Tutkimusten mukaan p4p voi hyödyttää myös käyttäjiä verkonkäytön tehostamisen lisäksi
				-Miksi P2P kannattaisi hyödyntää P4P?
					-1: Verkon tehokkaampi käyttö voi johtaa paremaan sovelluksen performanssiin
						-Lähempi vertainen voi olla nopeampi päästä (ei aina tosin)
						-Verkkoliikennnettä pystytään reitittämään paremmin -> nopeat reitit eivät ruuhkannu yhtä herkästi
						
					-2: Jos P2P "olevat kiltisti" niin ISPiden ei tarvi rajoittaa niiden liikennettä
					-3: P4P on antaa melko paljon joustoa P2P:lle
						-Third, P4P leaves much
						flexibility for P2P (e.g., P2P can integrate provider suggestions
						with its local application-specific requirements).
						
						-Eli ei vissiin määrää vertaisia suoraan, vaan antaa sovellusten itse valita omien speksien mukaisesti
						
					-4: Muutkin sovellukset hyötyvät kun verkkoa hyödynnettään tehokkaasti
						
				
		Related works:
			-Jakaa ratkaisut eri kategorioihin:
				ISP approaches:
					-Traffic engineering [2, 10] (traditional)
					-P2P välimuisti
						[8, 12, 16, 27, 29, 32, 36]
							[12]: Should ISPs fear P2P?
							
					-Using traffic shaping devices to rate limit P2P [6, 7, 19, 20, 28, 33]
						-Identifioidaan p2p packetit
						-Unilateral rate limiting by ISPs can be considered
						strong handed and may lead to P2P reactions such as encryption
						and dynamic ports to avoid being identified.
							-Furthermore, techniques
							such as rate limiting, end-point usage-based charging, or
							priority are mainly for controlling edge traffic demands, not for improving
							network efficiency.
							
				P2P approaches:
					-Jotkut P2P sovellukset yrittävät itse parantaa verkon tehokkuutta
						
					-Karagiannis et al. [12] and Madhyastha et
					al. [17] have observed that locality of P2P connections indeed reduces
					the download time of users.
						-However, as we discussed, there
						are many limitations on P2P determining locality. In our project,
						we target a fundamental solution and leverage the fact that the ISPs
						are best-positioned to determine locality and to direct applications
						to not only nearby peers but also to peers that are accessible over
						well-provisioned links.
						
						-There is also previous work on how to design P2P applications
						that limit their own transfer rates to share network resources with
						other traffic (e.g., [15, 34]). However, these approaches, similar to
						the ISP rate limiting approaches, are mainly for controlling traffic
						demands, instead of for improving network efficiency.
						
				Network architecture
					-Ehdotetaan että internetin rakenteeseen lisätään middelwareja yms. (e.g., [25]).
					-Eivät tiedä muita ehdotuksia kuin oraakkeli
						-Väittävät että oraakkeli on simmpelimpi versio p4p ja p4p on parempi ratkaisu (kato paprusta tarkemmin)
										
		Omat huomiot
			Artsassa P4P on lyhenne 'Provider portal for applications', mutta wikipedian mukaan P4P on lyhenne 'Proactive network provider participation for P2P'
				-Ovatko molemmat valideja nimiä vai onko jompikumpi vakiintunut toisen sijaan?
				-Kuitenkin tarkoittaa samaa asiaa
					https://s3.amazonaws.com/academia.edu.documents/31723441/tr1377.pdf?response-content-disposition=inline%3B%20filename%3DP4P_Proactive_Provider_Participation_for.pdf&X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWOWYYGZ2Y53UL3A%2F20200124%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20200124T134206Z&X-Amz-Expires=3600&X-Amz-SignedHeaders=host&X-Amz-Signature=8bfcfdefdf5d15166b3e07d9ffde231161f030a29ffcf7c30f9021c5b295dc17
						-Tässä artsassa käytetään proactive jne. nimeä ja samat kirjoittajat
							-137 viittausta
						
				-Myös on nimi 'p4p: explicit communications for cooperative control between p2p and network providers'
					https://laffertymediapartners.com/dcia/documents/P4P_Overview.pdf

			-https://torrentfreak.com/uncovering-the-dark-side-of-p4p-080824/
				-Blogi, mutta antaa piraattiyhteisön näkökulman
					
			https://en.wikipedia.org/wiki/Ono_(P2P)
				-Samankaltainen tavoite kuin p4p
					-open source, ei vaadi infrastruktuurimuutoksia, ideana vain muuttaa bittorrent clienttejä siten että ne suosivat lähempiä vertaisia
						-Vastaväite-artsa, jonka mukaan ei kuulemma tarjoa merkittävää ratkaisua
							http://conferences.sigcomm.org/hotnets/2009/papers/hotnets2009-final115.pdf
	
	Taming the torrent: a practical approach to reducing cross-isp traffic in peer-to-peer systems
		Choffnes, David R., and Fabián E. Bustamante. "Taming the torrent: a practical approach to reducing cross-isp traffic in peer-to-peer systems." ACM SIGCOMM Computer Communication Review 38.4 (2008): 363-374.
		
		597 viittausta
		
		A decentralized alternative for conveying network layer
		information to P2P-clients is proposed in [1]. This approach
		re-uses information provided by content delivery networks
		(CDNs) to guide peer selection for P2P-applications. This
		idea is based on the fact that CDNs try to minimise download
		latency. To achieve this, clients are directed to CDN replica
		servers via dynamic DNS. It is reasonable to assume that
		if two clients are sent to the same CDN replica server they
		are likely to be located close to each other on the network
		topology. As a metric to express network layer locality
		between peers based on CDN redirection, using the cosine
		similarity of the replication server ratio maps between two
		peers is proposed [1]. (Traffic Localization for P2P-Applications: The ALTO Approach)
		
		-Artikkelin pointit
			-P2P ja ISP yhteistyö ei välttämättä todennäköistä
			-Ehdottavat skaalautuvaa biased peer-selection tekniikkaa joka ei vaadi yhteistyötä ISPltä tai sen asiakkailta
				-This technique is based on
				the observation that the information necessary for peer selection is
				already being collected by content distribution networks (CDNs).
					-CDNs use dynamic DNS redirection to send clients to low-latency
					replica servers located in thousands of ISPs worldwide. We posit
					that if two clients are sent to a similar set of replica servers, they
					are likely to be close to these servers and, more importantly, to each
					other.
					-Eli hyväksikäyttää olemassaolevia CDN ikäänkuin "Oraakkeleina"
						-CDNt estimoivat käyttäjiensä etäisyyksiä
							-Kato tarkemmat tiedot paperista
							-(Onko tässä kuitenkin sama fundementaalinen ongelma että CDNllikään ei pääsyä suoraan verkon ominaisuuksien tietoihin)
							
					-CDNnät uudelleenohjaavat DNSn kautta käyttäjiä kopiopalvelimille, jotka sijaitsevat paikallisesti tuhansissa eri palveluntarjoajien verkoissa ympäri 
					maailmaa
						-Jos käyttäjät uudelleen ohjataan samoille palvelimille, sijaitsevat nämä todennäköisesti lähekkäin
						
			-Lisäosa Azureus BitTorrent-clientille
				-Paperin kirjoittamisen aikaan yli 120 000 käyttäjää
				-Koska kaikki eivät käyttä Ono-lisäriä, estimoi se myös niidenkin etäisyyksiä
					-(Pitfalls-paprussa kuitenkin sanottiin että hyötyisi vain jos molemmat vertaiset käyttävät lisäriä?)
						-Muistaakseni näin ei ollutkaan kun luki väitteen tarkemmin
				
			-Tutkijat väittävät että heidän ratkaisunsa
				-Skaalautuu hyvin
				-Vähentää verkkojenvälistä liikennettä
					-Ilman että P2P kärsisi performanssisn tai päällysverkon eheyden heikkenemisestä
					¨
				-Löytää vertaisia joilla two orders of magnitude pienempi latenssi ja 30% lower loss rates kuin satunnaisesti valituilla
					-These high-quality paths can lead to significant improvements in transfer rates
					
			-Ehdotetaan halvempaa ratkaisua jossa vertaispäätökset tehdään vaan AS-numeron perusteella
				-Se vähentää verkkonvälistä liikennettä, mutta se kärsii joistain rajoitteista
					-Suurilla palveluntarjoajilla on useampi numero käytössään
						-Tällöin AS:ien välinen liikenne ei ole välttämättä ISPn välistä liikennettä
						
				-AS:ien sisällä ei ole välttämättä monia vertaisia
					-Pätee myös CDN-ratkaisuun, mutta CDN:llä huomataan vertaisia jotka ovat silti lähempänä toisten ISPiden verkoissa
					
				-Jos AS on liian väljä, niin AS:n sisäiset reitit voivat olla hitaampia 
					-Because CDN redirection
					are based primarily on latency, however, CDN-based oracles can
					successfully avoid these scenarios.
		
			-Huolia CDN käyöstä
				-Paperilla vastataan että ei pitäisi olla syytä huoleen
				
			-Testausmenetelmät
				-Julkaisivat lisäosan lataukseen
					-Tammikuuhuun 2008 mennessä yli 120 000 lataajaa levittäytyneenä 108 eri maahan
				
				-Vertaisvalinnan lisäksi lisäosa tekee verkkomittauksia ja kerää tietoa tiedostonsiirron suorituskyvyistä
				-Saivat kerättyä tietoa yli 100 000 000 vertaisesta jotka käyttivät yli 100 eri clienttiä ja sijaitsivat yli 10 000 eri ASsissä
				-Kerättyjen tietojen pohjalta laskivat sitten tulokset
					-Kerätyt tiedot 6h sessioista (TÄMÄ EHKÄ TÄRKEÄ?)
						However, because users can terminate data reporting at
						any time by force-closing their client, it is not sufficient to rely
						on this information alone. Instead, we use ratio-map information
						collected over the course of a six-hour interval to determine which
						peers were recommended by Ono, then examine statistics inside
						this interval accordingly. We chose this interval because ratio
						maps are relatively stable at this time scale but tend to change
						significantly over larger ones. Thus, each point in the following
						figures represents the average of the statistics recorded from one
						Ono peer during a six-hour interval.
				
				-6.2 Reducing Cross-ISP-Traffic
					-Verrattiin onon suosittelemia vertaisia vs. bittorrentin suosittelmiin satunnaisiin vertaisiin (huom. nämä menetelmät voivat suositella samoja yksittäisiä vertaisia)
						-Huom käytetty näkökulma ei ollut globaali!
						-Ensin tarkasteltiin käyttämällä ranskalaisen sanomalehden verkkosivujen CDNnää Onossa
					
					-Tulokset
						Of course, IP hop counts (greater than 1) do not necessarily tell
						us whether traffic crosses ISPs. To better estimate the number of
						ISPs crossed by a particular path, we mapped each IP address in a
						traceroute measurement to its corresponding AS number.
						
						-IP
							-Onon suosittelemat vertaiset mediaani 6 IP hopin päässä, BitTorrentin 14
							-20% onon suosittelemista vertaisista vain yhden IP hopin päässä, BitTorrentilla alle 2%
							
						-AS
							-33% vertaisten välisistä reiteistä ovat AS:n sisällä
							-Onon löytämien vertaisten välisten reittien mediaani AS hop on 1
								-BitTorrentilla alle 10% valittujen vertaisten välisten reittien mediaani on 1
								
				-6.5
					-In the previous sections, we focused on how Ono reduces cross- ISP traffic without sacrificing download performance when using a single CDN name.
						-Ono tukee useiden CDNnien käyttämistä
					
					-Verrattiin eri CDN käyttävien onojen eroja
					-CDN:nien välillä on eroja
						-Paras CDN tarjoaa 10000 replika-palvelinta ympäri maailmaa
						-Huonoimmalla CDNllä oli vain 20 replika-palvelinta ympäri maailmaa
						
					-Tutkimusten mukaan huonoimmatkin CDNnät pystyivät merkittäviin ulkoliikennesäästöihin
				
				
			-Tutkimustulokset (conclusion-osioista)
				-Onon ratkaisu skaalautuu hyvin yli 100 000 käyttäjälle
				-Vähentää BitTorrentin ulkoliikennettä haittaamatta latausnopeuksia ja verkon eheyttä
					-Latausnopeudet voivat parantua mikäli vertaisilla on tarpeeksi hyvät yhteydet
					
				-yli 1/3 ajasta lisäri löytää vertaisten välille reitit jotka eivät kulje edes toisien AS kautta
				-Onon BPS löytää vertaiset joilla kaksi kertaa pienemmät latenssit kuin satunnaisesti valitut
					-ja 33% pienempi lossrate (abstract)
					-Valitut reitit johtavat parempiin latausaikoihin (abstract)
					
			-Tutkimustulokset abstractistä
				-In challenged settings where peers are overloaded
				in terms of available bandwidth, our approach provides 31%
				average download-rate improvement; in environments with large
				available bandwidth, it increases download rates by 207% on
				average (and improves median rates by 883%).
				
			-Tutkimustuloset abstractissä
				-Onon BPS suosittelee vertaisia joiden mediaani AS etäisyys on 1
				
			-Huom! Tulokset eivät ilmaise eksplisiittistä ulkoliikenteen vähenemisestä
				-Mittauksena käytetään IP- ja AS-hoppeja (Pushing pittorrent locality to the limit)
		

		Similar
		in spirit to this work, the P4P [37] project attempts to address
		the problem through custom trackers, both for ISPs and P2P
		systems, using an interface based on a primal-dual decomposition
		of an optimization problem. This interface design simplifies
		the realization of traffic-engineering objectives from each parties’
		perspective and ensures the extensibility of the approach.
		
		
		A clear advantage of these proposals is that they
		allow ISPs to incorporate aggregated traffic policies in their tracker
		recommendations (e.g., a particular traffic balance ratio between
		peering providers). However, all of them require deployments
		of oracles for each participating ISP and their effectiveness is
		ultimately predicated on their adoption by P2P applications and a
		trust relationship between P2P users and their ISPs.
		
	Improving traffic locality in bittorrent via biased neighbor selection
		Bindal, Ruchir, et al. "Improving traffic locality in BitTorrent via biased neighbor selection." 26th IEEE International Conference on Distributed Computing Systems (ICDCS'06). IEEE, 2006.
		
		502 viittausta
		
		A more concrete proposal to improve P2P-locality through
		network layer topology information has been proposed in
		[7]. The overall idea is simple: Instead of random peer
		selection, peers are supposed to select all but k peers from
		their ISP. For instance, if peers have a connectivity degree d
		(i.e., they are connected to d peers on the overlay layer), d−k
		neighbours for each peer are supposed to be located within
		the same ISP while k links exist to peers in different ISPs for
		each peer.
			This is called biased neighbour selection. In [7] the authors
			envision two ways to implement biased neighbour selection:
			Either by using a modified tracker or by modifying traffic
			shaping devices which intercept P2P traffic at edge routers
			of each ISP. Both solutions assume a way (for trackers or
			traffic shaping devises) to access information regarding ISP
			locality. (Traffic Localization for P2P-Applications: The ALTO Approach)
		
		Artikkelin pointit:
			-Onko satunnainen vertaisvalinta välttämätöntä BitTorrentin toiminnan kannalta?
			-Painotettu vertaisvalinta (biased peer selection) (BitTorrentille)
				-Testaavat simulaatioilla
					-We rely on simulations since it is difficult to
					capture all the relevant mechanisms in BitTorrent clients in
					an analytical model
					
					-Different from other simulation studies [1, 15],
					the simulator does not assume that the bottleneck link is the
					individual peer’s upload link, but rather can model arbitrary
					network links to be the bottleneck.
						15: should fear paperi
						
					-Testaavat homogeenisillä ja heterogeenisillä verkoilla
					
			-Testaavat myös bandwith throttlingia
			-Tulivat tulokseen että BPS (in which a peer chooses the majority, but not all, of its neighbours from peers within the same ISP) pystyy vähentämään ulkoliikennettä ja 
			takaamaan että latausperformanssi pysyy optimaalisena
				• As long as the original seed (the host that starts sharing
				the file) has moderately high upload bandwidth
				(e.g. four times the prevailing upload bandwidth of the
				peers), biased neighbor selection results in no degradation
				in download times, regardless of whether it is
				deployed by all ISPs or by just one ISP.
					-Jos alkuperäisellä tiedostonjakalla on tarpeeksi korkea lähetysnopeus, BPS ei hidasta latausnopeuksia
				
				• Under biased neighbor selection, the cross-ISP traffic
				due to downloading of a particular file stays relatively
				constant, and does not grow as the number of peers
				interested in the file increases. In fact, as the number
				of peers inside an ISP increases, the traffic is reduced
				slightly.
					-BPSllä ISPn ulkopuolinen liikenne ei kasva tietyn tiedoston vertaisten lisääntyessä
				
				• The “rarest first replication” algorithm is key to the
				success of biased neighbor selection. It has a “declustering”
				effect, improving the chances that peers
				within the same ISP have blocks to exchange with one
				another. Random piece selection, shown in other studies
				to work just as well in regular BitTorrent [1, 16],
				does not work well with biased neighbor selection.
				Here, “rarest first” refers to the strategy of choosing
				a block to download from the blocks a neighbor has.
				Under this scheme, the block which is least replicated
				among other neighbors is chosen first.
					-BPS toimii hyvin BitTorrentin rarest first replication -periaatteen kanssa
				
				• For a cable modem or DSL ISP, when there are external
				high bandwidth peers, biased neighbor selection
				needs to be combined with bandwidth limiting to keep
				cross-ISP traffic at a minimum level. However, unlike
				pure bandwidth limiting, the combined scheme does
				not increase download time.
					-BPS ja kaistanrajoituksen yhdistelmä ei kasvata latausaikoja mikäli kyseisellä ISPllä on hitaammat yhteydet ja vertaisia on enemmän ulkopuolella
				
				• Since each BitTorrent node prefers to upload to neighbors
				which have been giving data to it at a good rate,
				(the “tit-for-tat” mechanism) pure bandwidth limiting
				does push a peer toward intra-ISP peers, and can reduce
				cross-ISP traffic. However, its effect is limited
				by the initial neighbor selection of the peer, and combining
				bandwidth throttling with biased neighbor selection
				is much more effective.
					-Jos BPS yhdistää kaistanrajoituksen kanssa, saadaan tehokkaammin vertaiset pysymään ISPn sisällä
						-Pelkkä kaistanrajoitus joskus puskee vertaissuhteita verkon sisälle
					
				• Allowing only a single peer to connect to the external
				nodes results in a significant increase in download
				time. This means that ordinary peers cannot act
				as gateway peers. Instead, dedicated high-bandwidth
				nodes should be used, and the approach does not scale
				to multiple concurrent BitTorrent networks.
					-Jos vain yhdellä vertaisella on yhteys verkon ulkopuolelle, seuraa siitä nopeammat latausnopeudet muille vertaisille
						-Tämä yksi vertainen ei kuitenkaan voi olla tavallinen käyttäjä, vaan siihen tarvitaan ISPn dedikoima korkean kaistan solmu
							-Ei skaalaudu useampaan eri BitTorrent-verkkoon
				
				• Using caches inside ISP’s for BitTorrent traffic requires
				them to have high upload bandwidth to avoid
				increasing the download times. Combining biased
				neighbor selection with caches can reduce both the
				peak and average bandwidth needed, and the addition
				of bandwidth limiting can cap the peak bandwidth.
					-ISPn sisäiset välimuistit vaativat paljon lähetyskaistaa jotta latausajat eivät kärsisi
						-Yhdistämällä välimuistit BPS kanssa tarvittava maksimi kapasiteetti ei ole niin suuri	
				
			-Kaksi tapaa implementoida BPS
				-Trackerien ja clientin muutokset
				-P2P traffic shaping devices
					-Verkkojen reunoilla
					-Havaitsevat P2P-paketit ja manipuloivat niitä
					
				-Pitää kirjaa jokaiselle tiedostolle ketkä lataavat sitä verkon sisällä
				-Kaappaa trackerin lähettämät viestit vertaiselle ja korvaa sen ehdottamat vertaiset paikallisilla
				-Jos uusia paikallisia potentiaalisia vertaisia yhdistyy, väkisin sulkee yhteyden ulkopuolisen vertaisen kanssa jolloin vertainen lähettää uuden pyynnön trackerille
				
			-BitTorrent verkkoja voidaan klusteroida
				-Kunhan
					-Jokaisesta klusterista on useampi kuin yksi linkki ulkopuolelle
					-Rarest piece first replication is used
					
			-BPS voidaan käyttää laajakaistan rajoittamisen ja välimuistien kanssa
			
			-Our immediate next step is an implementation study.
			We are implementing the scheme in a modified BitTorrent
			client, and also in a HTTP proxy acting as a P2P shaping
			device.
			
	A survey of research on the application-layer traffic optimization problem and the need for layer cooperation ←--------------- KATO TÄÄ!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!
		Gurbani, Vijay K., et al. "A survey of research on the application-layer traffic optimization problem and the need for layer cooperation." IEEE Communications Magazine 47.8 (2009): 107-112.

		IEEE Communications Magazine
			H-index: 210
			JUFO-taso: 2

		-46 viittausta

		-Tiivistelmä ongelmasta ja katsaus artikkeleista !!!!!!!!!
		
		Abstract
			A significant part of Internet traffic today is generated
			by peer-to-peer applications, used traditionally
			for file sharing, and more recently for real-time
			communications and live media streaming. Such
			applications discover a route to each other through
			an overlay network with little knowledge of the
			underlying network topology. As a result, they may
			choose peers based on information deduced from
			empirical measurements, which can lead to suboptimal
			choices. We refer to this as the applicationlayer
			traffic optimization (ALTO) problem and
			present a survey of existing literature. We summarize
			and compare existing approaches, identify open
			research issues, and state the need for layer cooperation
			as a solution to the ALTO problem.
			
		-Paperin pointit
			-Antaa paikallisuusongelman nimeksi ALTO
				-Application Layer Traffic Optimization problem
				
			-P2P käytetään nykyään myös real-time multimedia communications ja live media streamning
			-Paprun kirjoittaneet ovat sitä mieltä että kerrosten (application ja network) välinen kommunikointi on paras ratkaisu ongelmaan
				-Pelkällä sovellustasolla tehtävillä ratkaisuilla on fundamentaaliset rajat mitä niillä kyetään saavuttamaan
				-Topologia-estimointi menetelmät käyttävät abstratioita verkkotopologiasta jotka kätkevät ominaisuuksia jotka voisivat olla kiinnostavia p2p-sovelluksille
				-Kun käytetään verkkokoordinaatteja estimoimaan topologia-informaatiota, oletetaan että latenssi määrittää etäisyydet
					-Tiedostojen jakamiseen pelkkä latenssi ei kuitekaan riitä
						-Throughput
						-Data loss
						-RTT (round-trip-time)
						
				-P2P-sovelluste omat topologian estimointi menetelmät eivät useinkaan johda optimaalisiin ratkaisuihin
				-Joitain verkon ominaisuuksia on vaikea tai mahdoton estimoida
					-Examples of such features are service provider
					policies and preferences such as the state and cost
					associated with interdomain peering and transit
					links. Another example is the traffic engineering
					policy of a service provider, which may counteract
					the routing objective of the overlay network, leading
					to poor overall performance [11].
					
				-Estimoinnit luovat traffic overheadia
					-Eritoten jos kaikki P2P-sovellukset tekevät estimoinnin itsenäisesti
						-(eikä esimerkiksi käyttämällä oraakkelia tms.)
					
			-Monet topologian estimoinnin menetelmät perustuvat latenssiin, joka yksinään ei välttämättä ole riittävä P2P tapauksessa
				-Monelle P2P-sovellukselle latenssi ei ole tärkein tekijä
					-Sovellukset voisivat hyötyä siis runsaammasta informaatiosta
						-Sophisticated methods of active network probing
						and passive traffic monitoring are generally very
						powerful, and can generate network statistics
						indirectly related to performance measures of
						interest, such as delay and loss rate on link-level
						granularity. Extraction of these hidden attributes
						can be achieved by applying statistical inference
						techniques developed in the field of inferential
						network monitoring or network tomography subsequent
						to sampling of the network state. Thus,
						network tomography enables the extraction of a
						richer set of topology information, but at the
						same time inherently increasing complexity of a
						potential information plane and introducing estimation
						errors.
						
						-For both active and passive methods,
						statistical models for the measurement
						process need to be developed, and the spatial
						and temporal dependence of the measurements
						should be assessed. Moreover, measurement
						methodology and statistical inference strategy
						must be considered jointly. For a deeper discussion
						of network tomography and recent developments
						in the field, we refer the reader to [14].
						
				-Muita kriteereitä:
					-Throughput
					-Packet loss rate
			
			-Ratkaisujen taksonomia
				-End systems mechanisms for topology estimation
					-Coordinate-based systems
						-Network coordinate systems require the embedding
						of the Internet topology into a coordinate system.
						This is not always possible without errors,
						which impacts the accuracy of distance estimations.
						
						-GNP
							-Vasatuksena IDMapsin skaalautuvuusongelmiin
							-IDMpas ja GNP vaativat verkkoinfrastruktuuria (tracereita/landmark hosts)
								-this often introduces a single point of failure and inhibits scalability
								
						-Vivaldi
							-Vastauksena IDMapsin ja GNPn ongelmiin
							-Käytetään ilmeisesti Azureuksessa, ilmeisesti skaalautuu erään paperin mukaan hyvin
							
						-PIC
							-Vastauksena IDMapsin ja GNPn ongelmiin
						
					-Path selection services
						-IDMaps
							-Ilmeisesti oli skaalautusongelmia
							
						-Meridian
							-Koordinaatti-systeemit herkkiä virheille (ylläoleva teksit), vastauksena tähän
							
						-Ono
							-Taming the torrent
						
					-Link-layer Internet maps
						iPlane
							-Sophisticated methods of active network probing
							and passive traffic monitoring are generally very
							powerful, and can generate network statistics
							indirectly related to performance measures of
							interest, such as delay and loss rate on link-level
							granularity. Extraction of these hidden attributes
							can be achieved by applying statistical inference
							techniques developed in the field of inferential
							network monitoring or network tomography subsequent
							to sampling of the network state. Thus,
							network tomography enables the extraction of a
							richer set of topology information, but at the
							same time inherently increasing complexity of a
							potential information plane and introducing estimation
							errors.
							
							-For both active and passive methods,
							statistical models for the measurement
							process need to be developed, and the spatial
							and temporal dependence of the measurements
							should be assessed. Moreover, measurement
							methodology and statistical inference strategy
							must be considered jointly. For a deeper discussion
							of network tomography and recent developments
							in the field, we refer the reader to [14].
							
							-Atlas joka sisältää tietoa Internetistä, kuten latenssi, bandwith, capacity ja loss rate
						
					-Paprussa tauluko menetelmien (ei ono) suhteellisista error-rateista
						
				-Operator-provided topological information
					-techniques where the application-layer
					works closely with some other layer (e.g., routing)
					or some entity that has more of a global networking
					view than the application does in isolation
					
					-Poistaa tarpeen p2p-sovelluksilta estimointiin
						-ISPt / network operaattorit tietävät valmiiksi
							-Verkkojensa ominaisuudet
							-the business agreements
							and routing policies that are used to shape
							traffic in the physical network
				
					-P4P: Provider for portal applications
						-The architecture proposed
						by Xie et al. [8] has been adopted by the DCIA
						P4P Working Group ,2 an open group established
						by ISPs, P2P software distributors, and technology
						researchers with the dual goal of defining mechanisms
						to accelerate content distribution and optimize
						utilization of network resources.
						
					-Oracle-based ISP and P2P cooperation
					-ISP-driven informed path selection

					-Tarkempia kuvauksia menetelmistä paprussa
					
					
			-Avoimet tutkimusongelmat
				-Cachaus
					-Haittapuolet
						-Protokolla-riippuvaisia (HTTP, BitTorrent)
						-Tekijänoikeudet
						
					-Välimuisti ei haittaa sovellusten omia estimointi-ratkaisuja
						-Voisi olla mahdollista peräti tehdä yhteistyötä
							-Sovellukset ottavat huomioon välimuistien olemesssaolon
					
				-A resilient protocol
					-Regardless, such a protocol
					should adequately express the preferences of a
					P2P host to the network operator without disclosing
					information the host may consider private,
					providing the network operator with enough
					primitives such that the response sent back to the
					host does not reveal undue topological information
					of the operator’s network.
					
					-Eli protokolla joka ei paljasta liikaa informaatiosta käyttäjästä tai verkosta
					
				-Coordinate estimation or path latencies?
					-Molemmilla omat vahvuudet ja heikkoudet
					
				-Malicious nodes
					-Oraakkelin suojaus vihamielisiltä vertaisilta
					
				-Information integrity
					-it is still possible that the information returned to
					applications is deliberately altered; for example,
					assigning higher priority to cheap (monetary-wise)
					links instead of neutrally applying proximity criteria
						-Similarly, what are the consequences if an
						oracle targets a particular node in another AS by
						redirecting an inordinate number of querying peers
						to it, essentially causing a distributed denial-of-service
						(DDoS) attack on the node? Furthermore,
						does an oracle broadcast or multicast a response to
						a query? If so, techniques to protect the confidentiality
						of the multicast stream will need to be investigated
						to thwart “free riding” peers.
						
				-Simulate or build?
					-Usein ainoa tapa testata ratkaisuja on simulaatioilla yms. testiympäristöillä
						-Nämä eivät kuitenkaan ole välttämättä riittäviä osoittamaan toimivuutta
				
				-Richness of topology information
					-Mitä kaikkea tietoa tulisi tarjota
					
				-Hybrid solutions
					-It is conceivable that P2P users
					may not be comfortable with operator intervention
					to provide topology information
					
					-Vaihtoehtoisia skeemoja jotta ISP ei tarvitse tulla mukaan
						-Ono hyödyntää Akamai-CDN:nää
						-Vivaldi, GNP, and PIC use synthetic coordinate systems.
						-Neutraali kolmanne osapuoli voisi tehdä hybridi-taso-yhteistyö-palvelun (ilman ISPn aktiivista osallistumista)

Välimuisti
	Design and Evaluation of a Proxy Cache for Peer to Peer Traffic	
		Hefeeda, Mohamed, Cheng-Hsin Hsu, and Kianoosh Mokhtarian. "Design and evaluation of a proxy cache for peer-to-peer traffic." IEEE Transactions on Computers 60.7 (2011): 964-977.

		41 viittausta
		
		twork  traffic  generated  by  P2P  applications  hasdifferent characteristics than traffic generated by other Internetapplications.  For  example,  object  size,  object  
		popularity,  andconnection  pattern  in  P2P  systems  are  quite  different  fromtheir counterparts in web systems. Most of these characteristicsimpact  the  performance  of  
		caching  systems,  and  therefore,they should be considered in their design

		In addition, as willbe  demonstrated  in  this  paper,  designing  proxy  caches  forP2P  traffic  is  more  complex  than  designing  caches  for  webor  multimedia  traffic,  
		because  of  the  multitude  and  diversenature  of  existing  P2P  systems.

		Furthermore,  P2P  protocolsare not standardized and their designers did not provision forthe potential caching of P2P traffic.

		In P2P systems, a receiving peer requests an object from
		multiple sending peers in the form of segments, where a
		segment is a range of bytes. Object segmentation is protocol
		dependent and even implementation dependent. Moreover, segment
		sizes could vary based on the number and type of senders
		in the download session, as in the case of Gnutella. Therefore,
		successive requests of the same object can be composed of
		segments with different sizes. For example, a request comes
		to the cache for the byte range [128—256 KB] as one segment,
		which is then stored locally in the cache for future requests.
		However, a later request may come for the byte range [0—512
		KB] of the same object and again as one segment. The cache
		should be able to identify and serve the cached portion of
		the second request. Furthermore, previous work [11] showed
		that to improve the cache performance, objects should be
		incrementally admitted in the cache because objects in P2P
		systems are fairly large, their popularity follows a flattenedhead
		model [1], [11], and they may not be even downloaded in
		their entirety since users may abort the download sessions [1].
		This means that the cache will usually store random fragments
		of objects, not complete contiguous objects, and the cache
		should be able to serve these partial objects.

		While web proxy caches share some characteristics with
		P2P proxy caches, their storage systems can yield poor performance
		for P2P proxy caches, as we show in Sec. 7.3.

		The authors of [7] propose using already-deployed web caches
		to  serve  P2P  traffic.  This,  however,  requires  modifying  the
		P2P  protocols  to  wrap  their  messages  in  HTTP  format  and
		to  discover  the  location  of  the  nearest  web  cache.  Given  the
		distributed and autonomous nature of the communities devel-
		oping  P2P  client  software,   incorporating  these  modifications
		into  actual  clients  may  not  be  practical.
			In addition, several
			measurement studies have shown that the characteristics of
			P2P traffic are quite different from those of web traffic [1],
			[2], [8], [10], [11]. These different characteristics indicate that
			web proxy caches may yield poor performance if they were
			to be used for P2P traffic. The experimental results presented
			in this paper confirm this intuition.
			
		Most storage systems of web proxy caches are designed for
		small objects. For example, the Damelo system [28] supports
		objects  that  have  sizes  less  than  a  memory  page,  which  is
		rather small for P2P systems. The UCFS system [23] maintains
		data structures to combine several tiny web objects together in
		order to fill a single disk block and to increase disk utilization.
		This adds overhead and is not needed in P2P systems, because
		a  segment  of  an  object  is  typically  much  larger  than  a  disk
		block.  Clustering  of  web  objects  downloaded  from  the  same
		web  server  is  also  common  in  web  proxy  caches  [22],  [24].
		This clustering exploits the temporal correlation among these
		objects in order to store them near to each other on the disk.
		This  clustering  is  not  useful  in  P2P  systems,  because  even  a
		single object is typically downloaded from multiple senders.

		Proxy caches for multimedia streaming systems [25]–[27],
		on  the  other  hand,  could  store  large  objects  and  serve  byte
		ranges.  Multimedia  proxy  caches  can  be  roughly  categorized
		into four classes [25]: sliding-interval, prefix, segment-based,
		and  rate-split  caching.  Sliding-interval  caching  employs
		a sliding-window  for  each  cached  object  to  take  advantage  of
		the  sequential  access  pattern  that  is  common  in  multimedia
		systems.  Sliding-interval  caching  is  not  applicable  to  P2P
		traffic,  because  P2P  applications  do  not  request  segments  in
		a  sequential  manner.  Prefix  caching  stores  the  initial  portion
		of multimedia objects to minimize client start-up delays. P2P
		applications  seek  shorter  total  download  times  rather  than
		start-up  delays.  Segment-based  multimedia  caching  divides  a
		multimedia object into segments using segmentation strategies
		such  as  uniform,  exponential,  and  frame-based.  P2P  proxy
		caches  do  not  have  the  freedom  to  choose  a  segmentation
		strategy;  it  is  imposed  by  P2P  software  clients.  Rate-split
		caching  employs  scalable  video  coding  that  encodes  a  video
		into several substreams, and selectively caches some of theses
		ubstreams.  This  requires  scalable  video  coding  structures,
		which renders rate-split caching useless for P2P applications
	
	
	
	Artikkelin pointit
	 	-HTPT tarvitaan laajamittaisia P2P clienttien muutoksia
		-Web-selaukseen tarkoitetut välimuistit eivät ole välttämättä soveltuvia P2P, koska p2p ja http liikenteen ominaisuudet ovat erilaisia
			-Suunniteltu pieniä objekteja varten
			
		-Multimedia cachet eivät myöskään välttämättä ole soveltuvia P2P
		-Jos P2P-paketit salataan niin välimuistit eivät välttämättä pysty tallettamaan haluttua sisältöä (paprussa sanottiin etto aikovat tehdä pcache version joka tunnistaa 
		salatut paketit)
		-Välimuistin pitää tukea eri P2P implementaatioita
			-P2P-sovellukset jakavat tiedostot segmentteihin
				-Käytetty segmentaatio riippuu protokollasta ja ehkä myös jopa sovelluksesta
	
		-P2P ei välttämättä lataa tiedostoa kokonaan
			-Välimuistin pitää siis tukea satunnaisten tiedostonosien säilömistä
			
	Measurement, modeling, and analysis of a peer-to-peer file-sharing workload <--------- KATO TÄÄ
		Gummadi, Krishna P., et al. "Measurement, modeling, and analysis of a peer-to-peer file-sharing workload." Proceedings of the nineteenth ACM symposium on Operating systems principles. 2003.
		
		1253 viittausta
		
		Abstract
			Peer-to-peer (P2P) file sharing accounts for an astonishing
			volume of current Internet traffic.  This paper probes deeply
			into  modern  P2P  file  sharing  systems  and  the  forces  that
			drive  them.   By  doing  so  ,we  seek  to  increase  our  under-
			standing  of  P2P  file  sharing  workloads  and  their  implica-
			tions  for  future  multimedia  workloads.   Our  research  uses
			a three-tiered approach.  First ,we analyze a 200-day trace
			of  over  20  terabytes  of  Kazaa  P2P  traffic  collected  at  the
			University of Washington.  Second  ,we  develop a model  of
			multimedia workloads that lets us isolate ,vary ,and explore
			the impact of key system parameters.  
			Our model ,which weparameterize with statistics from our trace ,
			lets us confirmvarious hypotheses about file-sharing behavior observed in
			the trace.  Third ,we explore the potential impact of locality-
			awareness in Kazaa.
			
			Our results reveal dramatic differences between P2P file
			sharing  and  Web  traffic.   For  example  ,we  show  how  the
			immutability  of  Kazaa’s  multimedia  objects  leads  clients
			to  fetch  objects  at  most  once;  in  contrast  ,a  World-Wide
			Web client may fetch a popular page (e.g. ,CNN or Google)
			thousands  of  times.   Moreover  ,we  demonstrate  that:   
			(1)this “fetch-at-most-once” behavior causes the Kazaa popu-
			larity distribution to deviate substantially from Zipf curves
			we  see  for  the  Web  ,and  (2)  this  deviation  has  significant
			implications for the performance of multimedia file-sharing
			systems.  Unlike the Web ,whose workload is driven by doc-
			ument change  ,we demonstrate that clients’ fetch-at-most-once behavior ,
			the creation of new objects ,and the addition
			of new clients to the system are the primary forces that drive
			multimedia  workloads  such  as  Kazaa.   We  also  show  that
			there is substantial untapped locality in the Kazaa workload.
			Finally  ,we  quantify  the potential  bandwidth  savings  that
			locality-aware P2P file-sharing architectures would achieve.
			
		Artikkelin pointit
			-Web- ja P2P-sisällön erot
				-Multimedia tiedostot ovat paljon suurempia kuin web-sivut (gigoja vs megoja/kiloja)
				-P2P jaettuja tiedostoja otetaan kerran per käyttäjä, verrattuna web-sivuihin joita sama käyttäjä voi hakea satoja ellei tuhansia kertoja
				-Multimedia sisältö ei muutu, mutta web-sivut voivat
				-P2P sisällön elinikä on usein lyhyt
					-Suosituin P2P-sisältö on hyvin tuoretta
					-Suositun web-sisällön suosio säilyy tasaisena koko ajan
				
				From the above discussion,i t is clear that the forces driving
				the Kazaa workload differ in many ways from those driving
				theWeb. Web users may download the same pages many
				times; Kazaa users tend to download objects at most once.
				The arrival of new objects plays an important role in P2P
				file-sharing systems,wh ile changes to existing pages are a
				more important dynamic in the Web. We discuss implications
				of these differences in Sections 3 and 4.
				
			-Simulaatio
				-Kerätty dataa university of washingtonin verkossa kulkeneesta kazaa-liikenteestä
					-200 päivää
					-20 teratavua
					
				-Ideaalinen välimuisti
					-Rajattomasti kaistaa ja tallennustilaa
					
				-Ideaalinen välimuisti toisi 86% säästöt
					-Eli 86% ulkoa ladatusta sisällöstä löytyisi verkon sisäisiltä vertaisilta
						-Kyseinen verkko oli University of Washingtonin verkko
		
		(Erään uuden paperin mukaan tässä tutkimuksessa väitettiin että ‘86% of requested contents are downloaded from peers outside the local network even though they were locally 
		available)
			
		Regarding the locality analysis, previous studies have
		proposed new ways of clustering peers (e.g. [5][19][20])
		and studied the potential benefits of locality in P2P filesharing
		systems such as KaZaa and Gnutella [8][24]. (Should internet service providers fear peer-assisted content distribution?)
		
		Saroiu et al. [17] and Gummadi
		et al. [6] examine the Gnutella and Kazaa workloads,
		document the increasing popularity of P2P systems,
		study the impact of caching and the potential for bandwidth
		savings of a locality aware mechanism. (Pitfalls for ISP-Friendly P2P Design)
		
		There are several possibilities on how to control the traffic patterns
		of P2P by ISPs. One proposal is to deploy P2P caching devices
		to cut down bandwidth consumed by P2P applications (e.g., [8,
		12, 16, 27, 29, 32, 36]) (P4P: Provider Portal for Applications)

	ARE FILE SWAPPING NETWORKS CACHEABLE? - CHARACTERIZING P2P TRAFFIC
		Leibowitz, Nathaniel, et al. "Are file swapping networks cacheable? Characterizing P2P traffic." Proc. of the 7th Int. WWW Caching Workshop. 2002.
		
		165
			
		Artikkelin pointit
			P2P-liikenne eroaa HTTP-liikenteestä
				-HTTP välimuistit eivät siis soveltuvia P2P:lle
				
				HTTP
					Pienet tiedostokoot (0-1 MB)
					Objektit siirretään täysin yhdessä tai useammassa sessiossa
					Tyypillinen sessio valmis sekunneissa
					Suhteellisen reliable sessiot (sisältö lähetetään dedikoiduilta palvelimilta) -> Sessioiden määrä kuvaa sisällön suosiota
					Graduaalinen muutos objektin suosiossa
					Standardi protokolla
					Yksi portti (80)
					Uniikki sisällön tunnitaminen URLin avulla
						Recent HTTP traffic analysis [4][5] suggests some portion of HTTP objects are associated with multiple URLs, degrading web caching
						performance which assumes unique content identification by URL.
			
				P2P
					Suuret tiedostokoot (100kb - 1gb)
					Tyypillinen tiedoston lataus avaa tusinoittain samanaikaisia sessioita
					Sessio voi viedä useita tunteja
					Sessiot aborttaavat jatkuvasti (sisältö lähetetään käyttäjien tietokoneilta) -> Sessioiden määrä ei kuvaa sisällön suosiota
					Jyrkät muutokset suosiossa kun musiikki, elokuva ja sovellukset tulevat hiteiksi
					Useita eri protokollia [tosin nykyään ehkä oleellisin BitTorrent]
					Useita eri portteja [vielä enemmän johtuen ISPeiden porttien blokkaamiseta]
					Samalla sisällöllä eri nimiä (eli ei uniikisti identifioitavissa)
					
			-Tutkimusmenetelmä: tarkasteltu israelilaisen ISPn verkossa kulkenutta P2P liikennettä
			
			-Alle 20% tiedostoista vastaa 80% latausten kokonaismäärästä
				The exact effect of this
				behavior on the caching potential of P2P traffic depends on
				the distribution of the file sizes. Actual caching results are
				detailed section 3.3, Caching
				
			-Suurin osa P2P-liikenteestä oli elokuvien latauksia
				-Musiikin osuus suht marginaalia
				
			-Suurin osa ladatuista tiedostoista oli ~5mb kokoisia
				-Vastaa tyypillistä musiikkitiedoston kokoa
				-Elokuvien tiedostokoot (>800mb) kuitenkin marginaaliosuus
				
			-100 tiedostoa jotka esiintyivät eniten tarkasteltavassa verkossa
				Musiikki 20%
				Elokuvat 45%
				Sovellukset 25%
				
				-Top 100 tiedoston liikenteen jakautuminen
					Elokuvat ~125 GB
					Applikaatiot ~190 GB
					Musiikki marginaalia	
						-Musiikki kuitenkin overall suurin osa ladatuista tiedoststas
						
			-Teoriassa ei tarvitse olla kovinkaan suuri välimuistin koko
				-~200gb koko voisi olla riittävä
					-(Vissiin johtuu suosion jakautumisesta)
						-Pieni osa tiedostoista hyvin suosittua
						
						
			This paper concludes that P2P traffic transmitted over an
			ISP link is highly repetitive and consequently responds well
			to caching. Our analysis of the traffic computed a 67%
			byte-hit-rate which compares favorably with web caching
			hit rates known to be in the range of 30% to 60%. Further, it
			was shown that the disk space required for effective caching
			of P2P traffic is small enough to be practical – close to
			maximal caching is attained with 200 GB disk space
				Taken together, these findings indicate that the caching
				of P2P traffic is an effective and desired means for coping
				with the bandwidth drain generated by the increase of P2P
				traffic.
				
				
		A recent study [24] has found the peer-to-peer traffic
		of a small ISP to be highly repetitive, showing great potential
		for caching.
		
	An Analysis of Internet Content Delivery Systems
		Saroiu, Stefan, et al. "An analysis of internet content delivery systems." ACM SIGOPS Operating Systems Review 36.SI (2002): 315-327.
		
		840
		
		-2002 artsa, mutta ehkä hyödyllinen näkökulma nähdä kuinka 2000-luvun alussa 
		
		Abstract
			In the span of only a few years, the Internet has experienced
			an astronomical increase in the use of specialized
			content delivery systems, such as content delivery networks
			and peer-to-peer file sharing systems. Therefore, an understanding
			of content delivery on the lnternet now requires
			a detailed understanding of how these systems are used in
			practice.
			This paper examines content delivery from the point of
			view of four content delivery systems: HTTP web traffic, the
			Akamai content delivery network, and Kazaa and Gnutella
			peer-to-peer file sharing traffic. We collected a trace of all
			incoming and outgoing network traffic at the University of
			Washington, a large university with over 60,000 students,
			faculty, and staff. From this trace, we isolated and characterized
			traffic belonging to each of these four delivery
			classes. Our results (1) quanti~, the rapidly increasing importance
			of new content delivery systems, particularly peerto-
			peer networks, (2) characterize the behavior of these systems
			from the perspectives of clients, objects, and servers,
			and (3) derive implications for caching in these systems.
			
		Should internet service providers fear peer-assisted content distribution?
			The fact that users in peer-assisted solutions
			only form a sharing community only while downloading
			the same file, significantly differentiates them from
			other existing file-sharing applications and has important
			implications in the potential benefit of locality-based solutions.
			For instance, [24] provides an extensive analysis of
			content delivery systems, including CDN caching, KaZaa,
			and Gnutella. However, their results do not carry over well
			to peer-assisted solutions such as BitTorrent where cooperation
			only happens if clients are active and sharing the
			same file.
			
			Regarding the locality analysis, previous studies have
			proposed new ways of clustering peers (e.g. [5][19][20])
			and studied the potential benefits of locality in P2P filesharing
			systems such as KaZaa and Gnutella [8][24].
			
		Artikkelin pointit
			-P2P-liikennettä erittäin paljon, joten potentiaalia välimuistille
			-Our goal is not to solve (or
			even identify) all of the complexities of P2P caching- a full
			caching study would be outside of the scope of this paper -
			but rather to gain insight into how important a role caching
			may play.
				-Eli ei funtsita toteutusta, vaan tarkastellaan käytön potentiaalia
			
			-Simuloitiin ideaalivälimuistia, jossa loputtomasti tilaa ja sen sisältö ei poistu koskaan (Kazaalle)
				-85% outband hit rate
				-35% inbound hit rate
				-Top 300 verkkoliikenttä aiheuttamaa p2p-objektia
					-Kokonaiskoko 180GB
					-Keskimääräiskoko 614 MB
					-Objektien verkkoliikenne aiheuttu 5.635 TB
						-42% of the total bytes consumed by Kazaa outbound traffic
						
					-Varovainen estimaatti
						-Välimuisti vain näille saisi aikaan >38% byte hit raten
			
			
		Saroiu et al. [17] and Gummadi
		et al. [6] examine the Gnutella and Kazaa workloads,
		document the increasing popularity of P2P systems,
		study the impact of caching and the potential for bandwidth
		savings of a locality aware mechanism. (Pitfalls for ISP-Friendly P2P Design)
		
		There are several possibilities on how to control the traffic patterns
		of P2P by ISPs. One proposal is to deploy P2P caching devices
		to cut down bandwidth consumed by P2P applications (e.g., [8,
		12, 16, 27, 29, 32, 36]) (P4P: Provider Portal for Applications)
		
		For
		example,a March 2000 study at the University of Wisconsin
		found that the bandwidth consumed by Napster had edged
		ahead of HTTP bandwidth [28]. Only two years later,a University
		of Washington study showed that peer-to-peer file
		sharing dominates the campus network,con suming 43% of
		all bandwidth compared to only 14% for WWW traffic [29] (Measurement, Modeling, and Analysis of a Peer-to-Peer File-Sharing Workload, tää artsa on [29])
		
	Cache Replacement Policies Revisited: The Case of P2P Traffic - (Kirjoita lyhyesti, muutaman virkkeen verran)
		Wierzbicki, Adam, et al. "Cache replacement policies revisited: The case of P2P traffic." IEEE International Symposium on Cluster Computing and the Grid, 2004. CCGrid 2004.. IEEE, 2004.
		
		130 viittausta
		
		Abstract
			Peer-to-peer (P2P) file-sharing applications
			generate a large part if not most of today's Internet
			traffic. The large volume of this traffic (thus the high
			potential benefits of caching) and the large cache sizes
			required (thus nontrivial costs associated with
			caching) only underline that efficient cache
			replacement policies are important in this case. P2P
			file-sharing traffic has several characteristics that
			distinguish it from well studied Web traffic and that
			require a focused study of efficient cache management
			policies. This paper uses trace driven simulations to
			compare traditional cache replacement policies with
			new policies that try to exploit characteristics of the
			P2P file-sharing traffic generated by applications
			using FastTrack protocol.
			
		There are several possibilities on how to control the traffic patterns
		of P2P by ISPs. One proposal is to deploy P2P caching devices
		to cut down bandwidth consumed by P2P applications (e.g., [8,
		12, 16, 27, 29, 32, 36]) (P4P: Provider Portal for Applications)
		
		Artikkelin pointit
			-Tutkimusmenetelmät
				-P2P välimuisti asennettu Israelilaisen ISPn verkkon
				-26 päivän ajalta dataa
				
			-Kolme P2P cachauksen ongelmaa (HUOM!!! Käsittelee nimenomaan fasttrackkia, ei ehkä kokonaisuudessa sovellu myös bittorrenttiins)
				-1. When does a hit occur?
					-P2P pyydetään tavuvälejä
					-Nämä välit eivät ole välttämättä kokonaan välimuistissa
						-Tai välin tavut/bitit on jakautunut muille väleille
						
					-Palautetaan vain yhtenäisiä osia, pyynnöt jotka haluavat dataa joka vain osittain välimuistissa ignorataan
						-Epätehokasta
						
					-Ratkaisut:
						-Muunnetaan käytettyä latausprotokollaa: pystytään palauttamaan osittaisia tavuvälejä
						-Välimuisti pystyy itse lataamaan tiedoston osia (aktiivinen)
							-Passiivinen välimuisti tallettaa vain käyttäjien lataamat osat
						
				-2. Should cache ignore user aborts?
					-Jos välimuisti ei pysty tyydyttämään käyttäjän pyyntöä, tulisiko sen silti ladata valmiiksi haluttu sisältö välimuistiin
						-Usein vertaisverkoissa jos käyttäjä pyytää vertaiselta sisältöä ja tällä ei sitä ole, käyttäjä pyytää tämän sisällön toiselta vertaisella
						-Välimuistin tapauksessa tulisiko välimuistin hankkia pyydetty sisältö välimuistiin, vaikka kyseinen käyttäjä ei tule enää sitä pyytämään
						
					-Ladattu sisältö voisi olla hyödyksi muille käyttäjille
						-Osoitettu että jotkin vertaisverkoilla jaettavat todella suosittuja, on hyvin todennäköistä että jokin muu haluaa myöhemmin samaa sisältöä
						
					-Välimuistien pointti kuitenkin säästää verkkoliikennettä
						-Joten onko pointtia esiladata kaikkea pyydettyä sisältöä
						If the main goal of caching is reducing generated
						network traffic, then the a decision on how the cache
						should handle user aborts can be made once it is known
						how ignoring aborts affects the amount of data
						downloaded by the cache. In other words, would the
						increased byte hit rate that results from more caching
						compensate for the increased download traffic to the
						cache?
						
				-3. Should a Cache Replace File Ranges?
					-Onko parempi säilöä kokonaisia tiedostoja vai pelkästään tiedostojen osia
						-A cache replacement policy can be viewed as a
						specialized instance of the well-known knapsack
						problem. The set of files cached has to maximize a
						certain utility function while satisfying a size
						constraint. In the knapsack problem, it is often easier to
						store many objects if the sizes of all objects are small
						relative to the knapsack size. A P2P cache that stores
						file ranges might therefore benefit from the
						replacement of individual ranges instead of whole files,
						because ranges are smaller and offer more flexibility to
						the replacement policy.
						
					-On vissiin tehokkaampaa säilöä pienempiä osuuksia
						It can be concluded that generally range requests are
						short and ask for any portion of the file. Additionally,
						user aborts tend to increase the number of small
						requests.
						
			-Eri cache replacement policyiden vertailu
				-Replacement policyn tehokkuus riippuu 
					-Palauttaako cache kokonaisia vai osittaisia byte rangeja
					-Tehdäänkö entryjen poisto kokonaisten tiedostojen vai yksittäisten osien perusteella
					
				-Kokonaisia tiedostoja ja file rangeja
				-Full caching (cache palauttaa kokonaisia byte rangeja)
					-LSB-F paras
					-LRU-R toisiksi paras (R = Range)
					-LRU-F kolmansiksi paras (F = File)
					
				-Partial caching (cache palauttaa osittaisia byte rangeja)
					-LRU-R
					-LSB-F
					-LRU-F
					
				-Parhaat overall
					-LRU-R-PARTIAL
					-LSB-F-PARTIAL
					-LSB-F-FULL
					
				-Full range-based
					-LRU hyvä performanssi

	Caching P2P Traffic: What are the Benefits for an ISP?
		Carlinet, Yannick, et al. "Caching P2P Traffic: What are the Benefits for an ISP?." 2010 Ninth International Conference on Networks. IEEE, 2010.
		
		9 viittausta
		
		-Artikkelin pointit
			-37% tarkasteltun verkon käyttäjistä käytti edonkeytä
			-4438 uutta tiedostoa per päivä
				-0.62 tiedostoa per eDonkey käyttäjä
				-Uusien tiedostojen nopea ilmaantuminen tulee ottaa huomioon välimuistia suunniteltaessa
				
			-Websivujen sisältö noudattaa zipfin lakia, mutta P2P objektien suosiota kuvaa paremmin mandelbrot-zipf laki
				-Vahvistaa saleeh ja hafeedan [14} tulokset että P2P objektien suosiota mallintaa manderlbot-zipf
		
			-Paperin tutkimuksen mukaan välimuisti tuo säästöjä
			-Least Recently Used (LRU) on paras P2P-cache replacement policy (bandiwthin säästön puolesta, joka on ISP:lle tärkein tekijä)
				-Aktiivisella välimuistilla LRU:lla on 27% byte hit ratio
					-Huom, tässä paperissa aktiivinen cache lataa tiedoston kokonaan jos jokin käyttäjä pyytää osaa
					
				-Aktiivinen välimuisti on parempi kuin passiivinen LRU ja LFU
					-FILO JA SIZE ei skaalaudu aktiivisuuden mukaan, muutenkin huonompia kuin LRU ja LFU bandwith säästön kannalta
					
			-LFU on parempi passiivisella cachella
				-Passiivisella cachella eksponentiaalinen hyödyn kasvu noin 1 teraan asti (kaistansäästön puolesta)
					-2 teralla
					
			-P2P cachen performanssiin vaikuttavat tekijät
				-The characteristics of the overlay (?), and in particular the distribution of the file popularity.
				-Välimuistin ominaisuudet
					-Koko
					-Replacement policy
					-Cache download rate (aktiivisille)
					
				-The behavior of customers. Since they may not download files completely, file popularity does not give enough information on the downstream traffic.
				-The number of customers. Obviously the cache is more useful if it can serve a lot of customers, because in that case traffic is more likely to be redundant
				
			-Aktiiviset cachet antavat paremmat hit ratiot
				-Välimuisti ei kuitenkaan saa ladata liian aktiivisesti
					On the other hand the data served cannot exceed the
					quantity of data requested, which is in our case equal to
					6,890 GB. The data downloaded by the cache is greater than
					the data served, therefore rather than saving bandwidth, the
					cache actually consumes more bandwidth.

			-Passivinen cache ei aiheuta yhtään ylimääräistä ulkoliikennettä
			
Vastaväitteet
	Pitfalls for ISP-friendly P2P design.
		Piatek, Michael, et al. "Pitfalls for ISP-friendly P2P design." HotNets. 2009.
		
		103 viittausta
		
		Hotnets 2009
			Proceedings of the xth ACM Workshop on Hot Topics in Networks
			-Scopuksella H-Index tapahtumissa ollu noin 10 luokkaa
			-Vissiin ilmeisesti sigcomm workshop?
			
		Michael Piatek
			2641 viittausta
			h-indeksi 19
			i10-indeksi 24
			
			Software engineer at google
			University of Washington
			
		Harsha Madhyastha
			4437 viittausta
			h: 31
			i10: 55
			
			Associate Professor of Computer Science and Engineering, University of Michigan
			Univ. of California, San Diego (paperissa)
			
		John P. John
			1615 viittausta
			h: 12
			i10: 15
			
			I now work at Google Seattle with the Google Maps team
			Univ. of Washington
			
		Arvind Krishnamurthy
			15838 viittausta
			h: 66
			i10: 148
			
			Professor, Univ. of Washington
			
		Thomas Anderson
			49370 viittausta
			h: 90
			i10: 166
			
			Warren Francis and Wilma Kolm Bradley Chair, CSE, University of Washington
			
		
		
		Abstract
			-Peer-to-peer file sharing applications have become enor-mously popular over the past few years, coming to repre-sent a large fraction of wide-area Internet traffic. 
			-A sideeffect of this explosive growth has been an emerging tus-sle between users, who want fast downloads, and ISPs,whose flat-rate pricing business model is threatened 
			by theextreme volume of P2P traffic. 
			-Because ISP costs scalewith usage while their prices do not, many ISPs have at-tempted to throttle or shut down P2P systems. 
			-Recently,several researchers have proposed that this tussle is unnec-essary, that small changes in client and/or protocol behav-ior can lead to a “win-win" solution of 
			better performancefor end-users with less wide-area traffic for ISPs. 
			-Usinga very large scale trace measurement of BitTorrent usage,we find evidence that such a win-win outcome is unlikelyfor at least one very popular P2P protocol
			
		-Lupaavalta vaikuttava artsa, esittää vasta-argumentteja
			-Lähinnä Onoa vastaan, mutta silti mielenkiintoinen näkökulma
			
		-Artikkelin pointit
			-Paikallisuuden tuomia hyötyjä vaikea saavuttaa
				-Limited impact
					-Client-only ratkaisut eivät yleensä paranna performanssia tai vähennä ulkoliikennettä
						-Torrenteilla usein liian vähän vertaisia
						-Ono vähentää ulkoliikennettä vähemän kuin 1%
							To confirm this in the wild, we show that Ono reduces
							interdomain traffic by less than 1% when connecting to
							live swarms through a large residential ISP.
							
					-Vertaisverkkojen performanssin ja eheyden heikkeneminen
						-Pelkälle lokalisoinnille optimointi heikentää eheyttä
							-Ja monelle käyttäjlle myös performanssia
							-Lokalisointiin perustuvat topologiat muodostavat vähemmän interdomain linkkejä
							
						-Paikalliset vertaiset eivät ole aina nopeampia
							-Verkon heterogeenisyys
							
					-Conflicting interest
						Reducing interdomain traffic reduces
						costs for some ISPs, while it reduces revenue for
						others. We present trace data demonstrating that the
						set of tier-1 ISPs have a strong incentive to strategically
						manipulate BitTorrent peering relationships, creating
						longer paths than necessary and potentially setting
						up an arms race between ISPs.
						
			-BitTorrentissa suuri osa total kapasiteetista tulee pienemmältä käyttäjäkunnalta
				-Käyttäjät eivät ole tasaisesti jakaantuneet globaalisti, vaan sijaitsevat tietyillä alueilla
					-Tällöin paikallistaminen rypästää nämä käyttäjät tietylle alueelle
						-Muiden latausajat kärsivät

			-Tier 1 ISPT hyötyvät ulkoliikenteestä
				-Kuljettavat alemman tason ISPn liikennettä maksua vastaan
				
			-ISPt joilla kaupallisia sopimuksia muiden ISP kanssa voivat uudelleenohjata liikennettä näille ISP oraakkelin yms. avulla
		
		
		
			-Tutkimusmenetelmät
				Introduction
					-Suuren mittakaavan mittaukset BitTorrentin käytöstä
						-Mittaukset kattavat 18370 swarmia (groups of peers downloading the same file) ja 15 miljoonaa uniikkia IPtä

					-By using simultaneous
					measurements of the Internet topology at scale,
					we can determine how often data in each swarm would
					transit the boundaries between ISPs. And indeed, we find
					that, in an idealized setting, most of the interdomain P2P
					traffic in our trace is unnecessary.
					
				-Tutkijat ovat kiinnostuneita tiedostonjakamisen ja ISPn interaktiosta _Internetin tasolla_
					-Käyttävät suuren mittakaavan mittauksia
						-1. Mitkä ISPt ovat osallisena missä swarmissa
							-Ladataan swarmien .torrent metatiedostot
								-Saadaan selville 
									-Total size of the set of files to be downloaded
										-Providing us with the demand (in bytes) of each user in the swarm
										
							-Lähetetään kyselyjä torrenttien trackkereille swarmien jäsenistä
								-Saatiin selville että 14 380 622 uniikkia IPtä
							
						-2. AS reiteistä vertaisten välillä
							-Käytetään mittauksia IPlane-projektista
							
				-3: Testataan simulaatioilla erilaisia paikallisuusskenaarioita yllä olevalle datalle
				-4: Testataan oikeasti
					-Mittaussolmu yhdellä ISPllä
					-Litytään 32 uuteen suorittuun swarmiin ja ladataan tiedostot peräkkäin (huom ei ladata kokonaan vaan ensimmäiset 30 mb)
					-Jokainen lataus tehtiin neljä kertaa eri lokaalisuusmenetelmällä (kaikki käyttävät Azureus-clienttia)
						-1. Lyhin AS reitti
						-2. Minimi latenssi
						-3. Ono
						-4. Muokkaamaton BitTorrent (eli ei paikallisuutta)
					
						From a measurement node connected via Comcast, a
						popular US residential cable ISP, we joined a set of 32
						popular, recently created candidate swarms drawn from
						a popular BitTorrent aggregation website and performed
						back-to-back downloads with instrumented BitTorrent clients.
						
				-5: Osoitetaan, että paikallisuusklusterointi johtaa monelle heikentyneeseen latausnopeuteen
					-Mittauksista poimittiin 100 suosituinta swarmia
					-Simuloivat swarmeille trackkeria joka valitsi 50 satunnaista tai 50 minimum as length vertaista
					-Asettivat vertaisille kapasiteetin prefix-pohjaisesti
						-Kapasiteetit pohjautuivat yli 100 000 bittorrent käyttäjien suosituimmista swarmeista bandwith nopeuksiin vuodelta 2006
						
					-Laskettiin molemmissa tapauksissa jokaisen käyttäjän vertaisten kapasiteetin
						-Tuloksena ratio
							-Jos ratio >1, valittujen vertiasten kapasiteetin keskiarvo kasvoi paikallisuus skenaariolla
							-Jos ratio <1, keskiarvo pieneni 
							
				-Tutkimustulokset
					-3: Paikallisuus vähentää ulkoliikennettä, suuremmat torrentin enemmän, pienemmät torrentit vähemmän
					
					-4
						-Onon latausajat ja ulkoliikenteen määrä ei vähentynyt merkittävästi vanilla Azureukseen verrattuna
						-Onon ja Azureuksen latausaikasuhde oli 1.02
						-Median weighted AS length onolla: 3.99, azureus: 4.02
						
						Although these results might seem contradictory
						given previously published measurements of Ono, the difference
						is simply one of presentation. While 33% of Onorecommended
						peers are within a single AS and download
						rates increase by 31% for recommended paths, Ono’s endto-
						end benefit is limited by the vanishingly small fraction
						of peers it recommends as “local”, even when applied to
						new, popular swarms.
							-Eli siis 33% onon suosittelemista vertaisista sijaitsee saman AS sisällä, ja suositeltujen vertaisten välillä latausnopeukset paranevat 31%
								-Ongelmana se, että onon suosittelemia vertaisia ei ole kovinkaan paljoa
									-Eli siis paikallisuudelle ei ole ensinnäkään aina potentiaalia, tai onon käyttämässä metodissa on puutteita
									
						-Tulokset osoittavat että BitTorrent ei ehkä sovellu paikallisuudelle
							-1. Client-only ratkaisut kärsivat täyden informaation puutteesta samanaikaisista lataajista
								-Tehokkuuden maksimoiminen riippuu vertaisvallinasta globaalilla tasolla, esim. trackereillä
								
							-2. Download and depart heikentää ulkoliikenteen paikallistamista
							-3. Vaikka paikallisia vertaisia olemassa, client todennäköisemmin suosii kaukaisempia vertaisia joilla nopeammat latausnopeudet
					
					-5: Suurimmalla osalla käyttäjistä kapasiteetti oli parempi satunnaisella vertaisvalinnalla

				-Konkreettisia tuloksia bittorrentin tarkastelusta internetissä
				-Syitä:
					-While 33% of Onorecommended
					peers are within a single AS and download
					rates increase by 31% for recommended paths, Ono’s endto-
					end benefit is limited by the vanishingly small fraction
					of peers it recommends as “local”, even when applied to
					new, popular swarms
					
					-Usein ei riittävästi paikallisia vertaisia
						-Download and depart behaviour
						-BitTorrent itsessään ei tarjoa kannustimia
						
					-Vaikka paikallisia vertaisia esiintyisikin, clientti todennäköisemmin suosii kauempia vertaisia joilta mahdollista ladata nopeammin
						-Alla mainittu kaistakapasiteettien epätasaisuus
						
					-Clientti-kohtaisilla ratkaisuilla ei täyttä tietoa samanaikaisista lataajista
						-Tehokkuuden maksimointi riippuu vertaisten matchaamisesta globaalilla tasolla
							-esim. tracker
				
			-Performanssin ja päällysverkon eheyden heikkeneminen
				-Mikäli optimoidaan pelkästään paikallisuutta ajatellen
				-Satunnaisiin topologioihin verrattuna interdomain linkkien määrä on pienempi
				-Paikalliset vertaiset eivät ole aina nopeampia, etenkin käyttäjille jotka ovat alueilla joissa epäsymmetriset laajakaistojen kapasiteetit ovat tyypillisiä
				
				-Oraakkeli-paperissa tutkittiin myös lokaliteetin vaikutusta päällysverkon eheyteen
					-Oli heikompi, mutta ei paljoa
					-Myöskään tämän paperin tutkimusten mukaan ei pitäisi olla aivan niin hirveästi huonompi, mikäli oikein ymmärsin
					-Oraakkeli-paperissa käsiteltiin gnutella-verkkoa, tässä bittorrent-tiedostojen verkkoja
					
			-Jotkut ISPt saavat rahaa interdomain liikenteestä
				-Säästöt muille ISPille tapahtuisi näiden kustannuksella
				-Jossain muussa paperissa joka viittasi tähän sanoi että tämä on ainoa ratkaisematon pointti tms

	Can P2P-Users Benefit from Locality-Awareness?
		Lehrieder, Frank, et al. "Can p2p-users benefit from locality-awareness?." 2010 IEEE Tenth International Conference on Peer-to-Peer Computing (P2P). IEEE, 2010.
		
		34 viittausta
		
		IEEE Tenth International Conference on Peer-to-Peer Computing (P2P). IEEE, 2010
			h-index: 12
			JUFO-taso: 1
			
		Frank Lehrieder
			h: 12
			339 (sitaattien määrä) / 263 (dokumenttien määrä) sitaattia 
			
			University of W¨urzburg
			
		Simon Oechsner
			h: 11
			504 / 439 sitaattia
			
			Universitat Pompeu Fabra Barcelona (Nykyään)
			University of W¨urzburg (Paperin kirjoittamisen aikaan)

		Tobias Hoßfeld
			h: 42 (scholar) / 28 (Scopus)
			i10: 117
			8352 (scholar), 3523 / 2496
			
			University of W¨urzburg
		
		Zoran Despotovic
			h: 27 (scholar) / 15 (scopus)
			i10: 45
			4095, 1493 / 1396
			
			Huawei Technologies Deutschland GmbH, Dusseldorf, Germany (nykyään)
			DOCOMO Communications Laboratories Europe GmbH (paperin aikaan)
			
		Wolfgang Kellerer
			h: 47 (scholar) / 30 (scopus)
			i10: 172
			8359, 3662 / 2967
			
			Technische Universität München (nykyään)
			DOCOMO Communications Laboratories Europe GmbH (paperin aikaan)
			
		Maximilian Michel
			h: 5
			100 / 94
			
			DoCoMo Communications Laboratories Europe GmbH, Munich, Germany

		
		
		-Locality-awareness is considered as a promising approach to increase the efficiency of content distribution by peer-to-peer (P2P) networks, e.g., BitTorrent. 
		-It is intended to reduce the inter-domain traffic which is costly for Internet service providers (ISPs) and simultaneously increase the performance from the viewpoint of the 
		P2P users, i.e, shorten download times. 
		-This win-win situation should be achieved by a preferred exchange of information between peers which are located closely to each other in the underlying network topology. 
		-A set of studies shows that these approaches can lead to a win-win situation under certain conditions, and to a win-no lose situation in most cases. 
		-However, the scenarios used assume mostly homogeneous peer distributions and that all peers have the same access speed. 
		-This is not the case in practice according to several measurement studies. 
		-Therefore, we extend previous work in this paper by studying scenarios with real-life, skewed peer distributions and heterogeneous access bandwidths of peers. 
		-We show that even a win-no lose situation is difficult to achieve under those conditions and that the actual impact for a specific peer depends heavily on the used 
		locality-aware peer selection and the concrete scenario. 
		-Therefore, we conclude that current proposals need to be refined so that users of P2P networks can be sure that they also benefit from their use. 
		-Otherwise, a broad acceptance of the concept of locality-awareness in the user community of P2P networks will not take place.
		
		
		In contrast to the aforementioned work, we show in this paper that a win-no lose situation is difficult to achieve under the real-life conditions we observe in today’s 
		Internet
		
		Artikkelin pointit:
			-Paikallisuudesta hyötyvät lähinnä ISPt, p2p käyttäjät eivät (välttämättä) hyödy
				-Ratkaisut lupaavat win-win-tilanteita, mutta jopa win-no lose tilannetta on vaikeaa saavuttaa nykyisillä ratkaisuehdotuksilla
				
			-Tarkastelevat paikallisuutta erilaisessa skenaariossa kuin muut
				-Skewed peer distributions
					-Joissain verkoissa on paljon vertaisia ja joissain vähän
					-Ei siis oleteta että vertaiset jakautuneet tasaisesti
					-Käytettyjen lähteiden mukaan tälläinen tilanne on tyypilinen
					
				-Vertaisilla on eri yhteysnopeudet
				
				-Näillä kahdella tekijällä on suuret vaikutukset paikallisuuden toimivuuteen
				
			-Nykyiset paikallisuusratkaisut "introduce unfairness in the distribution process"
				-Joskus jopa vähentävät jakamisprosessin tehokkuutta
				-Eli paikallisuus haittaa käyttäjiä
				
			-Ratkaisuehdotuksiin siis tarvitaan parannuksia
				-Jos ei paranneta, niin p2p sovellukset kiertävät näitä paikallisuusominaisuuksia (esim. oraakkelia) mm. enkryptauksilal / käyttäjät eivät käytä paikallis-clienttejä
				
			-Käyttäjien suostumus ehdottomasti tarvitaan kaikkiin potentiaalisiin paikallisuusratkaisuihin
				
			-Tulokset pähkinänkuoressa
				-1. Nykyisillä paikallisuusratkaisuilla vaikea saavuttaa yleistä win-no lose tilannetta
				-2. Nykyiset ratkaisut kasvattavat vertaisverkkojen epäreiluutta, ja joskus jopa yleisesti heikentävät jakamisen tehokkuutta (=keskimäärin hitaammat latausnopeudet)
				
				
				
		-Artsassa suht hyvin selitetty BitTorrentin perusteita (lähteihin perustuens)
		
		-Tutkimukset
			-Testataan BitTorrentilla kahta paikallisuusratkaisua
				-Biased peer/neighbour selection
					-Testeissä kysellään trackkerilta paljon suurempaa vertaislistaa (1000) mitä normaali bittorrent pyytää (50)
					-Otetaan paikallisia naapureita kunnes rBPS:sän max paikalliset naapuriraja (huom. ei kaikki naapurit) saavutetaan, tai paikallisia naapareita ei enää löydy
						-Vissiin tässä tapauksessa 90% paikallisia naapureita max
						
				-Biased peer unchoking
					-Suositaan paikallisia naapureita
					
			-Simulaatio
				-Yksi swarmi, jossa jaetaan 154.6 mb kokoista videotiedostoa
				-Swarmi sisältää keskimäärin 100-200 vertaista
					-Vastaa keskikokoista swarmia
						According to a measurement study of real BitTorrent
						swarms [6], these are typical values for medium-sized swarms
						observed in practice.
					
				-Koko simulaatioverkko koostuu 20 ASstä ja yhdestä transit-ASstä
					-Transit-AS sisältää vain alkuperäisen uploadaajan, joka menee offline 1h jälkeen
					-ASsät heterogeneisiä, eri määrä käyttäjiä
						This
						is motivated by the fact most of the peers participating in a
						swarm are usually located in a small number of ASes [5],
						[6].
					
					-Yhteysnopeudet myös heterogeenisiä
						Measurements in [7] show that the peers in a swarm can be
						clustered according to their access speeds.
						
						-Huom! Testaavat myös homogeenisillä nopeuksilla
						
			-Koe 1: Homogeeninen vs heterogeeninen skenaariot
				-A
					-Vertaiset homogeenisesti jakautuneet homogeenisillä nopeuksilla
					-Keskimääräiset latausajat eri AS:sien vertaisilla eivät juurikaan eronneet
					
				-B
					-Vertaiset heterogeenisesti jakautuneet heterogeenisillä nopeuksilla
					-ASsillä kuitenkin suunnilleen samat keskiverto latausnopeudet
						-AS:n sisäisitä vertaistaisista 50% nopeita, 50% hitaita
				
					-Latausajat eroavat
						-Osa hyötyi paikallisuudesta, osa ei
						
					-Kuvaaja (HUOM: Mitä pienempi k, sitä suurempi AS)
						-BU hyödytti suurempia AS, mutta ei pienepiä
							-Pääosin hitaampi kuin normi bittorrent
							
						-BNS antoi pienemmille ASsille suht saman latausnopeudet kuin normi
							-Suuremmat ASt saivat vähän hitaammat latausnopeudet
							-Keskikokoiset saivat vähän nopeamman
							
						-BNSBU hyödytti suuria AS
							-Pienemmät ja keskikokoiset AS saivat paljon hitaamman
						
					-Ei ole siis yleistä no-lose tilannetta kummallekkaan menetelmälle
					
				-C
					-Vertaiset heterogeenisesti jakautuneet homogeenisillä nopeuksilla
					-BNS pärjää huonommin suuremmilla verkoilla, miksi?
						-This effect seems counter-intuitive,
						but can be explained when considering the composition of
						the neighbor set of the peers. With BNS, peers in AS 1
						have a higher number of neighbors than peers in other ASes
						(Fig. 4(b)) and therefore also more peers which are interested
						in downloading from them (Fig. 4(c)). The reason is that peers
						in AS 1 are not only contacted by others peers in AS 1 but
						also with a high probability by peers in small ASes because
						BNS fills the neighbor set with random peers if a sufficient
						number of local peers is not available. As a consequence of
						the increased number of peers interested in a peer in AS 1,
						its upload capacity is shared among a larger set of peers and
						every one of them receives a smaller portion. Finally, peers in
						AS 1 have a large number of local neighbors and download
						almost exclusively from them. Hence, a peer in AS 1 receives
						less upload capacity from the swarm than other peers.
						
					-Ulkoliikenne vähenee AS:n koon kasvatessa
						If such an AS belongs to a Tier2 or Tier3
						ISP which is charged by either its uploaded or downloaded
						traffic or the maximum of both, this translates into higher cost
						savings.
						
					-Kuvaaja
						-BU mahdollistaa suuremmille AS nopeammat nopeudet, hitaammat pienemmille
						-BNS suurimmilla verkoilla hidas, muilla vähän nopeampi kuin perus bit-torrent
						-BNSBU about samat setit kuin BU
						
				-D
					Vertaiset homogeenisesti jakautuneet heterogeenisillä nopeuksilla
						-1. Skenaario = Nopeat vertaiset omissa AS, hitaat vertaiset omissa AS
							-Mukailee realistista tilannetta jossa jotkut ISPt omaavat parempaa teknologiaa
							
							-Keskimäärin bittorrentin oma takaa nopeammat latausnopeudet 
								-Hitaat vertaiset eivät hyödy paikallistamisesta, hidastuvat
								-Nopeat vertaiset hyötyvät paikallistamisesta
								
								-Paikallistaminen lisää epäreiluutta
									-Mutta toisaalta onko vertaisilla jotka uploadaa nopeasti myös oikeus ladata nopeasti
									
								-Nopeiden hyödyt ei näy keskimäärässä niin paljon koska ne myös lähtevät nopeammin pois swarmeista koska saavat ladattua nopeammin
							
						-2. Skenaario = Nopeat ja hitaat vertaisesti jakautuneet tasaisesti
							-Mukailee realistista tilannetta jossa yksittäinen ISP tarjoaa eri nopeuksia
						
							-Keskimääräisesti latausnopeudet eivät juurikaan eroa toisistaan eri menetelmillä
								-hitaat vertaiset
									-BNS about sama kuin bittorrent
										-BU ja BUBNS nopeampia
										
								-Nopeat vertaiset
									-BNS ja bittorrent about sama
										-BU ja BUBNS hitaampia
										
							-Toisin kuin hitaat vs nopeat skenaariossa, tässä tapauksessa epäreiluus väheenee
								-nopeampien käyttäjien kustannuksella
										
								-In contrast, the mechanisms including BU lead to shorter
								download times for slow peers and longer download times
								for fast ones. This is mainly owed to the fact that the fast
								peers allocate their optimistic unchoke slots mostly to local
								neighbors which might have only a slow uplink. This prolongs
								the process of finding fast but remote peers. Free-riding may be
								a bit more attractive in those scenarios since the AS affiliation
								of a peer is considered in the unchoking process in addition
								to the upload speed of the peer.
									-For the swarm as a whole, the results can be interpreted as a
									fairer distribution of the upload capacity. However, the peers
									that contribute more resources have less incentives to do so
									if they are not rewarded. We conclude that in this scenario
									BU and BNSBU lead to more balanced download times while
									the contrary is true in the scenario “fast vs. slow ASes”.
									
								-This
								shows that the actual bandwidth distribution of peers has a
								significant impact on the performance of locality-mechanisms
								experienced by the user
								
				Yhteenveto:
					A: No-lose (mutta ei realistinen)
					B: Pääasiassa nopeammat hyötyivät (paitsi pelkällä BNS), pienemmät kärsivät
						-BU: Suuret nopeita, muilla hitaampi kuin normi
						-BNS: Suuret vähän hitaampia, keskikokoisilla nopeampi, pienillä about sama kuin normi
						-BNSBU: Suuremmat nopeampia, muut hitaampia
						
					C: Muuten sama kuin B, paitsi BNS hyödytti yleisesti myös pienempiä AS
						-BU: Suuret nopeita, muut hitaampia
						-BNS: Suuret hitaampia, muilla nopeampi 
						-BNSBU: Suuret nopeita, muut hitaampia (about samat setit kuin BU)
						
					D.1: Nopeat hyötyvät, keskimäärin kuitenkin kaikki hidastuvat
						-Kaikki yleisesti: Paikallisuusmenetelmät hieman hitaampia kuin normi bittorrent
						-Hitaat vertaiset: Paikallisuusmenetelmät vaihtelevasti hitaampia kuin normi
						-Nopeat vertaiset: Paikallisuusmenetelmät hieman nopeampia kuin normi bittorrent
						
					D.2: Hitaat hyötyvät, nopeat hidastuvat, yleisesti ei juurikaan eroa normi bittorrenttiin
						-Kaikki yleisesti: ei juurikaan eroa 
						-Hitaat vertaiset: BU ja BNSBU nopeuttaa suht paljon, BNS ei hirveästi
						-Nopeat vertaiset: Paikallisuusmenetelmät jonkin verran hitaampia kuin normi
								
			-Koe 2: Eri parametrit paikallisuusskenaarioille
				-Pienempi preferenssi paikallisuudelle tasoittaa keskimääräisiä latausnopeuksia
					-Ulkoliikenteen säästöjen kustannuksella
					
				-Testataan arvoja 0.5 ja 0.9 BU, BNS ja BNSBU
				
				-BU
					-Latausajat keskimäärin pienemmät 0.5
						-Pienissä AS 0.9 nopeampi
						
					-0.5 ulkoliikenne kasvaa pienemmillä AS
					
					With lBU = 0.5, i.e.,
					a less strict preference of local peers, the average download
					times are more uniform over the individual ASes, especially
					for BU alone. For the combination of BNS and BU, the
					negative effect of BNS on the large ASes, described in
					Sect. IV-C, is offset less with this parameter. Consequently,
					the mean download times are uniform for the small ASes, but
					the large ASes are still at a disadvantage.
					
					While a lower preference for local peers can lead to more
					balanced average download times, it also influences the achiev-
					able traffic savings. Fig. 8(b) shows, again on the example of
					the downlink traffic of ASes, that the used bandwidth increases
					with a lower degree of locality-awareness. Thus, the parameter
					lBU can be used to directly influence the trade-off between
					unfairness in the swarm and cost savings by traffic reduction.
					
				-BNS
					-Latausajat pienenevät keskimäärin 0.9
						-Suuremmilla AS vähän paremmat nopeudet
						
					-0.5 ulkoliikenne kasvaa pienemmillä AS
					
					We
					observe that the significant increase in the download times for
					the largest AS vanishes for lBNS = 0.5, i.e., a lesser degree
					of locality. With BNS alone, the download times are fairly
					distributed, while the combination of BNS with BU shows the
					heavy unfairness of the BU mechanism described earlier. This
					is due to the fact that in this experiment, lBU = 0.9.
					
					Again, the better fairness achieved by more conservative
					parameters for locality-awareness is paid for by reduced
					savings in inter-AS traffic, cf. Fig. 9(b). In particular, the
					incoming inter-AS traffic of AS 1 increases by about 30%
					(for BNS alone) or 25% (for BNSBU) when lBNS = 0.5 is
					used instead of lBNS = 0.9. Similarly, but not shown here,
					the outgoing inter-AS traffic increases in comparison with the
					scenario where lBNS = 0.9.
					
				These results show that more conservative parameters might
				mitigate the negative effects of locality-awareness in terms of
				unbalanced average download times but reduce simultaneously
				the amount of inter-AS traffic that can be saved.
								
		The main difference
		of Ono to the approaches described above is that it does not
		rely on a central entity which guides the inclusion of peers in
		the neighbor set of a peer. Instead, it uses the similarity of the
		redirection ratio of CDN servers as a metric describing how
		close peers are.
		
		In [12], the authors present three pitfalls for ISP-friendly
		P2P design: limited impact, reduced performance and robustness,
		and conflicting interests. They show that localityaware
		peer selection has no impact when there are only very
		few peers of a swarm in the same AS.
			The difference to
			this study is that we focus on the users’ point of view and
			simulate a BitTorrent swarm with detailed peer behaviors, e.g.,
			the choke algorithm with the tit-for-tat policy. In addition, we
			simulate the concrete implementations of locality-awareness
			mechanisms currently under discussion, i.e., BNS, BU, and
			the combination of both. In this way we show that different
			implementations lead to a different application performance,
			which is neglected in [12], and explain which users benefit
			in which scenarios by using BNS, BU, or the combination of
			them.
				
		Related to this, we formulate an interesting question we
		plan to investigate in more detail. Differences in user performances
		may lead to different users employing different locality
		promotion mechanisms and even switching between different
		schemes in the course of application operation. It is unclear
		how the entire system behaves under these circumstances.
		
		
	Pushing Bittorrent Locality to the Limit	
		Le Blond, Stevens, Arnaud Legout, and Walid Dabbous. "Pushing bittorrent locality to the limit." Computer Networks 55.3 (2011): 541-557.
		
		127 viittausta
		
		Computer Networks
			H-Index: 119
			JUFO-taso: 2
			
		-Ilmeisesti tekninen raportti? (Traffic Localization for P2P-Applications: The ALTO Approach mukaans) 
			
		More recently, [9] investigated what extent of locality
		is beneficial to P2P-applications in general. Clearly, some
		degree of inter-ISP links needs to be preserved in order
		to guarantee robustness and prevent network partitioning
		in the case of node failure. The authors define locality as
		the percentage of intra-ISP connections over all connections
		with respect to the average peer. Their study concludes that
		compared to the regular BitTorrent protocol up to two orders
		of magnitude can be saved on inter-ISP traffic if locality is
		used. Further, they show in a test environment with modified
		BitTorrent implementations that the capacity of the initial
		content-seed has strong implications on the potential benefit
		of employing locality-biased neighbor selection. (Traffic Localization for P2P-Applications: The ALTO Approach)
			
		Abstract
			Peer-to-peer (P2P) locality has recently raised a lot of interest in the community. Indeed,
			whereas P2P content distribution enables financial savings for the content providers, it dramatically
			increases the traffic on inter-ISP links.
			To solve this issue, the idea to keep a fraction of the P2P traffic local to each ISP was introduced
			a few years ago. Since then, P2P solutions exploiting locality have been introduced.
			However, several fundamental issues on locality still need to be explored. In particular,
			how far can we push locality, and what is, at the scale of the Internet, the reduction of
			traffic that can be achieved with locality?
			In this paper, we perform extensive experiments on a controlled environment with up to
			10,000 BitTorrent clients to evaluate the impact of high locality on inter-ISP links traffic
			and peers download completion time.
			We introduce two simple mechanisms that make high locality possible in challenging
			scenarios and we show that we save up to several orders of magnitude inter-ISP traffic
			compared to traditional locality without adversely impacting peers download completion
			time. In addition, we crawled 214,443 torrents representing 6,113,224 unique peers spread
			among 9605 ASes. We show that whereas the torrents we crawled generated 11.6 petabytes
			of inter-ISP traffic, our locality policy implemented for all torrents could have
			reduced the global inter-ISP traffic by up to 40%
			
		Artikkelin pointit
			-Kuinka pitkälle paikallisuus voidaan viedä ennenkuin se haittaa päällysverkon eheyttä?
				-Eli jos verkko ei ole tarpeeksi eheä = latausajat kärsivät
				
			-Kuinka paljon liikennettä pystytään vähentämään globaalilla Internet-skaalalla paikallisuuden avulla
				-Inter-ISP linkkien säästöt
				-Eli kuinka paljon ISPt pystyvät hyötymään
			
			-Kysymyksiä tutkitaan BitTorrent-testeillä
				-10 000 bittorrent clienttiä hallitussa ympäristössä
					-Sektiot 4-5
					
				-Käyttämällä oikeaa dataa joka kerätty 214,433 torrentista, 6,113,224 uniikista vertaisesta ja 9605 ASstä (verkosta)
					-Sektio 6
			
			-Tulokset
				-BitTorrentissa paikallisuutta pystytään puskemaan pidemmälle kuin luultiin
					-Vähentää inter-isp-liikennettä moninkertaisesti				
					-Vertaisten latausajat pysyvät alhaisina
					-Finally, we propose new strategies to
					improve the efficiency and robustness of our locality
					policy on challenging scenarios defined from real
					world torrents.
					
				-214,433 torrentin skaalalla, ISPt hyötyvät paikallisuudesta paljon
					-Korkea paikallisuus pystyi säästämään 40% verkkojenvälisestä liikenteestä
						-P4P tutkimuksessa raportoitiin 60% säästöt, mutta käytetty tutkimusmenetelmä oli eri
							-P4P tehtiin ISP-skaalalla, tässä paperissa tehtiin Internet-skaalalla
							
				-Our main findings are that a small number of inter-ISP
				connections will dramatically reduce the overhead and
				keep the slowdown low independently of the torrent size,
				the number of peers per ISP, the upload capacity of peers,
				or the churn. We have introduced two new strategies
				called Round Robin and partition merging that make the
				use of a small number of inter-ISP connections feasible
				for real torrents of the Internet.
					-However, we do not advocate for such small number of
					inter-ISP connections in real deployments. Indeed, selecting
					a very small number of inter-ISP connections is a design
					choice. For BitTorrent client companies, it is not an
					option to increase the peers slowdown, even by just a
					few percents, in order to further reduce the load on inter-
					ISP links, because it will lead to a decrease in the number
					of users of this BitTorrent client. Conversely, content
					providers, might want to optimize the inter-ISP traffic in
					order to convince ISPs to do not block their BitTorrent
					traffic
			
			-Paperin paikallisuusmenetelmä on pikemminkin tarkoittu tutkimuksen käyttöön, eikä niinkään implementoitavaksi ratkaisumalliksi
				-Kuitenkin identifioivat 2 tärkeää strategiaa joita suositellaan edes harkittavaksi mikäli aikoo tehdä paikallisuusratkaisun
					-Round robin
						-Kun valitaan vertaista inter-ISP naapuruussuhteeseen, ensiksi valitaan ISP round robinilla ja ISPn sisältä valitaan satunnaisesti vertainen
							-Jos valinta tehdään pelkän satunnaisen vertaisen perusteella, suuremmat verkot (jotka sisältävät enemmän vertaisia) saavat enemmän tulevaa
							liikennettä, mikä nostaa suurten verkkojen Inter-ISP-liikenteen määrää (toteamus vahvistetaan section 6:sessa)
							-Sektioissa 4 ja 5 oletetaan ISPillä olevan homogeeninen määrä vertaisia, joten tällöin round-robin ja satunnainen valinta ovat ekvivalentteja
								-Sektiossa 6 testataan round robinia
								
					-Partition merging
						-Jos inter-isp yhteyksiä on vähän, on mahdollista että syntyy tilanne jossa torrentissa esiintyy partitioita
							-if peers who have inter-ISP connections leave the
							torrent and no new peer joins the ISP, then this ISP will
							form a partition.
						
						-Vertaiset lähettävät viestin seurantapalvelimelle mikäli naapurivertaiset eivät omaa jotain osaa sisällöstä
							-Pyytävät uutta inter-isp linkkiä
							-Yksityiskohtia paprussa
								-Trackerkin tekee jotain oleellista
							
							-Potentiaalinen yökkäyksen kohteena
								-Testi tehty kuitenkin hallitussa ympäristössä
								-Paprun mukaan ei pitäisi olla liian vakava ongelma
								
							-As this strategy has no impact on our experiments when
							there is no partition, we present results in Sections 4 and 5
							without the PM strategy unless explicitly specified, that is
							when there is a partition and that the PM strategy changes
							the result. We perform a detailed analysis of the PM strategy
							in Section 6.
							
				-Tracker voisi tehdä yhteistyötä esim p4p kanssa.
				
			Second, the dynamics
			of BitTorrent is subtle and not yet deeply understood. Running
			simulations with a simplified version of BitTorrent
			may hide fundamental properties of the system.
				-Ota tämä huomioon jos paperit testaavat yksinkertaistetuilla BitTorrenteilla
				
			-Sektion 5 (ja ehkä 4) tulokset
				-First, we remind that our main goal in this section was
				to minimize the overhead. We achieved up to three orders
				of magnitude reduction in the overhead compared to the
				BitTorrent policy
					-There is a price to pay for such a huge reduction,
					which is an increase by at most 30% in the slowdown.
						-Tutkijat kuitenkin pitävät tätä kohtuullisena vaihtona
						
				-Second, the increase we report on the slowdown is the
				worst one that can be achieved. Indeed, all our experiments
				(except the ones presented in Section 5.3) are performed
				without congestion in the network. However, we
				have shown in Section 5.3 that in case of congestion, our
				locality policy can reduce the slowdown compared to the
				BitTorrent policy. 
					-Therefore, on a real network, the slowdown
					with our locality policy is likely to be equivalent or
					even better than the one of the BitTorrent policy.


			-In the remaining of this section,
			we focus on inter-ASes rather than on inter-ISPs traffic
			for two reasons. First, the information to perform the mapping
			between IP addresses and ASes is publicly available,
			whereas there is no standard way to map IP addresses or
			ASes to ISPs. Second, ISPs may consist of several ASes.
			There is no way to find where an ISP wants to keep traffic
			local
			
			-Indeed, Asian torrents
			are usually large and, due to the geographical locality
			inherent to such torrents, spread among fewer ASes than
			an average torrent. Therefore, Asian torrents have a larger
			potential for locality than other torrents

			-Sektion 6 tulokset
				-Tarkastellaan Inter-AS eikä Inter-ISP
				-In Section 5, we performed experiments with a homogeneous
				number of peers per AS. However, real torrents
				have an heterogeneous number of peers per AS, which
				may adversely impact the overhead reduction we observed
				with a small number of outgoing inter-ISP connections.
				
				-Tarkasteltavat torrentit
					-Suositun englanninkielisen elokuvan torrent
						-9844 vertaista 1043 AS:sä, suurin AS 386 vertaista
						
					-Italiankielisen elokuvan torrent
						-4819 vertaista 211 AS:sä, suurin AS 2415 vertaista
						-Vähenmmän total AS kuin englanninkielisessä suositussa elokuvassa
							-Tukee should fear paperissa esitettyä väitettä että lokaalisuutta esiintyy sisällön kielestä johtuen
						
					-Pelin torrent
						-996 vertaista 345 AS:sä, suurin AS 31 vertaista
						-Edustaa keskikokoisia torrentteja jolla vähän potentiaalia paikallisuussäästöihin, sillä sen AS:sissä on keskimäärin vähän vertaisia
						
				-In this section, we want to estimate the benefits our
				locality policy would have had on the torrents we crawled.
				In our crawl, 117,677 torrents and 6643 ASes cannot benefit
				from a locality policy, because there is at most one peer
				per AS per torrent. However, we want to show that despite
				most of the torrents and ASes cannot benefit from a locality
				policy, the implementation of a locality policy at the scale
				of the Internet would be highly beneficial.
					-Huom loput torrentit ja ASsät hyötyivät paikallisuudesta
						-Total torrents: 214,443
						-Total AS: 9605 AS
					
					-Eli usein ASät eivät hyödy paikallistamisesta'
						-Ota huomioon paprussa
					
				-Fig. 11 lower plot shows that even with a small number
				of peers per AS, the overhead savings are already high. For
				instance, with 5 peers per AS, the overhead with our locality
				policy is 40% lower than the one with the BitTorrent
				policy.
				
				-We see that the cumulative inter-AS traffic with the BitTorrent
				policy is 11.6 petabytes, and that with 4 outgoing inter-
				AS connections it is 7.3 petabytes (and 7 petabytes
				with the PM + RR strategies), which is only 41% larger
				(35% with PM + RR) than what the ideal policy achieves.
				
		-Ottivat Pitfalls-paperin huomioon
			-Ei kuulemma päde tähän tutkimukseen, sillä
				-Pitfalls väitti että clientside only paikallisuus ei välttämättä toimi
					-Tämän paperin ratkaisu on seurantapalvelinpohjainen
					
				-Pitfalls väitti että vertaisverkon eheys kärsii
					-Paperin tekijät ottivat verkon eheyden säilyttämisen huomioon




Tarkista ohjaajalta
	HPTP: Relieving the Tension between ISPs and P2P. 2007
		Shen, Guobin, et al. "HPTP: Relieving the Tension between ISPs and P2P." IPTPS. 2007.
			International Workshop on Peer-to-Peer Systems 
			
		International Workshop on Peer-To-Peer-System
			-Ei löytynyt H-indexia yms.
			
		PAPERI EI SCOPUKSESSA
			
		Guobin Shen
			h: 44
			i10: 93
			
			6094 viittausta
			
			Zepp Labs, Inc. (nykyään)
			Microsoft Research Asia, Beijing, P.R.China (tekstin aikaan)
			
		
		114 viittausta
		
		Abstract
			-Measurement-based studies indicate that there is a severe ten-sion between P2P applications and ISPs. 
			-In this paper, we pro-pose a novel HTTP-based Peer-to-Peer (HPTP) framework torelieve this tension.  
			-The key idea is to exploit thewidely de-ployed web cache proxiesof ISPs to trick them to cache P2Ptraffic. 
			-This is achieved via a process we refer to as “HTTPi-fying”:  
				-we segment (if necessary) large P2P files or streamsinto  smaller  chunks,  encapsulate  and  transport  them  usingthe HTTP protocol so that they are cacheable. 
				
			-We outline thedesign of several key tools of the proposed HPTP framework– HTTPifying, cache detection and usability test tools, anddescribe a cache-aware tree 
			construction (CATC) protocol fordelivering P2P streaming traffic as an example to showcasethe HPTP framework.   
			-Simulation results demonstrate thatHPTP can lead to significant performance improvement. 
			-Weargue that the HPTP framework will benefit both ISPs andend users (P2P as well as normal web users) by significantlyreducingnetwork overloadcaused by repetitive P2P 
			traffic.
			
		Can ISPs and P2P Users Cooperate for Improved Performance?
			P2P traffic
			often starves other applications like Web traffic of bandwidth [8],
			and swamps the ISP network. 
			
			Yet another system [8] proposes to use caching to relieve the tension between ISPs and P2P systems.
			
		There are several possibilities on how to control the traffic patterns
		of P2P by ISPs. One proposal is to deploy P2P caching devices
		to cut down bandwidth consumed by P2P applications (e.g., [8,
		12, 16, 27, 29, 32, 36]) (P4P: Provider Portal for Applications)
			
		Artikkelin pointti
			-Hyväksikäytetään ISPiden HTTP-cacheja kapsuloimalla P2P-chunkit HTTP-paketteihin
				-Simulaatiotestataan
				-Tulokset vaikuttavat lupaavilta
					-Hyödyttää sekä ISP että P2P
					
			-Googlen perusteella ei vissiin otettu käyttöön
				-Mielenkiintoinen ratkaisu tosin




			-Ongelmia P2P-välimuistien käyttöönotossa
				-Jokainen P2P-sovellus käyttää omia porttejaan
					-P2P-välimuistien täytyy tukea lukuisia protokollia
						-Tosin vain osa näistä suosiossa (etenkin nykyään (tähän viittaus että bittorrent niin ja niin monta % kaikesta p2p liikenteestä)), joten voi olla feasible
				
				-Vaatii suuria investointeja
					Secondly, extra, possibly huge, investment is required
					for the equipment and facility purchase and also the
					administrative cost.






	
	
	
IMP: ISP-Managed P2P 2010
	James, Shakir, and Patrick Crowley. "Imp: Isp-managed p2p." 2010 IEEE Tenth International Conference on Peer-to-Peer Computing (P2P). IEEE, 2010
	
	15 viittausta 
	
	Abstract
		-Internet Service Providers (ISPs) have failed to independently reduce the cost peer-to-peer (P2P) traffic. 
		-Traffic- throttling devices increase user download times, and caches store content that may infringe copyright. 
		-We propose ISP-Managed P2P (IMP): a transparent peer-discovery service that returns peers favorable to ISPs. 
		-Unlike similar services, IMP does not require the direct support of developers who have no incentive to cooperate. 
		-This paper covers the design, implementation, and experimental evaluation of our IMP prototype, which reduces costly, cross-ISP traffic by eight times without 
		significantly increasing user download times.



	
	

	
	

				
		

ARE FILE SWAPPING NETWORKS CACHEABLE? CHARACTERIZING P2P TRAFFIC 
	Leibowitz, Nathaniel, et al. "Are file swapping networks cacheable? Characterizing P2P traffic." Proc. of the 7th Int. WWW Caching Workshop. 2002.
	
	165 viittausta
	
	Abstract
		Peer-to-Peer  (P2P)  file-sharing  traffic  on  the  Internet  has  grown to rival that of traditional web surfing (HTTP). This paper  measures  and  analyzes  the  
		characteristics  of  this  relatively new type of traffic and investigates the feasibility of caching it 
		
	There are several possibilities on how to control the traffic patterns
	of P2P by ISPs. One proposal is to deploy P2P caching devices
	to cut down bandwidth consumed by P2P applications (e.g., [8,
	12, 16, 27, 29, 32, 36]) (P4P: Provider Portal for Applications)
	
Traffic localization for P2P-applications: The ALTO approach
	122 viittausta
	
	Seedorf, Jan, Sebastian Kiesel, and Martin Stiemerling. "Traffic localization for P2P-applications: The ALTO approach." 2009 IEEE Ninth International Conference on Peer-to-Peer Computing. IEEE, 2009
	
	2009 IEEE Ninth International Conference on Peer-to-Peer Computing. IEEE
		h-index: 13
		
	Jan Seedorf
		h-index: 10
		
		37 (tehdyt paperit) / 291 (viittausten määrät)
		
		Hochschule für Technik Stuttgart, Stuttgart, Germany 
	
	Sebastian Kiesel
		h-index: 3
		
		4 / 101
		
		NEC Deutschland GmbH, Dusseldorf, Germany

	Martin Stiemerling
		h-index: 7
		
		22 / 240
		
		Hochschule Darmstadt, Darmstadt, Germany
	
	Abstract
		Today, most P2P applications do not consider
		locality on the underlying network topology when choosing
		their neighbors on the P2P routing layer. As a result, participating
		peers may experience long delays and peers’ ISPs
		suffer from a large amount of (costly) inter-ISP traffic. One
		potential solution to mitigate these problems is to have ISPs
		or third parties convey information regarding the underlying
		network topology to P2P-clients through a dedicated service.
		Following this approach, the IETF has recently formed an
		Application Layer Traffic Optimization (ALTO) working group
		for standardizing a protocol to enable P2P applications to
		obtain information regarding network layer topology.
		This paper comprises the problem space for such an ALTO
		approach, taking into account recent developments in the
		IETF ALTO Working Group. In particular, we will describe
		requirements for an ALTO protocol identified in the IETF,
		concrete protocols which have been proposed so far, and the
		overall challenges. In addition, we will discuss related issues
		such as privacy considerations, the relationship of an ALTO
		service with existing caching solutions, discovery mechanisms
		for an ALTO service, and security considerations.
		
	Artikkelin pointit
		-Alussa katsaus ratkaisuista
		-Kokoavat haasteita ja suunnitteluongelmia ALTO-ratkaisuun
		-Esittelevät ALTO working groupin ja sen suunnitteleman ratkaisu
			-Kävin kattommassa niiden sivut, ilmeisesti pelkkiä white-paper tyylisiä vertaisarvioimattomia dokumentteja
				
		-Alto-ratkaisu
			-Palvelu jota P2P-sovellukset voisivat käyttää optimaaliseen vertaisvalintaan
			-Palvelu lähettää tietoa vertaisille, saa tietoa ISP:ltä
			
		-HUOM!!!! Tutkijat eivät ilmeisesti saaneet aikaan mitään konkreettista
			-Paperista ei ainakaan löytynyt mitään testejä ratkaisulle
		
		
	
A bottleneck free model for p4p
	6 viittausta
	
	-Ei ehkä niin oleellinen
	
A game–theoretic analysis of the implications of overlay network traffic
on ISP peering
	37 viittausta
	
A Stochastic Analytical Modelling Framework on ISP-P2P Collaborations in Multi-domain Environments
	4 viittausta
	
BufferBank: A distributed cache infrastructure for peer-to-peer application
	9
	
	-2014
	

Cache Bandwidth Allocation for P2P File Sharing Systems to Minimize Inter-ISP Traffic	
	20
	
	-2014
	
Cache Capacity Allocation for BitTorrent-like Systems to Minimize Inter-ISP Traffic
	13
	
	-2012
					
					
Cache-to-Cache: Could ISPs Cooperate to Decrease Peer-to-Peer Content Distribution Costs?
	66
	
	-2011
	-IEEE Transactions on Parallel and Distributed Systems 22.9
	
Caching for BitTorrent-like P2P Systems: A Simple Fluid Model and its Implications
	19
	
	-2011
	
Deep Diving into BitTorrent Locality
	80
	
	-2010
	-ACM SIGMETRICS Performance Evaluation Review 38.1 
	
	Cuevas et al. [24] is by several aspects close to our work.
	Indeed, the authors also collected a large BitTorrent trace
	and explored the impact of high locality. However, their
	work significantly differs by other aspects. The core of their
	evaluation study is a mathematical model, whereas we
	performed extensive large scale experiments. They specifically
	focused on peers upload distribution, whereas we
	focused on the systematic evaluation of fundamental
	parameters like torrent size, or inter-ISP bottlenecks. Finally,
	they do not explore the second question of this work
	What is, at the scale of the Internet, the reduction of traffic
	that can be achieved with locality? In summary, our work
	is complementary to the one of Cuevas et al., as it validates
	some of the assumptions they made in the modeling of Bit-
	Torrent locality, in particular the good piece diversity with
	locality, which is fundamental to observe stratification in
	their model. (Pushing bittorrent locality to the limit)
	
Detecting BitTorrent Blocking <------------- KATO TÄÄ
	Dischinger, Marcel, et al. "Detecting bittorrent blocking." Proceedings of the 8th ACM SIGCOMM conference on Internet measurement. 2008.
	
	131 viittausta
	
	Abstract
		Recently, it has been reported that certain access ISPs are surreptitiously
		blocking their customers from uploading data using the
		popular BitTorrent file-sharing protocol. The reports have sparked
		an intense and wide-ranging policy debate on network neutrality
		and ISP traffic management practices. However, to date, end users
		lack access to measurement tools that can detect whether their access
		ISPs are blocking their BitTorrent traffic. And since ISPs do
		not voluntarily disclose their traffic management policies, no one
		knows how widely BitTorrent traffic blocking is deployed in the
		current Internet. In this paper, we address this problem by designing
		an easy-to-use tool to detect BitTorrent blocking and by presenting
		results from a widely used public deployment of the tool.
	
	Network oblivious sharing increases costs for ISPs. As
	demand increases on transit links, backbone ISPs are forced
	to invest in increasing capacity. These costs are passed
	on to edge ISPs that pay transit costs proportional to the
	amount of interdomain traffic they generate. Many customer
	facing ISPs, however, offer flat-rate pricing, forcing
	them to absorb the costs externalized by P2P file sharing.
	In response, some ISPs have elected to rate-limit or simply
	block these “problem” protocols [4, 14], in turn leading
	developers into an arms race to evade restrictions. (Pitfalls for ISP-Friendly P2P Design)
	
	As a result of
	this tension, some ISPs have started to
	traffic shape and even block BitTorrent
	traffic (Peer-to-peer-systems)
	
Efficiency of Caches for Content Distribution on the Internet
	28
	
	-2010
	
Improvement of bittorrent performance and inter-domain traffic by inserting isp-owned peers
	33
	
	-2009
	-Tallennettu pdf ei avaudu
	
Improving User and ISP Experience through ISP-aided P2P Locality
	78
	
	-2008
	-Feldmann
	
Incentives Build Robustness in BitTorrent
	3872
	
	-2003
	-BitTorrent-jäbän oma papru
	
ISP-Friendly Live P2P Streaming
	48
	
	-2013
	-IEEE/ACM Transactions on Networking 22.1
	
ISP-Friendly Peer Matching without ISP Collaboration
	24
	
	-2008
	-Proceedings of the 2008 ACM CoNEXT Conference. 2008
	
ISP-Friendly Peer Selection in P2P Networks
	25
	
	-2009
	
Locality-Awareness in BitTorrent-Like P2P Applications <------------- KATO TÄTÄ TARKEMMIN
	75
	
	-2009
	-EEE transactions on multimedia
	
	Abstract
		This paper presents the measurement study of locality-
		aware P2P solutions over real-world Internet autonomous
		systems (AS) topology. By using the accesses of nodes of PlanetLab
		testbed, we create a detailed AS-level map including the
		end-to-end path of all nodes, as well as the relationship of all
		involved ASes. Based on this map, we evaluate the performance of
		a set of locality-aware P2P solutions, including an optimal solution
		guaranteeing the minimum AS hop count, as well as modified
		BitTorrent system with locality-awareness built into its neighbor
		selection, peer choking/unchoking, and piece selection processes.
		Our findings suggest that locality-awareness can help existing P2P
		solution to significantly decrease load on Internet, and achieve
		shorter downloading time. By comparing the performance of different
		kinds of locality-aware and traditional BitTorrent systems,
		we also point out the necessity to tradeoff between the goals of
		optimizing AS-related performance and achieving fairness among
		peers such as intra-AS traffic and peer burden fairness.
		
Mitigating unfairness in locality-aware peer-to-peer networks <------------------ KATO TÄTÄ TARKEMMIN
	22
	
	-2011
	-International Journal of Network Management 21.1
	
	
	Locality awareness is considered as a promising approach to increase the efficiency of content distribution
	by peer-to-peer (P2P) networks, e.g., BitTorrent. It is intended to reduce the inter-domain traffic, which is
	costly for Internet service providers (ISPs), and to simultaneously increase the performance from the
	viewpoint of P2P users, i.e., to shorten download times. This win–win situation should be achieved by a
	preferred exchange of information between peers which are located close to each other in the underlying
	network topology.Aset of studies shows that these approaches can lead to a win–win situation under certain
	conditions, and to a win–no lose situation in most cases. However, the scenarios used mostly assume
	homogeneous peer distributions. This is not the case in practice according to recent measurement studies.
	Therefore, we extend previous work in this paper by studying scenarios with real-life, skewed peer
	distributions. We show that even a win–no lose situation is difficult to achieve under those conditions and
	that the actual impact for a specific peer heavily depends on the used locality-aware peer selection and the
	specific scenario. This contradicts the principle of economic traffic management (ETM), which aims for a
	solution where all involved players benefit and consequently have an incentive to adopt locality awareness.
	Therefore, we propose and evaluate refinements of current proposals, allowing all users of P2P networks to
	be sure that their application performance is not reduced. This mitigates the unfairness introduced by current
	proposals which is a key requirement for a broad acceptance of the concept of locality awareness in the user
	community of P2P networks. Copyright © 2011 John Wiley & Sons, Ltd.
	
Modeling and Caching of Peer-to-Peer Traffic
	180
	
	-2006
	
MultiCache: An overlay architecture for information-centric networking
	136
	
	-2011
	
	Abstract
		It has become apparent for quite some time that the Internet has evolved from a network
		connecting pairs of end-hosts to a substrate for information dissemination. While this shift
		towards information centric networking has been clearly demonstrated by the proliferation
		of file sharing and content delivery applications, it has not been reflected in a corresponding
		shift in network architecture. To address this issue, we designed MultiCache,
		an information-centric architecture aiming at the efficient use of network resources.
		MultiCache is based on two primitives: multicast and caching. It exploits overlay multicast
		as a means for content delivery and takes advantage of multicast forwarding information to
		locate, in an anycast fashion, nearby caches that have been themselves fed via multicast.
		We evaluate MultiCache against a widespread file sharing application (BitTorrent) with
		respect to both network resource consumption and end-user experience
	
On Selfish Routing in Internet-Like Environments
	343
	
	Qiu et al. [11] describe the interactions between over-
	lay networks and ISPs after the routing control mecha-
	nisms reach the Nash equilibrium point. In this paper,
	we explore some of the issues that arise due to dynamic
	interactions in the presence of unexpected or unplanned
	events such as network failures. We believe that the dy-
	namic network behavior in the presence of failures (that
	are common, everyday events for ISPs [7]) is very im-
	portant for ISPs and needs to be addressed. (Can  ISPs Take the Heat from Overlay Networks?)
	
On the Efficiency of Collaborative Caching in ISP-aware P2P Networks
	41
	
	-2011
	-2011 Proceedings IEEE INFOCOM. IEEE, 2011.
	
On the Interaction between Dynamic Routing in the Native and Overlay Layers
	-Scholarista löytyy pelkkä sitaatti
	
	"In other words, P2P systems reinvent and reimplement a routing system whose dynamics should be able to interact with the dynamics of the Internet routing [7, 17]."
		(Can ISPs and P2P Users Cooperate for Improved Performance?)
	
Peer-Assisted Content Distribution in Akamai NetSession
	93
	
	-2013
	-P2P ja CDN yhdistelmä
	
Pushing the Performance of Biased Neighbor Selection through Biased Unchoking
	37
	
	-2009
	-IEEE Ninth International Conference on Peer-to-Peer Computing
	-Aiemmin oli myös paperi jossa mainittiin biased unchoking
	
Revisiting Cacheability in Times of User Generated Content
	93
	
	-2010
	-2010 INFOCOM IEEE Conference on Computer Communications Workshops
	
Spatial and Temporal Locality of Content in BitTorrent: A Measurement Study
	7
	
	-2013
	
The Disparity between P2P Overlays and ISP Underlays: Issues, Existing Solutions, and Challenges
	19
	
	-2010
	-IEEE network 24.6
	
The Impact of Caching on BitTorrent-like Peer-to-peer Systems
	28
	
	-2010
	-2010 IEEE Tenth International Conference on Peer-to-Peer Computing (P2P)
	
TopBT: A Topology-Aware and Infrastructure-Independent BitTorrent Client
	86

	-2010
	-2010 Proceedings IEEE INFOCOM. IEEE, 2010
	
Traffic Localization for DHT-Based BitTorrent Networks
	27
	
	-2011
	-International Conference on Research in Networking. Springer, Berlin, Heidelberg, 2011
	
Traffic Localization for P2P-Applications: The ALTO Approach
	122
	
	-2009
	-2009 IEEE Ninth International Conference on Peer-to-Peer Computing
	
Traffic Modeling and Proportional Partial Caching for Peer-to-Peer Systems
	-255
	
	-2008
	
Packet Cache Network Function for Peer-to-Peer Traffic Management with Bloom-Filter Based Flow Classification 
	-4
	
	-2016
	
A Remedy for Network Operators against Increasing P2P Traffic Enabling Packet Cache for P2P Applications
	11
	
	-2008
	
P2P packet cache router for networkwide traffic redundancy elimination
	14
	
	-2012
	
A Novel Optimization Scheme for Caching inLocality-aware P2P Networks (tallennettu pdf ei toimi oikein)
	1
	
	-2016
	
	
Cache Capacity Allocation to Overlay Swarms
    Papafili, Ioanna, et al. "Cache capacity allocation to overlay swarms." International Workshop on Self-Organizing Systems. Springer, Berlin, Heidelberg, 2011.

    6
    
    Abstract:
        Peer-to-peer applications generate huge volumes of Internet traffic, thus leading to higher congestion, as well as higher costs for the ISPs particularly due to inter-domain traffic. The traditional traffic management approaches employed by ISPs (e.g. traffic shaping or even throttling) often lead to a deterioration of users‟ Quality-of-Experience. Previous works have verified that the insertion of ISP-owned Peers (IoPs) can deal effectively with this situation. The mechanism offers caching while exploiting the self-organizing structure of overlays. Thus, it leads to both improved performance for peers and reduced inter-domain traffic costs for ISPs. In this paper, we study how the available IoP bandwidth capacity should be allocated among the various swarms that it can possibly join. In particular, we identify a variety of factors that influence the effectiveness of Swarm Selection and Bandwidth Allocation, and we investigate their impact on the practically relevant example of BitTorrent, primarily by means of simulations
    Keywords:
        peer-to-peer, ISP-owned Peer (IoP), cost reduction, performance improvement, Swarm Selection, Bandwidth Allocation
    

Cache replacement policies for p2p file sharing protocols
    Wierzbicki, Adam, et al. "Cache replacement policies for P2P file sharing protocols." European Transactions on Telecommunications 15.6 (2004): 559-569.

    -40 viittausta

    Abstract
        Peer-to-peer (P2P) file-sharing applications generate a large part of today’s Internet traffic. The largevolume of this traffic (thus high potential caching benefits) and the large cache sizes required (thus non-trivial costs associated with caching) only underline that efficient cache replacement policies are importantin this case. File popularity in P2P file-sharing networks does not follow Zipf’s law and several additionalcharacteristics set the generated traffic apart from well-studied Web traffic. All this lead us to conduct afocused study of efficient cache management policies for P2P file-sharing traffic. This paper uses real-worldtraces and trace driven simulations to compare traditional cache replacement policies and new policies thatexploit characteristics of the P2P file-sharing traffic generated by applications using FastTrack protocol


The local and global effects of traffic shaping in the internet
    Marcon, Massimiliano, et al. "The local and global effects of traffic shaping in the internet." 2011 Third International Conference on Communication Systems and Networks (COMSNETS 2011). IEEE, 2011.

    60 viittausta


    Abstract
        Abstract—The Internet is witnessing explosive growth in traf-fic, in large part due to bulk transfers. Delivering such traffic isexpensive for ISPs because they pay other ISPs based on peakutilization. To limit costs, many ISPs are deploying ad-hoctrafficshaping policies that specifically target bulk flows. However, thereis relatively little understanding today about the effectiveness ofdifferent shaping policies at reducing peak loads and what impactthese policies have on the performance of bulk transfers.In this paper, we compare several traffic shaping policies withrespect to (1) the achieved reduction in peak network trafficand (2) the resulting performance loss for bulk transfers. Weidentified a practical policy that achieves peak traffic reductionsof up to 50% with only limited performance loss for bulktransfers. However, we found that the same policy leads to largeperformance losses for bulk transfers when deployed by multipleISPs along a networking path. Our analysis revealed that thisis caused by certain TCP characteristics and differences inlocalpeak utilization times.

Interaction patterns between p2p content distribution systems and isps
    Dan, Gyorgy, et al. "Interaction patterns between P2P content distribution systems and ISPs." IEEE Communications Magazine 49.5 (2011): 222-230.

    30 viittausta

    Abstract
        Peer-to-peer (P2P) content distribution sys-tems are a major source of traffic in the Inter-net, but the application layer protocols they useare mostly unaware of the underlying network inaccordance with the layered structure of theInternet’s protocol stack. Nevertheless, the needfor improved network efficiency and the businessinterests of Internet service providers (ISPs) areboth strong drivers toward a cross-layer approachin peer-to-peer protocol design, calling for P2Psystems that would in some way interact with theISPs. Recent research shows that the interaction,which can rely on information provided by bothparties, can be mutually beneficial. In this articlewe first give an overview of the kinds of informa-tion that could potentially be exchanged betweenthe P2P systems and the ISPs, and discuss theirusefulness and the ease of obtaining andexchanging them. We also present a classifica-tion of the possible approaches for interactionbased on the level of involvement of the ISPsand the P2P systems, and we discuss the poten-tial strengths and the weaknesses of theseapproaches.

Behavior-based P2P Traffic Identification using Fuzzy Approach
    -Ei viittauksia

    -Tää paperi esittelee keinoja identifioimaan P2P-liikennettä

Network pricing: can both ISP and P2P benefit?
	Li, Zhen, and Qi Liao. "Network pricing: can both ISP and P2P benefit?." International Journal of Network Management 24.6 (2014): 433-449.
	
    -6 viittausta

    -Käsittelee tarkemmin miksi ISP täytyy rajoittaa P2P liikennettä rahallisesta näkökulmasta
	
	Abstract
		Internet service providers are facing increasing back pressure from rising access demand by users, especially
		peer-to-peer (P2P)-based applications that greatly enhance the large-scale distribution of content into and
		out  of  their  networks.  With  the  ever  increasing  consumption  pressure  on  scarce  bandwidth  resources,
		ISPs have been forced to reconsider their business model of overselling ‘all-you-can-eat’ broadband at flat
		rates. Technical solutions such as traffic differentiation or blocking violate the principle of network neu-
		trality; traffic shaping and deep packet analysis fall short in the presence of encryption; and P4P (localized
		P2P)-based solutions are difficult to achieve in a heterogeneous environment. Economically, various usage-based 
		pricing schemes have been proposed and discussed. While they can improve efficiency in bandwidth
		consumption,  they  tend  to  face  strong  customer  resistance  as  users  have  strong  preference  in  favour  of
		simple  flat  rates.  We  argue  that  any  feasible  pricing  reforms  cannot  deviate  much  from  the  current  flat
		rates while providing financial incentives for bandwidth hogs to limit their bandwidth access. In contrast tonormal usage-
		based pricing models that charge by volume, we propose a temporal-based pricing modelthat may generate a mutually beneficial 
		solution that can not only increase the profitability of ISPs but also
		accommodate P2P, rather than killing it, without changing the software, protocols or hardware that clients
		or ISPs use on the network. Copyright © 2014 John Wiley & Sons, Ltd


Economics of network pricing with multiple ISPs
    -280 viittausta

    -2006

    -Internet service providers offer users access to the Internet and related services. There are roughly twotiers of ISPs according to the range of services provided:localISPs that provide services in smallregions to end-users andtransitISPs that transfer data between local ISPs [1]. (Network pricing: can both ISP and P2P benefit?)

Sandvine. Global internet phenomena report, 2013
    -White paper, ei ladattu (on refworksissa)

    -In recent years,although  easily  accessible  streaming  media  such  as  Netflix  and  YouTube  have  led  to  a  downwardtrend in P2P file sharing of movie and music, P2P systems such as BitTorrent still dominate upstream traffic with36:35% as of 2013(Network pricing: can both ISP and P2P benefit?)


On the feasibility of commercial, legal P2P content distribution
    -129 viittausta

    -Because of theincreased load and changing traffic patterns resulting from the large amount of traffic generated [6],especially the upstream bandwidth requirements by P2P, ISPs have been under significant pressure ontheir maximum link capacity to domains outside of their local networks, that is, their bottleneck linkcapacity (Network pricing: can both ISP and P2P benefit?)

The Internet’s not a big truck: toward quantifying network neutrality.
    -43 viittausta

    -ks. Viittaukset-filusta

The economics of network neutrality
    -ks. Viittaukset-filusta

Towards an ISP-compliant, peer-friendly design for peer-to-peer networks
    -Ei ladattu

    -15 viittausta
    -2008
    -There has been research about the rising tension between P2P and ISPs. Peer Coordination Protocol[27] was developed for ISP-compliant P2P systems, which puts a dynamic rate limit on P2P trafficbased on an ISPs’ constraint. (Network pricing: can both ISP and P2P benefit?)


			
The Internet-wide impact of P2P traffic localization on ISP profitability
    Seibert, Jeff, et al. "The internet-wide impact of p2p traffic localization on isp profitability." IEEE/ACM Transactions on Networking 20.6 (2012): 1910-1923.

    -18 viittausta

    -Vastaväite paperi!!!!
        -Lue artikkelia ehkä hieman kriittisellä silmällä

    Abstract
        Abstract—We conduct a detailed simulation study to examinethe impact of localizing P2P traffic within network boundarieson an ISP’s profitability. A distinguishing aspect of our workis the focus on Internet-wide implications, i.e., how adoption oflocalization within an ISP affects both itself and other ISPs. Oursimulations are based on detailed models of inter-AS P2P trafficand inter-AS routing, localization models that can predicttheextent to which P2P traffic is reduced, and pricing models topredict the impact of changes in traffic on an ISP’s profit. Toevaluate our models we use a large-scale crawl of BitTorrentinvolving over 138 million users sharing 2.75 million files.Ourresults show that the benefits of localization must not be takenfor granted. Some of our key findings include: (i) residentialISPs can actually lose money when localization is employed andsome will not see increased profitability until other ISPs employlocalization; (ii) the reduction in costs due to localization will belimited for small ISPs and tends to grow only logarithmicallywith client population; and (iii) some ISPs can better increaseprofitability through alternate strategies to localization by takingadvantage of the business relationships they have with others


Modeling the peering and routing tussle between ISPs and P2P applications
    Wang, Jessie Hui, Dah Ming Chiu, and John CS Lui. "Modeling the peering and routing tussle between ISPs and P2P applications." 200614th IEEE International Workshop on Quality of Service. IEEE, 2006.

    -23 viittausta

    -Wanget al. [35] modelled the peering and routing tussle between ISPs and P2Papplications  and  analysed  the  economic  implications  of  overlay  traffic  on  ISPs’  peering  decisions. (Network pricing: can both ISP and P2P benefit?)

BitTorrent Developers Introduce Comcast Busting Encryption (Uutisartsa)
    https://torrentfreak.com/bittorrent-devs-introduce-comcast-busting-encryption-080215/

    The large volumes of P2P traffic in today’s Internet have sig-nificantly changed the Internet traffic pattern and dramaticallyincreased the traffic-relay cost at the ISPs. Such a cost threathas led to ISPs’ packet filtering and rate throttling towardsP2Ptraffic [1], while on the other hand P2P application providersreact  by  encrypting  data  and  communicating  with  dynamicports to prevent from being recognized [2]. (The Performance and Locality Tradeoff inBitTorrent-like P2P File-Sharing Systems)
	
Clustering and sharing incentives in BitTorrent systems
	Legout, Arnaud, et al. "Clustering and sharing incentives in bittorrent systems." ACM SIGMETRICS Performance Evaluation Review 35.1 (2007): 301-312.
	
	-358 viittausta
	
	Abstract
		Peer-to-peer protocols play an increasingly instrumental role in In-
		ternet content distribution. It is therefore important to gain a com-
		plete understanding of how these protocols behave in practice and
		how their operating parameters affect overall system performance.
		This paper presents the ﬁrst detailed experimental investigation of
		the peer selection strategy in the popular BitTorrent protocol. By
		observing more than 40 nodes in instrumented private torrents, we
		validate three protocol properties that, though believed to hold,
		have not been previously demonstrated experimentally: the clus-
		tering of similar-bandwidth peers, the effectiveness of BitTorrent’s
		sharing incentives, and the peers’ high uplink utilization. In addi-
		tion, we observe that BitTorrent’s modiﬁed choking algorithm in
		seed state provides uniform service to all peers, and that an un-
		derprovisioned initial seed leads to absence of peer clustering and
		less effective sharing incentives. Based on our results, we provide
		guidelines for seed provisioning by content providers, and discuss
		a tracker protocol extension that addresses an identiﬁed limitation
		of the protocol.
		
	-Moreover, the clustering observed by Legout et al. [12]
	appears only when there is high piece diversity. As soon
	as piece diversity becomes lower, there is no more clustering
	even if the efficiency of BitTorrent is preserved
		-This is
		this kind of phenomenon we observe with locality. Indeed,
		even if upload distribution is supposed to foster communications
		among peers with the same upload capacity, this is
		by no mean an absolute constraint because, as soon as
		piece diversity decreases, clusters among peers are broken
		and any peer can communicate with any other peer [12].
		
		(Pushing bittorrent locality to the limit)
		
Rarest first and choke algorithms are enough
	Legout, Arnaud, Guillaume Urvoy-Keller, and Pietro Michiardi. "Rarest first and choke algorithms are enough." Proceedings of the 6th ACM SIGCOMM conference on Internet measurement. 2006.
	
	503 viittausta
	
	Abstract
		The performance of peer-to-peer file replication comes from
		its piece and peer selection strategies.  Two such strategies
		have been introduced by the BitTorrent protocol: the rarest
		first and choke algorithms.   Whereas it is commonly ad-
		mitted that BitTorrent performs well, recent studies have
		proposed the replacement of the rarest first and choke algo-
		rithms in order to improve efficiency and fairness.  In this
		paper, we use results from real experiments to advocate that
		the replacement of the rarest first and choke algorithms can-
		not be justified in the context of peer-to-peer file replication
		in the Internet.We instrumented a BitTorrent client and ran experiments
		on real torrents with different characteristics.  Our exper-
		imental evaluation is peer oriented, instead of tracker ori-
		ented,  which allows  us to get detailed information  on all
		exchanged messages and protocol events. We go beyond the
		mere observation of the good efficiency of both algorithms.
		We show that the rarest first algorithm guarantees close to
		ideal diversity of the pieces among peers.  In particular, on
		our experiments, replacing the rarest first algorithm with
		source or network coding solutions cannot be justified.  We
		also show that the choke algorithm in its latest version fos-
		ters reciprocation and is robust to free riders.  In particu-
		lar, the choke algorithm is fair and its replacement with a
		bit level tit-for-tat solution is not appropriate.  Finally, we
		identify new areas of improvements for efficient peer-to-peer
		file replication protocols.
		
	-Categories and Subject Descriptors:
		-C.2.2 [Computer-Communication   Networks]:Network  Protocols;   
		-C.2.4[Computer-Communication Networks]: Distributed Systems 
		
	-General Terms:
		-Measurement, Algorithms, Performance
		
	-Keywords:BitTorrent, choke algorithm, rarest first algo-rithm, peer-to-peer
	
Dissecting BitTorrent: five months in a torrent’s lifetime
	Izal, Mikel, et al. "Dissecting bittorrent: Five months in a torrent’s lifetime." International Workshop on Passive and Active Network Measurement. Springer, Berlin, Heidelberg, 2004.
	
	-720 viittausta
	
	Abstract
		Popularcontent such assoftwareupdatesis requestedby alargenumber of users.
		Traditionally, tosatisfya largenumber of requests,lagerserver farmsormirroringareused,
		bothof which areexpensive. Aninexpensive alternative arepeer-to-peerbasedreplicationsystems,
		whereuserswhoretrieve the le,actsimultaneouslyasclientsandservers.Inthispaper,
		we studyBitTorrent, a newandalreadyverypopularpeer-to-peerapplicationthatallowsdistributionof
		verylargecontentstoalargesetofhosts.OuranalysisofBitTorrent is basedonmeasurementscollected
		ona  ve monthslongperiod thatinvolvedthousandsofpeers.We assesstheperformanceof 
		thealgorithmsusedinBitTorrent throughseveralmetrics.OurconclusionsindicatethatBitTorrent 
		is a realisticandinexpensive alternative totheclassicalserver-basedcontent distribution.
		
	Should internet service providers fear peer-assisted content distribution?
		Content distribution using BitTorrent has been shown to
		offer outstanding performance in terms of content delivery
		rates to the clients [22, 9].
		
		Izal et al. analyze the log of a BitTorrent tracker showing
		the flash-crowd effect of a single file, download speeds,
		and the amount of time that peers stay after they have completed
		the download [9]
		
An ISP-friendly file distribution protocol: analysis, design and implementation
	Lin, Minghong, John CS Lui, and Dah-Ming Chiu. "An isp-friendly file distribution protocol: analysis, design, and implementation." IEEE Transactions on Parallel and Distributed Systems 21.9 (2009): 1317-1329.
	
	-27 viittausta
	
	Abstract
		In  the  past  few  years,  P2P  file  distribution  appli-
		cations (e.g.,  BitTorrent)  are  becoming so  popular that  they  are
		the dominating source of Internet traffic. This creates significant
		problems to  Internet Service  Providers (ISPs), not  only because
		of  the  added  complexity  in  traffic  engineering,  but  the  increase
		of traffic, in particular on the cross-ISP links, implies congestion
		and  a  higher operating  cost.  In  this paper,  we consider  an  
		ISP-friendly file distribution protocol  which uses the 
		“exploiting-the-locality principle” (ELP) to reduce the cross-ISP traffic. To show
		its  benefit,  we  derive  an  upper  and  lower  bound  of  cross-ISP
		traffic  for  the  protocols  which  rely  on  ELP,  and  show  that  the
		cross-ISP  traffic  can  be  reduced  significantly  when  the  number
		of  peers  within  an  ISP  increases.  To  carry  out  realistic  study,
		we  design  and  implement  our  ISP-friendly  protocol  (which  is
		compatible  with  the current  BitTorrent  protocol)  and  carryout
		large  scale  experiments  on  PlanetLab  to  measure  the  reduction
		of  the  cross  ISP-traffic  and  the  file  downloading  time.  More
		important, we also show how the proposed ISP-friendly protocol
		can  handle  the  “black-hole”  security  attack.  This  paper  sheds
		light  on  the merits  and  design  direction  of  ISP-friendly content
		distribution protocols.
		
	Lin et al. [22] introduce ELP that aims to keep traffic local
	to ISPs. They provide a model that gives bounds on the
	inter-ISP traffic, and they validate ELP experimentally on
	PlanetLab with a maximum of 60 peers. (Pushing bittorrent locality to the limit)
	
Preemptive Strategies to Improve Routing Performance of Native and Overlay Layers
	Seetharaman, Srinivasan, et al. "Preemptive strategies to improve routing performance of native and overlay layers." IEEE INFOCOM 2007-26th IEEE International Conference on Computer Communications. IEEE, 2007.
	
	-42 viittausta
	
	Abstract
		Overlay routing is known to cause undesired insta-
		bility in a network by operating in a selfish manner. The objec-
		tives  of  overlay  routing,  such as  optimizing  end-to-end 
		latency,are often in conflict with the objectives of traffic engineering in
		the  native  layer,  which  is  concerned  about  balancing  load.  In
		our  work,  we  build  on  past  research  that  has  investigated  the
		recurring  non-cooperative  interaction  between  overlay  routing
		and  traffic  engineering,  and  develop  strategies  that  improve
		the  routing  performance  of  a  particular  layer  with  incomplete
		information about the other layer. In our strategies, one layer acts
		as  a leader that predicts the follower’s reaction and undertakes
		countermeasures to prevent future deterioration in performance.
		Specifically,  we  propose  two  classes  of  strategies  –friendly or hostile–  
		for  each layer. By  simulating under  different network
		characteristics, we show that these preemptive strategies achieve
		near-optimal performance for the leader and increase the overall
		stability of the network. Furthermore, we observe that the best
		performance for a particular layer is achieved only when the goals
		of the other layer are completely violated, thereby motivating a higher level of selfishness
		
	There is an intrinsic struggle between
	the layers — P2P overlay and network underlay
	— when performing the same service (routing);
	however, there are strategies to mitigate this
	dichotomy [11] (A Survey of Research on the Application-Layer Traffic Optimization Problem and the Need for Layer Cooperation)
	
	Some features of the network topology are
	hard to infer through application-level techniques,
	and it may not be possible to infer them at all.
	Examples of such features are service provider
	policies and preferences such as the state and cost
	associated with interdomain peering and transit
	links. Another example is the traffic engineering
	policy of a service provider, which may counteract
	the routing objective of the overlay network, leading
	to poor overall performance [11]. (A Survey of Research on the Application-Layer Traffic Optimization Problem and the Need for Layer Cooperation)
	
	
Implementation and Preliminary Evaluation of an ISP-Driven Informed Path Selection
	Saucez, Damien, Benoit Donnet, and Olivier Bonaventure. "Implementation and preliminary evaluation of an ISP-driven informed path selection." Proceedings of the 2007 ACM CoNEXT conference. 2007.
	
	-15 viittausta
	
	ISP-Driven Informed Path Selection (IDIPS) Service
	— The solution proposed by Saucez et al. [10] is
	essentially a modified version of the oracle-based
	approach described above, and is intended to provide
	a network-layer service for finding best source
	and destination addresses when establishing a connection
	between two endpoints in multihomed environments
	(which are common in IPv6 networking). (A Survey of Research on the Application-Layer Traffic Optimization Problem and the Need for Layer Cooperation)
		
Network Coordinates in the Wild
	Ledlie, Jonathan, Paul Gardner, and Margo I. Seltzer. "Network Coordinates in the Wild." NSDI. Vol. 7. 2007.
	
	-330 viittausta
	
	Abstract
		Network coordinates provide a mechanism for select-
		ing and placing servers efficiently in a large distributed
		system. This approach works well as long as the coordi-n
		ates continue to accurately reflect network topology. We
		conducted a long-term study of a subset of a million-plus
		node coordinate system and found that it exhibited some
		of the problems for which network coordinates are fre-
		quently criticized, for example, inaccuracy and fragility
		in the presence of violations of the triangle inequality.
		Fortunately, we show that several simple techniques rem-
		edy many of these problems. Using the Azureus BitTor-
		rent network as our testbed, we show that live, large-scale
		network coordinate systems behave differently than their
		tame PlanetLab and simulation-based counterparts.  We
		find higher relative errors, more triangle inequality viola-
		tions, and higher churn. We present and evaluate a number
		of techniques that, when applied to Azureus, efficiently
		produce accurate and stable network coordinates
		
	A Survey of Research on the Application-Layer Traffic Optimization Problem and the Need for Layer Cooperation
		-Vivaldi is now used
		in the popular P2P application Azureus, and
		studies indicate that it scales well to very large
		networks [12].
		
		Network coordinate systems require the embedding
		of the Internet topology into a coordinate system.
		This is not always possible without errors,
		which impacts the accuracy of distance estimations.
		In particular, it has proven to be difficult to embed
		the triangular inequalities found in Internet path
		distances [12]. Thus, Meridian [6] abandons the
		generality of network coordinate systems and provides
		specific distance evaluation services.
		
		Undoubtedly, it is hard to foresee
		how proposed systems will perform in the Internet.
		Simulations and testbed emulations are in most
		cases the only options available for benchmarking
		the performance of a system. However, these have
		often proven inadequate; in at least one particular
		case [12], they have only provided rough optimistic
		approximations of what would be measured in the
		real world.
	
	
Flash Crowds and Denial of Service Attacks: Characterization and Implications for CDNs and Web Sites
	Jung, Jaeyeon, Balachander Krishnamurthy, and Michael Rabinovich. "Flash crowds and denial of service attacks: Characterization and implications for CDNs and web sites." Proceedings of the 11th international conference on World Wide Web. 2002.
	
	907 viittausta
	
	Should internet service providers fear peer-assisted content distribution?
		Peer-assisted solutions are inherently self scalable, in
		that the bandwidth capacity of the system increases as more
		nodes arrive: each new node requests service from, but also
		provides service to, the other nodes. The network can thus
		spontaneously adapt to the demand by taking advantage
		of the resources provided by every end-node, thus making
		it more resilient to “flash crowd” events, which may
		challenge content distribution networks with hundreds of
		servers [10].
			As
			a P2P protocol, BitTorrent enjoys the benefits of a distributed
			system that is inherently more robust to events such
			as flash crowds, shown to be challenging even for CDNs
			with hundreds of servers [10], as well as cheaper in terms
			of infrastructure cost on the part of the content provider.
			
	-Ei vissiin käsittele p2p näkökulmasta, vaan CDNnien yms.
		
Modeling and performance analysis of bittorrent-like peer-to-peer network
	Qiu, Dongyu, and Rayadurgam Srikant. "Modeling and performance analysis of BitTorrent-like peer-to-peer networks." ACM SIGCOMM computer communication review 34.4 (2004): 367-378.
	
	1659 viittausta
	
	Abstract
		In this paper, we develop simple models to study the per-
		formance  of  BitTorrent,  a second  generation  peer-
		to-peer(P2P) application.   We first present a simple fluid model
		and study the scalability, performance and efficiency of such
		a file-sharing mechanism. We then consider the built-in in-
		centive mechanism of BitTorrent and study its effect on net-
		work performance. We also provide numerical results based
		on both simulations and real traces obtained from the In-
		ternet.
	
	Content distribution using BitTorrent has been shown to
	offer outstanding performance in terms of content delivery
	rates to the clients [22, 9]. (Should internet service providers fear peer-assisted content distribution?)
	
Understanding availability
	Bhagwan, Ranjita, Stefan Savage, and Geoffrey M. Voelker. "Understanding availability." International Workshop on Peer-to-Peer Systems. Springer, Berlin, Heidelberg, 2003.
	
	720 viittausta
	
	Abstract
		Thispaperaddressesa  simple,yetfundamentalquestioninthedesignofpeer-to-peersystems:
		Whatdoesit meanwhenwesay“availability”andhowdoesthisunderstand-ingimpacttheengineeringofpracticalsystems?
		We  ar-guethatexistingmeasurementsandmodelsdonotcapturethecomplex time-varyingnatureofavailabilityintoday’s
		peer-to-peerenvironments.Further, weshowthatunfore-seenmethodologicalshortcomingshave dramaticallybiased
		previousanalysesofthisphenomenon.Asthebasisofourstudy, weempiricallycharacterizetheavailabilityofa 
		largepeer-to-peersystemovera periodof7 days,analyzethede-pendenceoftheunderlyingavailabilitydistributions,mea-
		surehostturnoverinthesystem,anddiscusshow thesere-sultsmayaffectthedesignofhigh-availabilitypeer-to-peerservices.
	
	The “tit-for-tat” policy is a distinctive advantage of the
	BitTorrent system which renders it ideal for a P2P content
	distribution scheme: Peers are forced to always share
	the content during their downloads while “free-riders” [2]
	are indirectly banned from the network. (Should internet service providers fear peer-assisted content distribution?)
	
The Bittorrent P2P File-sharing System: Measurements and Analysis	
	Pouwelse, Johan, et al. "The bittorrent p2p file-sharing system: Measurements and analysis." International Workshop on Peer-to-Peer Systems. Springer, Berlin, Heidelberg, 2005.
	
	1079 viittausta
	
	Pouwelse et al. present an extensive
	analysis of BitTorrent showing availability, peer uptimes,
	and providing a better understanding of peer interarrival
	times [21]. (Should internet service providers fear peer-assisted content distribution?)
	

	
DSL Broadband Providers Perform Balancing Act (uutisartsa)
	http://www.slyck.com/news.php?story=973
	
	On the one hand, P2P system applications have resulted
	in an increase in revenue for ISPs, as they are one of the major
	reasons cited by Internet users for upgrading their Internet access
	to broadband [6]. (Can ISPs and P2P Users Cooperate for Improved Performance?)
	
Controlling P2P Traffic (uutisartsa)	
	http://www.lightreading.com/document.asp?site=lightreading&doc_id=44435&page_number=3.
	
	On the other hand, ISPs find that P2P traffic poses a significant traffic engineering challenge [4, 7] (Can ISPs and P2P Users Cooperate for Improved Performance?)
	
Methodology for Estimating Network Distances of Gnutella Neighbors
	Aggarwal, Vinay, et al. "Methodology for estimating network distances of Gnutella neighbors." Informatik 2004, Informatik verbindet, Band 2, Beiträge der 34. Jahrestagung der Gesellschaft für Informatik eV (GI) (2004).
	
	33 viittausta
	
	Abstract
		In this  paper  we ask the  question how  much  does  the neighborhood  se-lection  process  of  a  P2P  protocol  such  as  Gnutella  respect  the  underlying  
		Internettopology.
		
	Can ISPs and P2P Users Cooperate for Improved Performance?
		P2P traffic
		often starves other applications like Web traffic of bandwidth [8],
		and swamps the ISP network. This is because most P2P systems
		rely on application layer routing based on an overlay topology on
		top of the Internet, which is largely independent of the Internet routing
		and topology [9].
		
		It has been shown that
		P2P traffic often crosses network boundaries multiple times [9, 10].
		This is not necessarily optimal as most network bottlenecks in the
		Internet are assumed to be either in the access network or on the
		links between ISPs, but not in the backbones of the ISPs [11].
		
	Most P2P systems employ an arbitrary peer selection policy
	that ignores the underlying Internet topology and ISP link costs,
	establishing connections between randomly chosen subsets of cooperating
	peers from around the world. Such a policy results in
	P2P traffic that often crosses network boundaries multiple times to
	reach content that could have been more speedily obtained from
	nearby peers [2, 8, 17]. (Taming the torrent)
	
An Empirical Evaluation of Wide-Area Internet Bottlenecks
	Akella, Aditya, Srinivasan Seshan, and Anees Shaikh. "An empirical evaluation of wide-area internet bottlenecks." Proceedings of the 3rd ACM SIGCOMM conference on Internet measurement. 2003.
	
	321 viittausta
	
	It has been shown that
	P2P traffic often crosses network boundaries multiple times [9, 10].
	This is not necessarily optimal as most network bottlenecks in the
	Internet are assumed to be either in the access network or on the
	links between ISPs, but not in the backbones of the ISPs [11]. (Can ISPs and P2P Users Cooperate for Improved Performance?)
	
	Further, we expect that these peers
	will be mostly within the same ISP, thus avoiding cross-ISP traffic
	and optimizing clients’ performance by avoiding most network
	bottlenecks [7]. (Taming the torrent)
	
On the Long-term Evolution of the Two-Tier Gnutella Overlay
	Rasti, Amir H., Daniel Stutzbach, and Reza Rejaie. "On the long-term evolution of the two-tier gnutella overlay." Proceedings IEEE INFOCOM 2006. 25TH IEEE International Conference on Computer Communications. IEEE, 2006.
	
	74 viittausta
	
	Besides,
	studies have shown that the desired content is often available
	“in the proximity” of interested users [10, 12]. (Can ISPs and P2P Users Cooperate for Improved Performance?)
	
Topologically aware overlay construction and server selection
	Ratnasamy, Sylvia, et al. "Topologically-aware overlay construction and server selection." Proceedings. Twenty-First Annual Joint Conference of the IEEE Computer and Communications Societies. Vol. 3. IEEE, 2002
	
	1137 viittausta
	
	Abstract
		A  number  of  large-scale  distributed  Internet  applications
		could  potentially  benefit from some level  of knowledge about the relative
		proximity  between its participating  host nodes.  For example,  the perfor-
		mance of large overlay networks could be improved if the application-level
		connectivity between the nodes in these networks is congruent with the un-
		derlying IP-level topology.  Similarly, in the case of replicated web content,
		client nodes could use topological information in selecting one of multiple
		available servers.  For such applications, one need not find the optimal so-
		lution in order to achieve significant practical benefits.  Thus, these appli-
		cations, and presumably others like them, do not require exact topological
		information and can instead use sufficiently informative hints about the rel-
		ative positions of Internet hosts.
		
		In  this  paper,  we  present  a binning scheme  whereby  nodes  partition
		themselves  into  bins such  that  nodes  that  fall  within  a given  bin  are  rel-
		atively  close  to  one  another  in  terms  of  network  latency.    
		Our  binningstrategy is simple (requiring minimal support from any measurement  in-
		frastructure),  scalable (requiring no form of global knowledge, each node
		only needs knowledge of a small number of well-known landmark nodes)
		and  completely  distributed  (requiring  no  communication  or  cooperation
		between the nodes being binned).
		
		We apply this binning strategy to the two applications mentioned above:
		overlay  network  construction  and  server  selection.   We  test  our  binning
		strategy  and  its  application  using  simulation  and  Internet  measurement
		traces.  Our results indicate that the performance of these applications can
		be significantly improved by even the rather coarse-grained knowledge of
		topology offered by our binning scheme.
		
	While we do not know of a P2P network that tries to reverseengineer
	the Internet topology, there are some proposals that suggest
	that P2P networks should bias their overlay topology by choosing
	neighbors that are close in the sense of high throughput or low
	latency, e.g., [18, 19, 20] or that are within the same AS, e.g., [10,
	21]. (Can ISPs and P2P Users Cooperate for Improved Performance?)
	
Packet Forgery by ISPs: A Report on the Comcast Affair (uutisartsa)
	http://www.eff.org/wp/packet-forgery-isps-report-comcast-affair.
	
	Network oblivious sharing increases costs for ISPs. As
	demand increases on transit links, backbone ISPs are forced
	to invest in increasing capacity. These costs are passed
	on to edge ISPs that pay transit costs proportional to the
	amount of interdomain traffic they generate. Many customer
	facing ISPs, however, offer flat-rate pricing, forcing
	them to absorb the costs externalized by P2P file sharing.
	In response, some ISPs have elected to rate-limit or simply
	block these “problem” protocols [4, 14], in turn leading
	developers into an arms race to evade restrictions. (Pitfalls for ISP-Friendly P2P Design)
	
Analyzing peer-to-peer traffic across large networks
	Sen, Subhabrata, and Jia Wang. "Analyzing peer-to-peer traffic across large networks." Proceedings of the 2nd ACM SIGCOMM Workshop on Internet measurment. 2002.
	
	1287 viittausta
	
	Abstract
		The use of peer-to-peer (P2P) applications is growing
		dramatically, particularly for sharing large video/audio files and
		software. In this paper, we analyze P2P traffic by measuring flowlevel
		information collected at multiple border routers across a large
		ISP network, and report our investigation of three popular P2P systems—
		FastTrack, Gnutella, and Direct-Connect. We characterize
		the P2P trafffic observed at a single ISP and its impact on the
		underlying network. We observe very skewed distribution in the
		traffic across the network at different levels of spatial aggregation
		(IP, prefix, AS). All three P2P systems exhibit significant dynamics
		at short time scale and particularly at the IP address level. Still,
		the fraction of P2P traffic contributed by each prefix is more stable
		than the corresponding distribution of eitherWeb traffic or overall
		traffic. The high volume and good stability properties of P2P traffic
		suggests that the P2P workload is a good candidate for being managed
		via application-specific layer-3 traffic engineering in an ISP’s
		network.
	
	Sen and
	Wang [18] perform trace analysis of P2P traffic along the
	border routers of a single ISP and provide data that suggests
	that application-level traffic engineering might help. (Pitfalls for ISP-Friendly P2P Design)
	
Characterizing the Performance and Stability Issues of the AS Path Prepending Method: Taxonomy, Measurement Study and Analysis
	Wang, Hui, et al. "Characterizing the performance and stability issues of the AS path prepending method: taxonomy, measurement study and analysis." Proceedings of ACM SIGCOMM Asia Workshop. 2005
	
	25 viittausta
	
	The notion of ISPs manipulating existing protocols to
	accomplish traffic engineering goals or for strategic benefit
	has also received attention by researchers.
		Wang et
		al. report widespread use of path prepending to influence
		routing [19]. Mahajan et al. suggest additional protocol
		mechanisms by which ISPs coordinate their actions to overcome
		common inefficiencies in interdomain routing [13],
		but efficient outcomes depend on mutual trust between
		ISPs. More recently, Goldberg et al. [5] examine the incentives
		for ISPs to manipulate routing announcements
		to attract generic revenue-generating traffic and find that
		ensuring honesty likely requires substantial restriction in
		policy freedom. (Pitfalls for ISP-Friendly P2P Design)
	
On the locality of bittorrent-based video file swarming
	Wang, Haiyang, Jiangchuan Liu, and Ke Xu. "On the locality of BitTorrent-based video file swarming." IPTPS. 2009.
	
	43 viittausta
	
	In contrast to the aforementioned work, we show in this
	paper that a win-no lose situation is difficult to achieve under
	the real-life conditions we observe in today’s Internet. The
	scenarios we investigate here differ mainly in two aspects from
	the ones considered in the previous work: First, we consider
	skewed peer distributions, i.e., a few ASes contain a large
	number of peers and most ASes contain only very few peers.
	According to the measurement studies presented in [5] and [6],
	these distributions are typical for today’s BitTorrent swarms. (Can P2P-users benefit from Locality-Awarenss)
	
Measurement of bittorrent swarms and their as topologies
	Hoßfeld, Tobias, et al. "Measurement of BitTorrent swarms and their AS topologies." Computer Networks (2009).
	
	19 viittausta
	
	In contrast to the aforementioned work, we show in this
	paper that a win-no lose situation is difficult to achieve under
	the real-life conditions we observe in today’s Internet. The
	scenarios we investigate here differ mainly in two aspects from
	the ones considered in the previous work: First, we consider
	skewed peer distributions, i.e., a few ASes contain a large
	number of peers and most ASes contain only very few peers.
	According to the measurement studies presented in [5] and [6],
	these distributions are typical for today’s BitTorrent swarms. (Can P2P-users benefit from Locality-Awarenss)
	
Characterizing residential broadband networks
	Dischinger, Marcel, et al. "Characterizing residential broadband networks." Proceedings of the 7th ACM SIGCOMM conference on Internet measurement. 2007.
	
	430 viittausta
	
	Second, not all peers in a swarm have the same access speeds
	(cf. [7]) as assumed in most previous works. (Can P2P-users benefit from Locality-Awarenss)
	
Characterizing and mitigating inter-domain policy violations in overlay routes
	Seetharaman, Srinivasan, and Mostafa Ammar. "Characterizing and mitigating inter-domain policy violations in overlay routes." Proceedings of the 2006 IEEE International Conference on Network Protocols. IEEE, 2006.
	
	45 viittausta
	
	Abstract
		The Internet is a complex structure arising from the interconnection of numerous autonomous systems (AS), each exercising its own administrative policies to reflect the 
		commercial agreements behind the interconnection. However, routing in service overlay networks is quite capable of violating these policies to its advantage. To prevent 
		these violations, we see an impending drive in the current Internet to detect and filter overlay traffic. In this paper, we first present results from a case study overlay 
		network, constructed on top of Planetlab, that helps us gain insights into the frequency and characteristics of the different inter-domain policy violations. We further 
		investigate the impact of two types of overlay traffic filtering that aim to prevent these routing policy violations: blind filtering and policy- aware filtering. We show 
		that such filtering can be detrimental to the performance of overlay routing. We next consider two approaches that allow the overlay network to realize the full advantage of 
		overlay routing in this context. In the first approach, overlay nodes are added so that good overlay paths do not represent inter-domain policy violations. In the second 
		approach, the overlay acquires transit permits from certain ASes that allow certain policy violations to occur. We develop a single cost-sharing framework that allows the 
		incorporation of both approaches into a single strategy. We formulate and solve an optimization problem that aims to determine how the overlay network should allocate a 
		given budget between paying for additional overlay nodes and paying for transit permits to ASes. We illustrate the use of this approach on our case study overlay network and 
		evaluate its performance under varying network characteristics.
		
	Second, for interdomain, network-oblivious P2P may generate a
	significant amount of interdomain transit traffic [12] or relay a substantial
	amount of traffic between the providers of a network [30]. (P4P: Provider Portal for Applications)
		-[30] on tämä artikkeli
		
Making intra-domain routing robust to changing and uncertain traffic demands: Understanding fundamental tradeoffs
	Applegate, David, and Edith Cohen. "Making intra-domain routing robust to changing and uncertain traffic demands: Understanding fundamental tradeoffs." Proceedings of the 2003 conference on Applications, technologies, architectures, and protocols for computer communications. 2003.
	
	382 viittausta
	
	Abstract
		Intra-domain traffic engineering can significantly enhance
		the performance of large IP backbone networks. Two im-
		portant components of traffic engineering are understanding
		the traffic demands and configuring the routing protocols.
		These two components are inter-linked, as it is widely be-
		lieved that an accurate view of traffic is important for op-
		timizing the configuration of routing protocols and through
		that, the utilization of the network.
		
		This basic premise, however, never seems to have been
		quantified – How important is accurate knowledge of traf-
		fic demands for obtaining good utilization of the network?
		Since traffic demand values are dynamic and illusive, is it
		possible to obtain a routing that is “robust” to variations
		in demands? Armed with enhanced recent algorithmic tools
		we explore these questions on a diverse collection of ISP net-
		works. We arrive at a surprising conclusion: it is possible
		to obtain a robust routing that guarantees a nearly optimal
		utilization with a fairly limited knowledge of the applicable
		traffic demands.
	
		While ISPs have clear incentives to improve network
		efficiency, existing approaches have limitations. The traditional
		approach to improving network efficiency is traffic engineering
		(e.g., [2, 10]). (P4P: Provider Portal for Applications)
		
Walking the tightrope: Responsive yet stable traffic engineering
	Kandula, Srikanth, et al. "Walking the tightrope: Responsive yet stable traffic engineering." ACM SIGCOMM Computer Communication Review 35.4 (2005): 253-264.
	
	491 viittausta
	
	Abstract
		Current intra-domain Traffic Engineering (TE) relies on offlin
		emethods, which use long term average traffic demands.  It can-
		not react to realtime traffic changes caused by BGP reroutes, di-
		urnal traffic variations, attacks, or flash crowds. Further, current
		TE deals with network failures by pre-computing alternative rout-
		ings for a limited set of failures. It may fail to prevent congestion
		when unanticipated or combination failures occur, even though the
		network has enough capacity to handle the failure.
		
		This paper presents TeXCP, an online distributed TE protocol
		that balances load in realtime, responding to actual traffic demands
		and failures. TeXCP uses multiple paths to deliver demands from
		an ingress to an egress router, adaptively moving traffic from over-
		utilized to under-utilized paths. These adaptations are carefully de-
		signed such that, though done independently by each edge router
		based on local information, they balance load in the whole net-
		work without oscillations. We model TeXCP, prove the stability of
		the model, and show that it is easy to implement. Our extensive
		simulations show that, for the same traffic demands, a network us-
		ing TeXCP supports the same utilization and failure resilience as a
		network that uses traditional offline TE, but with half or third the
		capacity.
		
	While ISPs have clear incentives to improve network
	efficiency, existing approaches have limitations. The traditional
	approach to improving network efficiency is traffic engineering
	(e.g., [2, 10]). (P4P: Provider Portal for Applications)
	
BLINC: Multilevel Traffic Classification in the Dark
	Karagiannis, Thomas, Konstantina Papagiannaki, and Michalis Faloutsos. "BLINC: multilevel traffic classification in the dark." Proceedings of the 2005 conference on Applications, technologies, architectures, and protocols for computer communications. 2005.
	
	1541 viittausta
	
	Abstract
		We present a fundamentally different approach to classify-
		ing traffic flows according to the applications that gener-
		ate them. In contrast to previous methods, our approach is
		based on observing and identifying patterns of host behavior
		at the transport layer. We analyze these patterns at three
		levels of increasing detail (i) the social, (ii) the functional
		and (iii) the application level. This multilevel approach of
		looking at traffic flow is probably the most important con-
		tribution of this paper. Furthermore, our approach has two
		important features.  First, it operatesin the dark, having
		(a) no access to packet payload, (b) no knowledge of port
		numbers and (c) no additional information other than what
		current flow collectors provide.  These restrictions respect
		privacy, technological and practical constraints. Second, it
		can be tuned to balance the accuracy of the classification
		versus the number of successfully classified traffic flows. We
		demonstrate the effectiveness of our approach on three real
		traces. Our results show that we are able to classify 80%-90% 
		of the traffic with more than 95% accuracy
		
	A widely used ISP approach is to use traffic shaping devices to
	rate limit P2P (e.g., [6, 7, 19, 20, 28, 33]). These devices rely on
	deep packet inspection or other P2P traffic identification schemes
	(e.g., [11, 31]) (P4P: Provider Portal for Applications) (tää papru on [11])
	
iPlane: An information plane for distributed services
	Madhyastha, Harsha V., et al. "iPlane: An information plane for distributed services." Proceedings of the 7th symposium on Operating systems design and implementation. 2006.¨¨
	
	670 viittausta
	
	Abstract
		In this paper, we present the design, implementation, and
		evaluation ofiPlane, a scalable service providing accu-
		rate predictions of Internet path performance for emerg-
		ing overlay services. Unlike the more common black box
		latency prediction techniques in use today,iPlane
		adopts a structural approach and predicts end-to-end path per-
		formance by composing the performance of measured
		segments of Internet paths. For the paths we observed,
		this method allows us to accurately and efficiently pre-
		dict latency, bandwidth, capacity and loss rates between
		arbitrary Internet hosts. We demonstrate the feasibility
		and utility of theiPlaneservice by applying it to several
		representative overlay services in use today: content dis-
		tribution, swarming peer-to-peer filesharing, and voice-over-IP. 
		In each case, usingiPlane’s predictions leads to
		improved overlay performance.
	
	Karagiannis et al. [12] and Madhyastha et
	al. [17] have observed that locality of P2P connections indeed reduces
	the download time of users. (P4P: Provider Portal for Applications)
	
Exploiting autonomous system information in structured peer-to-peer networks
	Li, Ji, and Karen Sollins. "Exploiting autonomous system information in structured peer-to-peer networks." Proceedings. 13th International Conference on Computer Communications and Networks (IEEE Cat. No. 04EX969). IEEE, 2004.
	
	29 viittausta
	
	Abstract
		With  the  rise  of  peer-to-peer  (P2P)  networks,  two  
		problems have become prominent: (1) reliance on large 
		amounts of probing traffic to improve lookup perform-
		ance;  (2)  no  adequate  information  for  peers  to  
		place  replicas. We believe that there is an emerging need 
		for information  flow  across  network  layers.  In  this 
		work,  we  explore  how  structured  P2P  networks  can  
		exploit  Autonomous System information. We propose a hybrid 
		proximity neighbor selection algorithm which uses the AS-path  
		length  as  a  proxy  for  network  latency  to  re-
		duce  the  number  of  nodes  to  be  probed.  We  find  
		that,  by  using  Autonomous  System  information  
		effectively,  we  can  achieve  lookup  performance  
		approaching  that  based  on  proximity  neighbor  selection,  
		but  with  much  less  network  traffic.  For  example,  our  
		simulation  re-sults  demonstrate  a  92%  reduction  in  
		probing  traffic  with  only  a  2%  increase  in  the  lookup  
		latency  on  a  synthetic  topology.  We  also  present  a  
		heuristic  ap-proach using simple AS topology and scoping informa-
		tion to improve replication in structured P2P networks. 
		Finally  we  discuss  how  our  approach  helps  to  match  
		peer-to-peer activities with administrative boundaries.
		
	Several proposals have suggested using AS
	numbers in peer selection (e.g., [18, 23]) to improve performance
	and reduce cross-network traffic, and this approach has even been
	adopted by several P2P applications (e.g., Neokast and Joost). (Taming the torrent)
	
A Routing Underlay for Overlay Networks
	Nakao, Akihiro, Larry Peterson, and Andy Bavier. "A routing underlay for overlay networks." Proceedings of the 2003 conference on Applications, technologies, architectures, and protocols for computer communications. 2003.
	
	330 viittausta
	
	Abstract
		We argue that designing overlay services to independently probe the Inter-
		net –with the goal of making informed application-speciﬁc routing decisions–
		is an untenable strategy. Instead, we propose a shared routing underlay that
		overlay services query. We posit that this underlay must adhere to two high-
		level principles. First, it must take cost (in terms of network probes) into
		account. Second, it must be layered so that specialized routing services can
		be built from a set of basic primitives. These principles lead to an underlay
		design where lower layers expose large-scale, coarse-grained static infor-
		mation already collected by the network, and upper layers perform more
		frequent probes over a narrow set of nodes. This paper proposes a set of
		primitive operations and three library routing services that can be built on
		top of them, and describes how such libraries could be useful to overlay
		services.
		
	Several proposals have suggested using AS
	numbers in peer selection (e.g., [18, 23]) to improve performance
	and reduce cross-network traffic, and this approach has even been
	adopted by several P2P applications (e.g., Neokast and Joost). (Taming the torrent)
	

	

	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
Tuoreemmat paperit
	A Stochastic Analytical Modeling Framework on ISP–P2P Collaborations in Multidomain Environments 2017
		Zhang, Xu, et al. "A Stochastic Analytical Modeling Framework on ISP–P2P Collaborations in Multidomain Environments." IEEE Systems Journal 12.3 (2017): 2320-2331.
		
		4 viittausta (on tuoreempi tosin)
		
		Index terms
			-Analytical modelling
			-Markov Chain
			-Peer-to-peer (p2p) systems
			-Peer selection algorithms
		
		Abstract
			-Cooperation between peer-to-peer (P2P) overlays and underlying networks has been proposed as an effective approach toimprove the efficiency of both the applications and 
			the underlyingnetworks. 
			-However, fundamental characteristics with respect toInternet service providers (ISP) business relationships and inter-ISP routing information are not sufficiently 
			investigated in thecontext of collaborative ISP–P2P paradigms in multidomain en-vironments. 
			-In this paper, we focus on such issues and developan analytical modeling framework for analyzing optimized inter-domain peer selection schemes concerning ISP policies, 
			with themain purpose of mitigating cross-ISP traffic and enhancing ser-vice quality of end users. 
			-In addition, we introduce an advancedhybrid scheme for peer selections based on the proposed analyticaltheory framework, in accordance with practical network scenar-ios, 
			wherein cooperative and noncooperative behaviors coexisting.
			-Numerical results show that the proposed scheme incorporatingISP policies is able to achieve desirable network efficiency as wellas great service quality for P2P users. 
			-Our analytical modelingframework can be used as a guide for analyzing and evaluatingfuture network-aware P2P peer selection paradigms in generalmultidomain scenarios.
		
		Introduction
			-Theoverlay routing of peer-to-peer (P2P) traffic in the Internet, how-ever, may indirectly violate the business relationships of ISPs, asobserved in [3]
				-[3] J. S. Otto, Mario A. S ́anchez, D. R. Choffnes, F. E. Bustamante, and G.Siganos, “On blind mice and the elephant: Understanding the networkimpact of a large 
				distributed system,” inProc. ACM SIGCOMM, 2011,pp. 110–121.
		
			-In addition, carrying P2P traffic through appli-cation overlays may introduce unexpected extra economic costto ISPs since P2P flows can travel across transit links to 
			reachthe demanded data, even if the content objects can be acquired inlocal ISPs.
				-Such a scenario can impose unnecessary extra trafficvolumes across domain boundaries that usually accounts for theInternet bottlenecks [4]. 
					-[4] V. Aggarwal, A. Feldmann, and C. Scheideler, “Can ISPs and P2P sys-tems co-operate for improved performance?”ACM SIGCOMM Comput.Commun. Rev., vol. 37, no. 3, pp. 29–40, 2007
			
				-And the tussle is becoming even morechallenging with the proliferation of P2P-based applications,e.g., P2P-style video streaming [5] and emerging social mediaapplications, such as 
				Facebook/Pipe [6] and WebRTC [7].
				
			-A coordination between ISPs and P2P networks [4]–[10] hasbeen proposed as an efficient approach to deal with the tus-sle of P2P overlay and ISP underlay interaction, by 
			reducingsubstantial cross-ISP traffic while retaining desired P2P usersquality of experiences (QoE)
				- The basic idea is to provide alist of optimized peer candidates in proximity to each clientpeer by taking into account the context information providedby 
				overlay–underlay collaboration. 
					-Such an approach is of-ten known as thelocality-aware strategies(ornoncooperativestrategy). 
					-A collaboration entity located inside each ISP enablessuch peer selection ranking procedure, by collecting relevantcontext information of the local underlying 
					network topologyfor locality-aware peer selection operations, e.g., the ALTOframework proposed in IETF [11]
						-[11] J. Seedorfet al., “Application-layer traffic optimization (ALTO) problemstatement,” IETF RFC 5693, Oct. 2009
						
						
				[4] V. Aggarwal, A. Feldmann, and C. Scheideler, “Can ISPs and P2P sys-tems co-operate for improved performance?”ACM SIGCOMM Comput.Commun. Rev., vol. 37, no. 3, pp. 29–40, 2007.
				[5] Cisco, “Cisco visual networking index: Forecast and methodology, 2015–2020,” White Paper, Cisco, San Jose, CA, USA, Jun. 2016.
				[6] The Independent News, “P2P file-transfer comes to Facebook with Pipe,”pp. 1–2, Jun. 2013.
				[7] WebRTC 1.0: Real-Time Communication Between Browsers PublicationHistory, pp. 1–20, 2017. [Online]. Available: https://webrtc.org
				[8] H. Xie Y. R. Yang, A. Krishnamurthy, Y. G. Liu, and A. Silberschatz,“P4P: Provider portal for applications,” inProc. ACM SIGCOMM, 2008,pp. 351–362.
				[9] D. Choffnes and F. E. Bustamante, “Taming the torrent: A practical ap-proach to reducing cross-ISP traffic in P2P systems,” inProc. ACM SIG-COMM, 2008, pp. 363–374.
				[10] S. Ren, E. Tan. T. Luo, S. Chen, L. Guo, and X. Zhang, “TopBT: Atopology-aware and infrastructure-independent BitTorrent client,” inProc.IEEE INFOCOM, 2010, pp. 1–9.
						
			-However, under the tradi-tional noncooperative peering strategy, external peers located inremote domains are selected without distinguishing between in-terdomain paths 
			regarding the diversity in business relationshipsamong ISPs. 
				-A few works have been proposed suggesting thatISP business relationships should be taken into considerationin order to encompass the economic benefits of ISPs [12]–[14],
			referred to as theISP-policy-aware strategy(orcooperativestrategy)
			
			-It is worth mentioning that, while these approaches can effec-tively mitigate ISP costs among different interdomain links, theyare barely based on the hypothesis of an 
			ideal all-cooperativeenvironment, and there is still limited understanding of theirperformance on larger scale collaborations across multiple au-tonomous ISP networks from 
			an theoretical standpoint
			
			-In this paper, we aim to systematically address these afore-mentioned research issues by proposing a theoretical frameworkto provide comprehensive and accurate analysis 
			on the followingimportant research question.
				-How should peer selection proce-dure operate in a multidomain scenario, with awareness of bothISP preferences and P2P users capacities diversity?
				
			-Our ob-jective is to analytically quantify the P2P traffic optimizationstrategies across multiple autonomous domains, in order to helpto understand the fundamental design 
			criteria of collaborativeISP–P2P mechanisms in the research community.
			
		Related Work
			-Karagianniset al.[16] introduced the notion of peeringlocalization in the context of BitTorrent. Based on payloadpacket traces and tracker-based logs, their 
			simulation-based re-sults showed that locality-aware solutions are able to signifi-cantly alleviate the induced cost at the ISPs, while providingan efficient performance 
			for end users
				-16] T. Karagiannis, P. Rodriguez, and K. Papagiannaki, “Should Internet ser-vice providers fear peer-assisted content distribution?” inProc. ACM SIG-COMM Conf. 
				Internet Meas., 2005, p. 6
				
			-Danet al.[17] summa-rized specific interaction patterns between ISP and P2P systems,and concludes that both network operators and P2P applicationscould benefit from 
			exchanging information with each other.
				-[17] G. Danet al., “Interaction patterns between P2P content distribution sys-tems and ISPs,”IEEE Commun. Mag., vol. 49, no. 5, pp. 222–230, May2011.
				
			-Relevant analytical works, such as [18], mainlyexplore the impact of P2P traffic on the ISP business benefitswhile [19] modeling the tussle between ISP and P2P systems.
				-However, how peer selections can be evaluated in the scope ofmultidomain has not yet been well examined.	
				
				-[18] J. H. Wang, D. M. Chiu, and J. C. S. Lui, “Modeling the peering androuting tussle between ISPs and P2P applications,” inProc. Int. WorkshopQual. Service, 2006, pp. 51–59.
				-[19] M. Garetto, D. R. Figueiredo, R. Gaeta, and M. Sereno, “A modelingframework to understand the tussle between ISPs and P2P file sharingusers,”Perform. Eval., vol. 64, no. 9, pp. 819–837, 2007

			-Piateket al.[20] discussed the pitfalls for an ISP-friendly locality policy, and three main issues are discussed, with respectto the limited effect on the user side, the 
			degradation on the P2Psystems robustness, and conflicting interests between differentISPs. 
				-The first two issues are mostly addressed by works, suchas Lehriederet al.’s[21], they proposed a refined locality-awarepeer selection to divide ASes into groups 
				based on differentswarms, in order to maintain fairness among P2P users in termsof balanced uploading and downloading capacities. 
				-Regardingthe last issue, however, it is still not well understood.
				
				-[20] M. Piateket al., “Pitfalls for ISP-friendly P2P design,” inProc. ACMHotNets, 2009.
				-[21] F. Lehriederet al., “Mitigating unfairness in locality-aware peer-to-peernetworks,”Int. J. Netw. Manage., vol. 21, no. 1, pp. 3–20, 2011.
				
			-P2P caches are deployed by many ISPs to reduce transit traf-fic through storing popular contents at local ISP [22]. 
				-However,analysis [23] shows that caching can lead to increased transittraffic in certain scenarios. 
				-In order to resolve this issue, Danet al.[24] proposed a cache-to-cache scheme to enable collab-oration between caches deployed by peering ISPs, which haveshown the 
				effectiveness of considering ISP business relationshipinto the concern of P2P traffic localization.
				
				-[22] M. Hefeeda and O. Saleh, “Traffic modeling and proportional partialcaching for P2P systems,”IEEE/ACM Trans. Netw., vol. 16, no. 6,pp. 1447–1460, Dec. 2008.
				-[23] F. Lehrieder, G. Dan, T. Hossfeld, S. Oechsner, V. Singeorzan, “Theimpact of caching on BitTorrent-like peer-to-peer systems,” inProc. IEEEInt. Conf. Peer-to-Peer Comput., 2010, pp. 1–10.
				-[24] G. Dan, “Cache-to-Cache: Could ISPs cooperate to decrease peer-to-peercontent distribution costs?,”IEEE Trans. Parallel Distrib. Syst., vol. 22,no. 9, pp. 1469–1483, Sep. 2011.

			-A few works proposed recently suggesting that peers in re-mote autonomous network systems should be ranked based ondiversity ISP business requirements [12]–[14], [25]–[27]. 
				-Whileconcerning BGP routing polices in peer selections, these worksare mainly developed on the basis of a simple assumption, i.e.,a fully cooperative scenario. 
				-However, congestion risks couldpotentially exist over critical interdomain links under theseproposals. 
				-On the other hand, ISPs are generally reluctant tocollaborate due to privacy concerns. 
				-This would become a hugeburden for the underlying network with P2P traffic constantlygrowing that accounts for a significant volume [3] in the Internet.
				
				-[12] Z. Dulinski, M. Kantor, W. Krzysztofek, R. Stankiewicz, and P. Cholda,“Optimal choice of peers based on BGP information,” inProc. IEEE Int.Conf. Commun., 2010, pp. 1–6.
				-[13] Z. Dulinski, R. Stankiewicz, P. Wydrych, M. Kantor, and P. Cholda, “Cost-driven peer rating algorithm,” inProc. IEEE Int. Conf. Commun., 2011,pp. 1–6.
				-[14] P. Racz, S. Oechsner, and F. Lehrieder, “BGP-based locality promotionfor P2P applications,” inProc. IEEE 19th Int. Conf. Comput. Commun.Netw., 2010, pp. 1–6.
				-[25] J. Dai, B. Li, F. Liu, B. Li, and H. Jin, “On the efficiency of collaborativecaching in ISP-aware P2P networks,” inProc. IEEE INFOCOM, 2011,pp. 1224–1232.
				-[26] E. Agiatzidou and G. D. Stamoulis, “Collaboration between ISPs forefficient overlay traffic management,” inProc. 10th Int. IFIP TC 6 Conf.Netw., 2011, pp. 109–120.
				-[27] M. P. Manzillo, L. Ciminiera, G. Marchetto, and F. Risso, “CLOSER: Acollaborative locality-aware overlay service,”IEEE Trans. Parallel Dis-trib. Syst., vol. 23, no. 6, pp. 1030–3037, Jun. 2011.
				
			-This paper is an extension of our previous work [28], inwhich we show by analytical modeling that a hybrid peer selec-tion can achieve enhanced performance for both ISPs 
			and P2Pusers. 
				-However, in [28], a simple single-homed ISPs scenariowas considered, while, in practice, asymmetrical ISP routingissues exist due to multihomed ISPs, which are taken 
				into ac-count in this paper. 
				-Additionally, considering the importanceand the necessity of maintaining the settlement-free relation-ship between peering ISPs, a boundary condition regarding 
				theP2P traffic exchanged is analyzed. 
				-For comparison purpose,an enhanced locality-aware peer selection is considered and modeled. 
				-We also discuss in this paper the implementation is-sues of the proposed hybrid peer selection strategy.

				-[28] X. Zhang, N. Wang, and M. Howarth, “A hybrid peer selection scheme forenhanced network and application performances,” inProc. IEEE Consum.Commun. Netw. Conf., 2013, pp. 13–21


		-Conclusion
			-In this paper, we develop a comprehensive analytical model-ing framework for multidomain peer selection, based on whichclosed forms of ISP efficiency, economic benefits, 
			and user ef-ficiency are derived. 
			-Based on this modeling framework, wepropose an advanced hybrid peer selection scheme, taking intoaccount of coexisting both cooperative and noncooperative ISPbehaviors in 
			practice. 
			-The theoretical framework facilitates sys-tematic analysis on different aspects of P2P system behaviors.
			-In particular, we have derived bound requirements for ISPs totarget in order to achieve desirable utilities for both ISPs andP2P systems. 
			-The numerical results show that the proposedmechanism is able to achieve significant performance gains forboth P2P systems and ISPs. 
			-Specifically, risks of potential con-gestions over critical inter-ISP links could be greatly alleviated,and possible failure operations of cooperation strategies couldbe 
			avoided as well.
			
			
			
	Is more P2P always bad for ISPs? An analysis of P2P and ISP business models 2014
		-Liao, Qi, Zhen Li, and Aaron Striegel. "Is more P2P always bad for ISPs? An analysis of P2P and ISP business models." 2014 23rd international conference on computer communication and networks (ICCCN). IEEE, 2014

		-4 viittausta
		
		-Abstract
			-Internet   Service   Providers   (ISPs)   face   increasingbandwidth pressure from rising access demand by users, especiallyP2P and VoD applications. 
			-Traditionally, P2P has been viewed astremendously  negative  from  the  perspective  of  the  ISP.  
			-In  thispaper,  we  question  this  assumption  and  study  the  impact  of  P2Papplications  on  the  effective  ISP  functionality.  
			-We  perform  aneconomic analysis to show that a higher P2P penetration rate doesnot  necessarily  lead  to  increased  ISP  bottleneck  link  bandwidthpressure.  
			-Our  results  show  that  the  local  serving  rate  is  criticalfor the sustainability of the ISP business model as well as for thebenefit  of  P2P  users
			
		-Introduction
			-Since  it  is  unlikely  that  ISPs  can  truly  eliminate  P2P,  wewould argue that P2P users and ISPs need to find an equilibriumpoint  that  is  beneficial  to  both  
			sides.  
			-We  note  that  more  P2Papplications  do  not  necessarily  hurt  ISPs  since  higher  P2Ppenetration rate will likely increase content local serving rate.
			-With P2P traffic localization such as P4P [8], ISPs gain since data does not have to traverse the transit link and users gain aswell with lower latency. 
			-Motivated by the desire to seek for apossible mutually beneficial relationship between P2P and ISPs,we  model  their  interactions  in  a  game  theoretical  framework 
			and  solve  the  resulting  optimization  problem.  
			-We  show  thatthere exists a critical value of the local serving rate that wouldmake  ISPs  indifferent  with  or  without  P2P.  
			-The  fact  that  inreality  ISPs  usually  are  not  in  favor  of  P2P  implies  that  theactual  local  serving  rate  may  be  far  below  the  critical  level.
			-We  also  propose  the  concept  ofP2P botsthat  can  potentiallyaffect the local serving rate, i.e., the key determinant of P2P’snet effects on ISPs
			
		-Conclusion
			-As the amount of data transferred over the Internet increasesexponentially  in  the  big  data  era,  ISPs  face  bottleneck  band-width  pressure,  in  particular  from 
			P2P  applications.  
			-However,the  impact  of  P2P  on  ISPs  has  not  been  well  understood.
			-Through  modeling  analysis  and  simulation  study,  we  foundmore  P2P  users  may  not  necessarily  be  a  bad  thing  for  ISPs.
			-We  illustrate  the  direct  impact  of  the  key  determining  factor,the local serving rate of P2P, on the bottleneck link bandwidthand the business model of ISPs. 
			-We also explore the feasibilityof  potential  methods  to  increase  the  local  serving  rate.  
			-Ourequilibrium  solutions  suggest  it  would  be  mutually  beneficialfor  ISPs  to  localize  P2P  traffic,  which  will  allow  the  co-prosperity of both ISPs and P2P 
			networks.
			
			
	The disparity between P2P overlays and ISP underlays: issues, existing solutions, and challenges 2010
		Dai, Jie, Fangming Liu, and Bo Li. "The disparity between P2P overlays and ISP underlays: issues, existing solutions, and challenges." IEEE network 24.6 (2010): 36-41.
		
		19 viittausta
		
		-Abstract
			-The proliferation of peer-to-peer applications has generated tremendous traffic inthe Internet backbone and has also posed unprecedented pressure on Internet Ser-vice 
			Providers. 
			-Many P2P applications, oblivious of underlying ISP networks, canlead to inefficient utilization of Internet resources and a significant amount of costlyinter-ISP traffic. 
			-Recently, increasing efforts have been directed toward mitigatingISP costs from P2P applications while preserving the user perceived service quality.
			-In this article we review state-of-the-art research on P2P applications with particularfocus on their topological properties and navigating algorithms with awareness of ISP 
			costs and performances. 
			-We discuss ISP-friendly designs in P2P applications byidentifying their respective benefits and deficiencies. 
			-Based on the lessons we havelearned, we further highlight future research challenges and issues regarding thejoint design and optimization of P2P system performance and ISP 
			traffic and costs
			
		-Introuduction
			- In particular, the keychallenge that has recently received significant attention inboth research and practice is that on one hand, many network-oblivious P2P 
			applications without awareness of ISP bound-aries can lead to inefficient utilization of Internet resourcesand poor system performance, as well as resulting in 
			immensecosts for ISPs due to the costly inter-ISP traffic; 
				-on the otherhand, current existing ISP-friendly P2P designs that aim to mit-igate inter-ISP traffic by optimizing peering locality could stillincur potential defects 
				in violating ISP policies and degradingthe robustness and performance of P2P applications.
			
		-Conclusion
			-Nowadays, one of the most pressingconcerns of ISPs is the disparitybetween P2P application overlayand  the  ISP  underlay  network, which can lead to costly inter-ISP 
			traffic and inefficient utilization ofnetwork resources. 
			-In this article wereview representative ISP-friendlydesigns that aim to mitigate ISP traffic costs and improve userperceived service quality. 
			-These objectives can be achieved viatopology navigation based on peer locality information, ISP-relevant information, and optimization algorithms regardingcost, 
			performance, and topology concerns. 
			-Caching proxiesdeployed at the boundaries of ISPs can also contribute to thereduction of costly inter-ISP traffic. 
			-Future research should bedirected toward cooperation between ISPs and P2P applica-tions, especially when ISPs can play dual roles of both networkprovider and content 
			provider. 
			-A collaborative caching schemewith regard to traffic cost and policy concerns of ISPs, and crit-ical performance metrics of P2P applications is desired in thefuture to 
			unify the targets of both sides.
		
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
Etsi paperita:
	-jotka ovat tuoreempia
		-A Stochastic Analytical Modeling Framework on ISP–P2P Collaborations in Multidomain Environments 2017
		-Is more P2P always bad for ISPs? An analysis of P2P and ISP business models 2014
		
	-jotka esittävät vasta-argumentteja esitettyihin ratkaisuihin (ja vasta-argumentteja näille vasta-argumenteille!)
		-Pitfalls for ISP-friendly P2P design.
			-Vastaväite taming the torrent:issa esitelly Ono-ratkaisulle
			-Vastaväite tälle paperille:
				Pushing BitTorrent Locality to the limit
					Piatek et al. [23] discuss pitfalls for an ISP-friendly
					locality policy and ISPs traffic engineering constraints. In
					particular, Piatek et al. discuss three main issues: client
					side only localization might not work, localization might
					adversely impact robustness and efficiency, ISPs have conflicting
					interests. The two first issues do not apply to our
					work as we consider a tracker based locality policy, and
					as we have designed and evaluated the partition merging
					strategy to prevent robustness issues. Concerning the last
					issue on ISPs conflicting interests, it is beyond the scope of
					this study to evaluate the economical benefit for tier-1
					ISPs to keep traffic local. Our work shows that if ISPs want
					to apply a locality policy to BitTorrent traffic, it is doable
					and it will significantly reduce the traffic on inter-ISP
					links.
			
		-Can P2P-Users Benefit from Locality-Awareness?
			-Biased neighbour selection ja biased unchoking -perustuvat ratkaisut eivät välttämättä hyödytä käyttäjiä
				-mm.
					-Oraakkeli
					-Ono
					-P4P
			
		
		-TopBT: A Topology-Aware and Infrastructure-Independent BitTorrent Client
			-Onolle ja P4P vastaväitteitä
			-Viittaa pitfallssiin
				Finally, based on a trace analysis,
				a recent study [22] shows that ISP-friendly based BitTorrent,
				such as Ono and P4P, may have limited performance gain, and
				may reduce robustness by focusing on reducing traffic for a
				single ISP.
				
				The significant amount of BT traffic on the Internet has
				caused ISPs to throttle, shape, or even block it. Targeting
				BT traffic reduction, researchers have proposed biased peer
				selection for BT systems by using network intelligence. Papers
				[3] and [15] suggested to select peers in the same ISP.
				The effectiveness of this approach is arguable considering 
				most BT peers are not in the same ISP [22] (22 = pitfalls).
				
		-Locality-awareness in bittorrent-like p2p applications
			The authors point out that there is a tradeoff
			between reducing inter-domain traffic and fairness among
			peers in terms of the data the peers upload
				-(Can P2P-Users Benefit from Locality-Awareness?)
				
	-Ratkaisuehdotuksia (mielellään paljon viittauksia)
		-Cache-ratkaisut
			However, P2P caches need to be designed
			for specific applications and speak the appropriate protocols, which
			limit their generality and applicability to proprietary protocols. In
			addition, ISPs may not want to bear the costs of caches if they
			consider that P2P is a mechanism for content providers to shift distribution
			costs to ISPs. Furthermore, caching contents may lead to
			legal liability.
				-(P4P provider portal for applications)
				
			An Analysis of Internet Content Delivery Systems
			ARE FILE SWAPPING NETWORKS CACHEABLE? CHARACTERIZING P2P TRAFFIC
			HPTP: Relieving the Tension between ISPs and P2P
			MultiCache: An overlay architecture forinformation-centric networking
			Sandvine
				SANDVINE. Sandvine incorporated: Peer-to-peer policy
				management, 2008. http://www.sandvine.com/
				solutions/p2p_policy_mngmt.asp.
				
				Taming the torrent-paperissa
				
			Revisiting Cacheabilityin Times of User Generated Content
		
		-ISPn ratkaisut
		-Middleware-ratkaisut
			-Oraakkeli
			-P4P
			
		-Clienttiratkaisut
		-Muut ratkaisut
							
	-Analyysiä ongelmista
		-Should internet service providers fear peer-assisted content distribution?
		
		-Can ISPs Take the Heat from Overlay Networks
			-Pätee p2p
			
		-Controlling P2P Traffic
			-Nettiartikkeli, https://www.lightreading.com/controlling-p2p-traffic/d/d-id/598203&page_number=3
			
	-P2P/ISP välinen sota
		-Eli keinot joilla ISP estää P2P ja miten P2P välttää näitä estoja
		
		-Pitfalls for ISP-friendly P2P design
			-Detecting BitTorrent blocking
			-Packet Forgery by ISPs: A Report on the Comcast Affair
				http://www.eff.org/wp/packet-forgery-isps-report-comcast-affair
		
		“List of ISPs throttling P2P traffic,” http://www.p2pon.com/guides/list-of-internet-service-providers-that-throttle-p2p-traffic/
		
	-P2P/Bittorrent tarkempi analyysi
		
		
Kulmakivipaperit:
	-1.-4. SIGCOMM paperita
	
	-1. Should internet service providers fear peer-assisted content distribution? (Erityisesti tämä)
		-Lokalisaation mahdollistamat hyödyt
		
	-2. P4p: provider portal for applications
		-Rajapinta jolla palveluntarjoajien verkot voivat kommunikoida sovellusten kanssa
		-Monelle sovellukselle, vaatii niiden suostumusta
		-Pääsee käsiksi verkkotason tietoihin
		
	-3. Taming the torrent: a practical approach to reducing cross-isp traffic in p2p systems (Ono)
		-Lisäosa Azureus-Bittorrent clientille
		-Käyttää olemassa olevaa informaatiota (CDN)
		-Käyttää CDN ikään kuin oraakkelina
			-Ei vaadi uusia infrastruktuurimuutoksia toisin kuin varsinainen oraakkeli
			
		-Ei kuitenkaan ilmeisesti oikeasti tehokas
			-Pitfalls
		
	-4. Can ISPs and p2p users cooperate for improved performance? (Oraakkeli)
		-Oraakkeli, joka asettaa vertaiset paremmuusjärjestykseen paikallisuuden perusteella (ensimmäinen versio, jatkokehitetty pidemmälle)
		-Ilmeisesti ei tarvi muutoksia sovelluksilta (kaappaa peer list-lähetyksiä) (vai tarviiko???????, ainakin taming the torrent paperin mukaan tarvitsisi)
		-Gnutellalle
		-Pääsee käsiksi verkkotason tietoihin
P2P
	-Can download data from multiple sources, so is flexible
		-Scalable
		-Robust
		
	-Mahdollistaa nopeamman latausajan käyttäjille
	-Halvempaa sisällönjakajille
		
	-Käytöt
		-Voice over IP
		-Tiedostojen jako
		-Video streamaus
		
P2P ongelmat:
	-1. Määrä
	-2. Mielivaltainen reititys
		-Sovellukset ja ISPt tekevät omaa reititystään eri kerroksillaan
			-Eivät tietoisia toisistaan
			-P2P ei pääse suoraan käsiksi alusverkon tietoihin
			
		-Hankaloittaa ISP verkkoliikenteenhallintaa
			-P2P liikennettä vaikea ennustaa
			
		-Lisää turhaa ulkopuolelle menevää liikennettä <- aiheutuu lisäkuluja ISP:lle
		
	-3. Lisätty upload-liikenteen määrä (?)
	
Keinot joilla ISPt koittaa hallita P2P liikennettä	
	-Charging
	-Rate throttling
	-Tiettyjen porttien käytön estäminen
		-> P2P rupesi käyttämään satunnaisia portteja
		
	-Packettien tarkastelu
		-> P2P rupesi enkryptaamaan pakettejaan
	
	-Eivät tehokkaita keinoja, tarvitaan yhteistyötä
		-P2P sovellukset keksivät ratkaisuja kiertämään yllämainittuja ongelmia
		
	-Recently, some ISPs have attempted to reduce P2P
	traffic by placing caches at the ISP’s gateway to the Internet or
	by using network appliances (e.g., Sandvine [28]) for spoofing
	TCP RST messages, which trick clients into closing connections
	to remote peers [28, 31]. The legality of these approaches is
	questionable. By caching content, ISPs may become participants in
	illegal distribution of copyrighted material, while interfering with
	P2P flows in a non-transparent way may not only break the law
	but also lead to significant backlash [11].
		-Taming the torrent paperissa
		
	-Jotkut P2P clientit koittaa käyttää paikallisuutta, mutta keinot ovat rajalliset ilman ISP yhteistyötä
		[9] Joost. http://www.joost.org/whatsjoost.html.
		[14] Kontiki. http://www.kontiki.com.
		
		-Vaikea estimoida ja reverse engineeraa verkon tietoja
	
	-A widely used ISP approach is to use traffic shaping devices to
	rate limit P2P (e.g., [6, 7, 19, 20, 28, 33]). These devices rely on
	deep packet inspection or other P2P traffic identification schemes
	(e.g., [11, 31]). Unilateral rate limiting by ISPs can be considered
	strong handed and may lead to P2P reactions such as encryption
	and dynamic ports to avoid being identified. Furthermore, techniques
	such as rate limiting, end-point usage-based charging, or
	priority are mainly for controlling edge traffic demands, not for improving
	network efficiency.
		-(p4p: provider portal for applications)
		
Vastaväitteitä lokalisaatiolle (ainakin suurten tiedostojen suhteen):
	-1. Tiedostot lyhytaikaisia, jälkeen vähemmän vertaisia, lokaliteetti ei enää niin hyödyllinen
	-2. Joillekin käyttäjille saattaisi olla nopeampaa ladata sisältöä verkon ulkopuolelta
	-3. Mahdolliset muutokset verkon ja sen reitityksen rakenteeseen
	-4. Interdomain liikenteen vähentäminen vie tuloja joiltakin ISP, vaikka joiltakin ISP se säästää rahaa
	-5. Ei ole P2P clienttien etujen mukaista
		-Pienempi teho -> Käyttäjät vaihtavat käyttämään toisia clientteja
		
	-6. Asettaa suurta painetta alueille joissa paljon vertaisia
		Pure locality-based peering, however, could cause problems. First,
		consider the high concentration of clients in certain areas such as
		the northeastern part of US. Locality-based peering could cause
		traffic concentrated on a few backbone links.
			-P4P: Provider Portal for Applications
			
	-7. Ei välttämättä ota huomioon että esim. yliopistojen verkot ovat interdomain, mutta sijaitsevat lähellä muita kaupunkilaisia
		Second, consider a heterogeneous deployment where a P2P session
		consists of clients not only in US educational institutions but
		also in non-educational networks. Using only latency or hop count,
		a client might choose to peer with clients that are in the same city
		or nearby cities, but communicate with them through interdomain
		links, leading to unnecessary transit costs.
			-P4P: Provider Portal for Applications
			
		-(6.-7. ovat pure localityä vastaan, mahdollista tehdä järkevämpi paikallisuusratkaisu)
			