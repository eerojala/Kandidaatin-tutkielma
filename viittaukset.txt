Can  ISPs Take the Heat from Overlay Networks?
	Qiu et al. [11] describe the interactions between over-
	lay networks and ISPs after the routing control mecha-
	nisms reach the Nash equilibrium point. In this paper,
	we explore some of the issues that arise due to dynamic
	interactions in the presence of unexpected or unplanned
	events such as network failures. We believe that the dy-
	namic network behavior in the presence of failures (that
	are common, everyday events for ISPs [7]) is very im-
	portant for ISPs and needs to be addressed.
	
	Within each domain, we emulate an IP-layer inte-
	rior gateway protocol (IGP) that implements Dijkstra's
	shortest path algorithm. We generate link failures and
	model IGP dynamics in response to failures as outlined
	in [7] and [8].
	
	ISPs apply TE mainly in reaction to changes in the
	topology (due to link failures [6, 10]) or tra±c demands
	(due to °ash crowd events or BGP failures). In these
	scenarios, a common way for ISPs to manage the tra±c
	is by changing the IGP link weights. ISPs make two
	assumptions while using this technique: (i) tra±c de-
	mands do not vary signi¯cantly over short timescales,
	and (ii) changes in the path within a domain do not im-
	pact tra±c demands. Overlay network routing defeats
	these assumptions as illustrated below.
	
	ISPs employ techniques such as [13] to compute their
	TM i.e., a matrix that speci¯es the tra±c demand from
	origin nodes to destination nodes in a network.


	Viitatut artikkelit: (vain [11] vaikuttaa tutkielmaanhyödylliseltä)
		[6] Internet Tra±c Engineering by Optimizing OSPF Weights
		[7] Feasibility of IP Restoration in a Tier-1 Backbone.
		[8] A New Approach to Characterize IP Backbone Topologies.
		[9] A. Nakao, L. Peterson, and A. Bavier. A Routing Underlay for Overlay Networks. In ACM SIGCOMM, Aug. 2003.
		[10] Link Weight Assignment for Transient Link Failures
		[11] L. Qiu, Y. Yang, Y. Zhang, and S. Shenker. On Selfish Routing in Internet-Like Environments. In ACM SIGCOMM, 2003.
		[13] How to Identify and Estimate the Largest Tra±c Matrix Elements in a Dynamic Environment
		[14] B. Zhao, L. Huang, J. Stribling, A. Joseph, and J. Kubiatowicz. Exploiting Routing Redundancy via Structured Peer-to-Peer Overlays. In ICNP, 2003.
		
	
	Viittaavat Artikkelit:
		P4P: Provider portal for applications X
		Can ISPs and P2P users cooperate for improved performance? X
		On selfish routing in internet-like environments
		Pitfalls for ISP-friendly P2P design X
		A bottleneck-free model for P4P
		Spatial and temporal locality of content in BitTorrent: A measurement study
		
Should internet service providers fear peer-assisted content distribution?
	Peer-assisted solutions are inherently self scalable, in
	that the bandwidth capacity of the system increases as more
	nodes arrive: each new node requests service from, but also
	provides service to, the other nodes. The network can thus
	spontaneously adapt to the demand by taking advantage
	of the resources provided by every end-node, thus making
	it more resilient to “flash crowd” events, which may
	challenge content distribution networks with hundreds of
	servers [10].
		As
		a P2P protocol, BitTorrent enjoys the benefits of a distributed
		system that is inherently more robust to events such
		as flash crowds, shown to be challenging even for CDNs
		with hundreds of servers [10], as well as cheaper in terms
		of infrastructure cost on the part of the content provider.
		
	Content distribution using BitTorrent has been shown to
	offer outstanding performance in terms of content delivery
	rates to the clients [22, 9].
	
	In detail, the BitTorrent file distribution protocol specifies
	the functionality of three main entities [28]
		The nominal format for all
		packets can be found in [28].
	
	The “tit-for-tat” policy is a distinctive advantage of the
	BitTorrent system which renders it ideal for a P2P content
	distribution scheme: Peers are forced to always share
	the content during their downloads while “free-riders” [2]
	are indirectly banned from the network.
	
	Previous work on BitTorrent has focused on measurements
	[4, 9], theoretical analysis [22], and improvements [27].
		Izal et al. analyze the log of a BitTorrent tracker showing
		the flash-crowd effect of a single file, download speeds,
		and the amount of time that peers stay after they have completed
		the download [9]
		
		Pouwelse et al. present an extensive
		analysis of BitTorrent showing availability, peer uptimes,
		and providing a better understanding of peer interarrival
		times [21].
		
	Apart from BitTorrent, several measurement studies
	have addressed the issues of availability [2, 3, 8], integrity
	[29], flash-crowds [4][14], and download performance
	[1][26][25][3] in other P2P systems.
		Saroiu et
		al. use SProbe (sprobe.cs.washington.edu) to measure the
		bandwidth of Gnutella peers [25].
		
		Liang et al. provide
		an extensive study of the performance of the KaZaA network
		[15]
		
		An analysis of Gnutella traces in terms of resource
		demand, popularity of particular search terms, overlay
		topology, and node latency was presented by Nogueira
		et al. [18].
		
		Gnutella data, was also examined by Ripeanu
		and Foster [23], focusing on node connectivity, overlay
		topology, and protocol message overhead.
		
		A trace analysis
		of the network traffic from the perspective of traffic characterization
		and bandwidth provisioning was presented by
		Sen and Wang [26].
		
		Markatos [16] conducted a study of
		Gnutella protocol traffic aimed at caching query/response
		traffic to reduce network load.
		
	The fact that users in peer-assisted solutions
	only form a sharing community only while downloading
	the same file, significantly differentiates them from
	other existing file-sharing applications and has important
	implications in the potential benefit of locality-based solutions.
	For instance, [24] provides an extensive analysis of
	content delivery systems, including CDN caching, KaZaa,
	and Gnutella. However, their results do not carry over well
	to peer-assisted solutions such as BitTorrent where cooperation
	only happens if clients are active and sharing the
	same file.
	
	Regarding the locality analysis, previous studies have
	proposed new ways of clustering peers (e.g. [5][19][20])
	and studied the potential benefits of locality in P2P filesharing
	systems such as KaZaa and Gnutella [8][24].

	
	Viitatut Artikkelit:
		[2]: Understanding availability
		[4]: Incentives build robustness in Bittorrent
		[5]: PIC: Practical Internet Coordinates for Distance Estimation
		[8]: Measurement, modeling, and analysis of a peer-to-peer filesharing workload
		[9]: Dissecting BitTorrent: Five Months in a Torrent’s Lifetime
		[10]: Flash Crowds and Denial of Service Attacks: Characterization and Implications for CDNs and Web Sites.
		[19]: An investigation of geographic mapping techniques for internet hosts
		[20]: Lighthouses for scalable distributed locations
		[21]: The Bittorrent P2P File-sharing System: Measurements and Analysis
		[22]: Modeling and performance analysis of bittorrent-like peer-to-peer network
		[24]: An Analysis of Internet Content Delivery Systems
		[25]: A Measurement Study of Peer-to-Peer File Sharing Systems
		[27]: Slurpie: A cooperative bulk data transfer protocol
		[28]: Bittorrent Protocol Specification v1.0. http://wiki.theory.org/BitTorrentSpecification.
		
	Viittaavat Artikkelit:
		P4P: Provider portal for applications X
		Taming the torrent: a practical approach to reducing cross-isp traffic in peer-to-peer systems X
		Can ISPs and P2P users cooperate for improved performance? X
		Traffic Modeling and Proportional Partial Caching for Peer-to-Peer Systems
		Peer-to-Peer systems
		Modeling and Caching of Peer-to-Peer Traffic
		MultiCache: An overlay architecture for information-centric networking
		Pushing BitTorrent locality to the limit
		Pitfalls for ISP-friendly P2P design. X
		Improving user and ISP experience through ISP-aided P2P locality
		Locality-Awareness in BitTorrent-Like P2P Applications
		
Can ISPs and P2P Users Cooperate for Improved Performance?
	On the one hand, P2P system applications have resulted
	in an increase in revenue for ISPs, as they are one of the major
	reasons cited by Internet users for upgrading their Internet access
	to broadband [6]. On the other hand, ISPs find that P2P traffic
	poses a significant traffic engineering challenge [4, 7].
	
	P2P traffic
	often starves other applications like Web traffic of bandwidth [8],
	and swamps the ISP network. This is because most P2P systems
	rely on application layer routing based on an overlay topology on
	top of the Internet, which is largely independent of the Internet routing
	and topology [9].
	
	To construct an overlay topology, unstructured P2P networks
	usually employ an arbitrary neighbor selection procedure [5]. This
	can result in a situation where a node in Frankfurt downloads a
	large content file from a node in Sydney, while the same information
	may be available at a node in Berlin.
	
	It has been shown that
	P2P traffic often crosses network boundaries multiple times [9, 10].
	This is not necessarily optimal as most network bottlenecks in the
	Internet are assumed to be either in the access network or on the
	links between ISPs, but not in the backbones of the ISPs [11].
	
	Besides,
	studies have shown that the desired content is often available
	“in the proximity” of interested users [10, 12].
	
	To better understand the origin of the problem of overlay-underlay
	routing clash, let us consider how routing works in the Internet and
	P2P systems. In the Internet, which is a collection of Autonomous
	Systems (ASes), packets are forwarded along a path on a per-prefix
	basis. This choice of path via the routing system is limited by
	the contractual agreements between ASes and the routing policy
	within the AS (usually shortest path routing based on a fixed per
	link cost) [13].
	
	P2P systems, on the other hand, setup an overlay topology and
	implement their own routing [14] in the overlay topology which is
	no longer done on a per-prefix basis but rather on a query or key
	basis. In unstructured P2P networks queries are disseminated, e.g.,
	via flooding [15] or random walks while structured P2P networks
	often use DHT-based routing systems to locate data [5]. Answers
	can either be sent directly using the underlay routing [5] or through
	the overlay network by retracing the query path [15]. By routing
	through the overlay of P2P nodes, P2P systems hope to use paths
	with better performance than those available via the Internet [14,
	16].
	
	In other words, P2P systems
	reinvent and reimplement a routing system whose dynamics should
	be able to interact with the dynamics of the Internet routing [7, 17].
	
	While we do not know of a P2P network that tries to reverseengineer
	the Internet topology, there are some proposals that suggest
	that P2P networks should bias their overlay topology by choosing
	neighbors that are close in the sense of high throughput or low
	latency, e.g., [18, 19, 20] or that are within the same AS, e.g., [10,
	21].
	
	Others such as the Brocade [22] system propose to build an
	overlay on top of a structured DHT P2P system that exploits knowledge
	of the underlying network characteristics. Yet another system
	[8] proposes to use caching to relieve the tension between ISPs
	and P2P systems.
	

	Viitatut artikkelit:
		[1] A. Nakao, L. Peterson, and A. Bavier, “A Routing Underlay for Overlay Networks,” in SIGCOMM, 2003.
			"This is because P2P systems either implement their own routing in the overlay topology or may use a P2P routing underlay [1],--"
			"While a routing underlay as proposed by Nakao et al. [1] can reduce the work duplications it cannot by itself overcome the interaction problems"
			
		[4] Light Reading, “Controlling P2P Traffic,” http://www.lightreading.com/document.asp?site=lightreading&doc_id=44435&page_number=3.
			"On the other hand, ISPs find that P2P traffic poses a significant traffic engineering challenge [4, 7]."
			
		[5] R. Steinmetz and K. Wehrle, P2P Systems and Applications, Springer Lecture Notes in CS, 2005.
			
		[6] T. Mennecke, “DSL Broadband Providers Perform Balancing Act,” http://www.slyck.com/news.php?story=973
			
		[7] R. Keralapura, N. Taft, C. Chuah, and G. Iannaccone, “Can ISPs Take the Heat from Overlay Networks?,” in HotNets, 2004.
		[8] G. Shen, Y. Wang, Y. Xiong, B. Zhao, and Z. Zhang, “HPTP: Relieving the Tension between ISPs and P2P,” in IPTPS, 2007.
			"P2P traffic often starves other applications like Web traffic of bandwidth [8],---"
			"Yet another system [8] proposes to use caching to relieve the tension between ISPs and P2P systems."
			
		[9] V. Aggarwal, S. Bender, A. Feldmann, and A. Wichmann, “Methodology for Estimating Network Distances of Gnutella Neighbors,” in GI Jahrestagung - Informatik 2004, 2004.
			
		[10] T. Karagiannis, P. Rodriguez, and K. Papagiannaki, “Should ISPs fear Peer-Assisted Content Distribution?,” in IMC, 2005.
			"As more of the P2P traffic is localized within an ISP the available bandwidth may increase as it is no longer capped by the peering links [10]."
			
		[11] A. Akella, S. Seshan, and A. Shaikh, “An Empirical Evaluation of Wide-Area Internet Bottlenecks,” in ACM IMC, 2003.
		[12] A. Rasti, D. Stutzbach, and R. Rejaie, “On the Long-term Evolution of the Two-Tier Gnutella Overlay,” in Global Internet, 2006.
		[13] S. Halabi, Internet Routing Architectures, Cisco Press, 2000. (Kirja)
		[14] D. Andersen, H. Balakrishnan, M. Kaashoek, and R. Morris, “Resilient Overlay Networks,” in SOSP, 2001.
			
		[17] S. Seetharaman and M. Ammar, “On the Interaction between Dynamic Routing in the Native and Overlay Layers,” in INFOCOM, 2006.
			"In other words, P2P systems reinvent and reimplement a routing system whose dynamics should be able to interact with the dynamics of the Internet routing [7, 17]."
			
		[18] S. Ratnasamy, M. Handley, R. Karp, and S. Shenker, “Topologically aware overlay construction and server selection,” in INFOCOM, 2002
		[19] K. Shanahan and M. Freedman, “Locality Prediction for Oblivious Clients,” in IPTPS, 2005.
		[20] M. Adler, R. Kumar, K. Ross, D. Rubenstein, T. Suel, and D. Yao, “Optimal Selection of Peers for P2P Downloading and Streaming,” in INFOCOM, 2005.
		[21] Bindal et.al., “Improving Traffic Locality in BitTorrent via Biased Neighbor Selection,” in IEEE ICDCS, 2006.
		
	Viittaavat artikkelit:
		P4P: Provider portal for applications X
		Taming the torrent: a practical approach to reducing cross-isp traffic in peer-to-peer systems X
		Pushing BitTorrent locality to the limit 
		Traffic localization for P2P-applications: The ALTO approach
		Pitfalls for ISP-friendly P2P design.
		Cache-to-Cache: Could ISPs Cooperate to Decrease Peer-to-Peer Content Distribution Costs?
		ISP-friendly live P2P streaming
		Can P2P-Users Benefit from Locality-Awareness?
		Improvement of BitTorrent Performance and Inter-domain Traffic by Inserting ISP-Owned Peers
		The Impact of Caching on BitTorrent-Like Peer-to-Peer Systems
		Efficiency of caches for content distribution on the Internet
		ISP-Friendly Peer Selection in P2P Networks
		
		
Pitfalls for ISP-Friendly P2P Design
	Network oblivious sharing increases costs for ISPs. As
	demand increases on transit links, backbone ISPs are forced
	to invest in increasing capacity. These costs are passed
	on to edge ISPs that pay transit costs proportional to the
	amount of interdomain traffic they generate. Many customer
	facing ISPs, however, offer flat-rate pricing, forcing
	them to absorb the costs externalized by P2P file sharing.
	In response, some ISPs have elected to rate-limit or simply
	block these “problem” protocols [4, 14], in turn leading
	developers into an arms race to evade restrictions.
	
	Saroiu et al. [17] and Gummadi
	et al. [6] examine the Gnutella and Kazaa workloads,
	document the increasing popularity of P2P systems,
	study the impact of caching and the potential for bandwidth
	savings of a locality aware mechanism.

	Sen and
	Wang [18] perform trace analysis of P2P traffic along the
	border routers of a single ISP and provide data that suggests
	that application-level traffic engineering might help.
	
	For instance, Keralapura et al. [9]
	show that P2P systems could have an adverse impact on
	the stability of traffic engineering techniques currently used
	by ISPs in the absence of cooperation.
	
	The notion of ISPs manipulating existing protocols to
	accomplish traffic engineering goals or for strategic benefit
	has also received attention by researchers.
		Wang et
		al. report widespread use of path prepending to influence
		routing [19]. Mahajan et al. suggest additional protocol
		mechanisms by which ISPs coordinate their actions to overcome
		common inefficiencies in interdomain routing [13],
		but efficient outcomes depend on mutual trust between
		ISPs. More recently, Goldberg et al. [5] examine the incentives
		for ISPs to manipulate routing announcements
		to attract generic revenue-generating traffic and find that
		ensuring honesty likely requires substantial restriction in
		policy freedom. 
		
		We apply similar ideas to the interaction
		between ISPs and P2P applications and quantify the potential
		for increasing revenue with measured workloads.
		
	Viitatut artikkelit
		[1] V. Aggarwal, A. Feldmann, and C. Scheideler. Can ISPs
		and P2P systems cooperate for improved performance?
		ACM CCR, 2007
		
		[2] R. Bindal, P. Cao, W. Chan, J. Medval, G. Suwala,
		T. Bates, and A. Zhang. Improving Traffic Locality in
		BitTorrent via Biased Neighbor Selection. In Proc. of
		IEEE ICDCS, 2006.
		
		[3] D. R. Choffnes and F. E. Bustamante. Taming the Torrent:
		A practical approach to reducing cross-ISP traffic in P2P
		systems. In SIGCOMM, 2008.
		
		[4] M. Dischinger, A. Mislove, A. Haeberlen, and K. P.
		Gummadi. Detecting BitTorrent blocking. In IMC, 2008.   ------------------------------------- kato tää
		
		[6] K. P. Gummadi, R. Dunn, S. Saroiu, S. Gribble, H. Levy,
		and J. Zahorjan. Measurement, Modeling and Analysis of a Peer-to-Peer File-Sharing Workload. In SOSP, 2003.
		
		[8] T. Karagiannis, P. Rodriguez, and K. Papagiannaki.
		Should Internet Service Providers fear Peer-Assisted
		Content Distribution? In IMC, 2005.
		
		[9] R. Keralapura, N. Taft, C.-N. Chuah, and G. Iannaccone.
		Can ISPs take the heat from overlay networks? In
		HotNets, 2004.
		
		[11] Lightreading.com. P2P plagues service providers. http:
		//www.lightreading.com/document.asp?doc id=31767,
		Apr. 2003.
		
		[14] Packet Forgery by ISPs: A Report on the Comcast Affair.
		http://www.eff.org/wp/packet-forgery-isps-report-comcast-affair.
		
		[17] S. Saroiu, K. P. Gummadi, R. Dunn, S. Gribble, and
		H. Levy. An Analysis of Internet Content Delivery Systems. In OSDI, 2002.
		
		[18] S. Sen and J. Wang. Analyzing peer-to-peer traffic across large networks. IEEE/ACM Trans. on Netw., 2004.
		
		[19] H. Wang, R. K. C, C. Dah, M. Chiu, and J. C. S. Lui. 
		Characterizing the performance and stability issues of the as path prepending method: taxonomy, measurement study and analysis. 
		In SIGCOMM Asia Workshop, 2005.
		
		[20] H. Xie, R. Yang, A. Krishnamurthy, Y. Liu, and
		A. Silberschatz. P4P: Provider portal for P2P applications.
		In SIGCOMM, 2008.
		
	Viittaavat artikkelit
		Pushing bittorrent locality to the limit (ottaa kantaa tämän paperin väitteisiin)
		Peer-assisted content distribution in akamai netsession (ei ota kantaa)
		TopBT: A Topology-Aware and Infrastructure-Independent BitTorrent Client (on samaa mieltä paperin kanssa)
		Deep diving into bittorrent locality (helkan kautta saatu artsa ei viittaa, http://netcom.it.uc3m.es/sites/default/files/pdf/publications/2011/Deep_DIving_BitTorrent_2011.pdf tässä viitataan)
			--https://ieeexplore.ieee.org/abstract/document/5935324 tää versio vissiin se johon ne haluaa että viitataan
		On the efficiency of collaborative caching in ISP-aware P2P networks (samaa mieltä, mutta oma ratkaisu perustuu välimuisteihin eikä biased neighbour selectioniin)		
		Can p2p-users benefit from locality-awareness?
		Mitigating unfairness in locality-aware peer-to-peer networks
					Piatek et al. [14] present three pitfalls for ISP-friendly P2P design: limited impact, reduced performance
		and robustness, and conflicting interests. They show that locality-aware peer selection has no
		impact when there are only very few peers of a swarm in the same AS. The second issue is similar to
		the focus of this paper and investigates application performance. The third pitfall considers different
		types of ISPs and the authors argue that strategical behavior of ISPs can limit the applicability of
		locality awareness. The difference from this study is that we focus on the users’ point of view and
		simulate a BitTorrent swarm with detailed peer behaviors, e.g., the choke algorithm with the tit-for-tat
		policy. In addition, we simulate the concrete implementations of locality awareness mechanisms
		currently under discussion, i.e., BNS, BU, and the combination of both. In this way we show that
		different implementations lead to a different application performance, which is neglected in Piatek
		et al. [14].
		
Can P2P-Users Benefit from Locality-Awareness?
	Locality-awareness is one of the most promising concepts in
	this field. It equips peers with knowledge about the underlying
	network topology, e.g., to which autonomous system (AS) they
	belong. This information enables peers to prefer local neighbors,
	i.e., peers located in the same AS, for data exchange.
	Various implementations of this concept have been proposed
	and evaluated in literature, e.g. in [1], [2], [3], or [4].
	
	In contrast to the aforementioned work, we show in this
	paper that a win-no lose situation is difficult to achieve under
	the real-life conditions we observe in today’s Internet. The
	scenarios we investigate here differ mainly in two aspects from
	the ones considered in the previous work: First, we consider
	skewed peer distributions, i.e., a few ASes contain a large
	number of peers and most ASes contain only very few peers.
	According to the measurement studies presented in [5] and [6],
	these distributions are typical for today’s BitTorrent swarms.
	
	Second, not all peers in a swarm have the same access speeds
	(cf. [7]) as assumed in most previous works. Conversely, we
	study the impact of locality-awareness for peers with different
	access speeds.
	
	Some ISP-based solutions are
	under discussion which do not require the P2P users or the
	overlay providers to cooperate [1].
	
	One of the first approaches to locality-awareness in P2P
	networks was proposed in [3]. There, peers query a so-called
	“oracle” which is maintained by the ISP where the respective
	peers are located. The oracle ranks the peers according to
	the preferences of the ISP and sends this information back to
	the peers. Consequently, they can include traffic engineering
	policies in their peer selection. The evaluation is based on the
	Gnutella protocol. In contrast, we use the BitTorrent protocol
	in this study because it is the most widely used P2P protocol
	today, mainly contributing to the high load of P2P traffic in
	the networks
	
	In [1], Bindal et al. propose biased neighbor selection (BNS)
	for BitTorrent-like P2P systems. With BNS, the neighbor
	set of a peer is modified to contain preferentially peers in
	the same AS. This can for example be implemented by a
	modified tracker which is aware of the ASes where peers are
	located. The evaluation of BNS in [1] uses simulations with a
	homogeneous peer distribution of 700 peers over 14 ASes. The
	results show that a large fraction of the inter-AS traffic can be
	saved by BNS and that the median as well as 95th percentile
	of the download times are decreased.
	
	In [2], an approach very
	similar to BNS is investigated by experiments of up to 10.000
	real BitTorrent clients which are homogeneously distributed
	among 10 ASes. According to the results, BitTorrent locality
	can be “pushed to the limit”, i.e., the neighbor set of all
	peers contains almost only local peers, without degrading the
	performance for the viewpoint of a P2P user.
	
	The P4P project [8] goes further and also considers the
	intra-AS topologies in addition. The authors propose to create
	an iTracker that communicates to the P2P application and
	gives recommendations about which peers to contact.
	
	Finally,
	a plugin called “Ono” for the open-source BitTorrent client
	Vuze is presented and evaluated in [9]. The main difference
	of Ono to the approaches described above is that it does not
	rely on a central entity which guides the inclusion of peers in
	the neighbor set of a peer. Instead, it uses the similarity of the
	redirection ratio of CDN servers as a metric describing how
	close peers are.
	
	Biased unchoking (BU) is a complementary mechanism to
	BNS proposed in [4]. It does not influence the neighbor set of a
	BitTorrent peer but the choke algorithm which determines the
	actual data exchange in a BitTorrent P2P network. Like in [1]
	and [2], the study is based on a homogeneous peer distribution
	and shows that inter-AS traffic can be saved without decreasing
	the efficiency of the distribution process seen by the users, i.e.,
	without increased download times.
		A similar approach to [4]
		is taken in [10] and the evaluation in a PlanetLab environment
		shows that download times can be slightly reduced on average.
		
	The work presented in [11] compares different localityawareness
	solutions for BitTorrent-based file-sharing and
	video-streaming. The authors point out that there is a tradeoff
	between reducing inter-domain traffic and fairness among
	peers in terms of the data the peers upload. They also study
	the download and stall time of the peers but do not consider
	the impact of the distribution of the peers over the ASes.
	
	In contrast to the studies mentioned above, we focus on
	scenarios with swarm sizes and peer distributions observed
	in real BitTorrent swarms [5], [6], i.e, with heterogeneous
	peer distributions and heterogeneous access bandwidths of
	the peers. We study their impact on the performance of a
	BitTorrent network for the P2P user and explain which users
	can benefit from locality-awareness and which not.

	In [12], the authors present three pitfalls for ISP-friendly
	P2P design: limited impact, reduced performance and robustness,
	and conflicting interests. They show that localityaware
	peer selection has no impact when there are only very
	few peers of a swarm in the same AS. The second issue is
	similar to the focus of this paper and investigates application
	performance. The third pitfall considers different types of ISPs
	and the authors argue that strategical behavior of ISPs can
	limit the applicability of locality-awareness.
		The difference to
		this study is that we focus on the users’ point of view and
		simulate a BitTorrent swarm with detailed peer behaviors, e.g.,
		the choke algorithm with the tit-for-tat policy. In addition, we
		simulate the concrete implementations of locality-awareness
		mechanisms currently under discussion, i.e., BNS, BU, and
		the combination of both.
		
		In this way we show that different
		implementations lead to a different application performance,
		which is neglected in [12], and explain which users benefit
		in which scenarios by using BNS, BU, or the combination of
		them.
		
	The Internet-draft “Mythbustering P2P Locality” [13] is a
	collection of facts and conclusions regarding the performance
	improvements by locality-awareness. It mentions that application
	performance may suffer and that a swarm may be
	weakened by a locality-aware peer selection without giving
	concrete evaluation results.
		-Ei siis hyvä lähde
		
	A large-scale measurement campaign which analyzes the
	AS-distribution of peers in more than 250,000 BitTorrent
	swarms is presented in [6]. For the measurements, all movieand
	music .torrent-files have been downloaded from the Mininova
	index site in April 2009 and the AS-distribution of the
	peers was obtained via distributed measurements. The study
	reveals that the AS-distribution is heavily skewed and the
	authors propose to model the probability P(k) that a peer
	belongs to the k-th top AS of a swarm involving n ASes as
	P(k) = a/kb + c. The parameters a, b, and c depend on the
	actual swarm size and the number of involved ASes.
	
	The approach taken in [5] is very similar. The authors
	propose to model P(k) = K/(k + q) as a Mandelbrot-
	Zipf distribution where K = 1/Pn
	k=1 1/(k + q) and the
	parameters q and  are used to fit the data. The measurements
	were performed during the years 2007 and 2008 and comprise
	more than 70,000 BitTorrent swarms mainly advertised by
	www.btmon.com.
	
	A detailed
	description of BitTorrent can be found in [14] and [15].
	
	Both mechanisms need a locality metric to decide which
	peers are considered closer than others. The predominant solution
	in literature, e.g., used in [1], [2], [4], is to differentiate
	between peers in the same AS (local peers) and peers in
	other ASes (remote peers). Therefore, we keep this simple
	differentiation and assume that all peers have access to the
	information which other peers are local or remote to them.
	This could be implemented in practice for example by an
	information service provided by the ISP [16] or by contacting
	public databases.
	
	1) Biased Neighbor Selection: BNS is a rather general approach
	suitable for most overlays. As a consequence, different
	forms of it are proposed in [1], [3], [8], [9]. It changes the process
	of the overlay neighbor selection, so that more local peers
	are established as neighbors. For BitTorrent-based overlays,
	there are two major alternatives for a BNS implementation,
	namely the tracker-based and the peer-based BNS. The first
	changes the responses of the tracker so that no longer random
	peers from the swarm are returned. Instead, the response
	includes a configurable share of local peers. Provided that the
	tracker has access to this kind of locality information, this
	change is easy to implement since it affects only the tracker
	[1]. However, it takes the decision about promoting locality
	from the end user.
	
	2) Biased Unchoking: The biased unchoking (BU) mechanism
	evaluated here was presented in [4] and is specifically
	targeted to BitTorrent-like P2P networks. It works as follows:
	local neighbors are preferred in the unchoking process, i.e.,
	chunks are preferentially uploaded to local peers. To this end,
	the optimistic unchoke slot is assigned to a local neighbor with
	probability lBU if a local neighbor is present. Via the tit-fortat
	policy of BitTorrent, this small modification has also an
	impact on the three regular unchoke slots.
	
	The arrival process of the peers is modeled as a Poisson
	process with a mean inter-arrival time of 10 s. After a peer
	has downloaded the whole file, it remains in the swarm for
	an additional seeding time. The seeding time is exponentially
	distributed and on average 10 minutes long. As a result, we
	measured that the swarm contains on average about 100 to 200
	peers. According to a measurement study of real BitTorrent
	swarms [6], these are typical values for medium-sized swarms
	observed in practice.
	
	The simulator used in this work is based on the P2P
	simulation and prototyping Java framework ProtoPeer [17],
	[18]. The simulator contains a flow-based network model
	adopting the max-min-fair-share principle [19]. It mimics the
	property of TCP that the bandwidth of a link is shared
	among competing data flows. Still, the computational effort
	is smaller than for a packet-based network model. This is
	important since every simulation run consists of more than
	2300 BitTorrent peers simulated in detail and several runs have
	to be performed for each scenario. On top of the ProtoPeer
	framework, we implemented the BitTorrent functionality and
	behavior as described in [14] and [15]. This implementation
	includes all key mechanisms, in particular the piece selection
	mechanisms, the management of the neighbor set, and the
	choke algorithm. Furthermore, the complete message exchange
	among the peers themselves and between peers and the tracker
	is simulated in detail.
	
	As a result, we
	measured that the swarm contains on average about 100 to 200
	peers. According to a measurement study of real BitTorrent
	swarms [6], these are typical values for medium-sized swarms
	observed in practice
	
	In this study, we investigate heterogeneous peer distributions,
	i.e., some ASes contain more peers than others. This
	is motivated by the fact most of the peers participating in a
	swarm are usually located in a small number of ASes [5],
	[6].
	
	In addition to heterogeneous peer distributions, we investigate
	scenarios with heterogeneous access speeds of the peers.
	Measurements in [7] show that the peers in a swarm can be
	clustered according to their access speeds. That means that
	for example 20% of the peers in a swarm have 128 kbps
	upload capacity, 30% have 256 kbps, 40% have 512 kbps and
	the rest is faster. The concrete numbers and cluster sizes
	depend mainly on the ISP where the peers are located

	Viitatut artikkelit
		[1] Improving traffic locality in bittorrent via biased neighbor selection
		[2] Pushing BitTorrent Locality to the Limit
		[3] Can ISPs and P2P systems co-operate for improved performance?		
		[4] Pushing the performance of biased neighbor selection through biased unchoking
		[5]	On the locality of bittorrent-based video file swarming.
		[6] Measurement of bittorrent swarms and their as topologies,
		[7] Characterizing residential broadband networks
		[8] P4P: Provider portal for applications
		[9] Taming the torrent: a practical approach to reducing cross-ISP traffic in Peer-to-Peer systems
		[10] TopBT: a topology-aware and infrastructureindependent bittorrent client
		[11] Locality-awareness in bittorrent-like p2p application
		[12] Pitfalls for isp-friendly p2p design
		[14] Rarest first and choke algorithms are enough
		[15] Bittorrent specification http://wiki.theory.org/BitTorrentSpecification
		[16] The SmoothIT project, “http://smoothit.org/,” 2008.
		
	Viittaavat artikkelit
		Characterization of BitTorrent swarms and their distribution in the Internet (Samoja tyyppejä)
		Mitigating unfairness in locality‐aware peer‐to‐peer networks (Samoja tyyppejä)
			
P4P: Provider Portal for Applications
	Second, for interdomain, network-oblivious P2P may generate a
	significant amount of interdomain transit traffic [12] or relay a substantial
	amount of traffic between the providers of a network [30].
	
	In [12], Karagiannis et al. studied the behaviors of BitTorrent on
	a university network. They found that 50%-90% of existing local
	pieces in active users are downloaded externally. Even for tier-1
	ISPs who do not make payments to network providers, P2P traffic
	may cause traffic imbalance with its peers, leading to potential
	violation of peering agreements. Such inefficiency in interdomain
	traffic may lead to serious disruption to ISP economics
	
	Third, P2P’s dynamic traffic distribution patterns do not necessarily
	enjoy a synergistic coexistence with network traffic engineering
	[13, 24] – network providers go to great lengths to estimate
	traffic patterns and determine routing based on them, but all of
	this effort could be negated if P2P applications adapt their traffic to
	changes in the network, thereby resulting in potential oscillations
	in traffic patterns and sub-optimal routing decisions.
	
	On the other hand, P2P applications have also unilaterally tried
	to improve network efficiency by utilizing peering flexibility. For
	example, several popular P2P applications such as Joost [9] and
	Kontiki [14] strive to localize application-level peering within the
	same autonomous system. However, there are fundamental limits
	on what P2P can achieve alone: to improve network efficiency, P2P
	applications will have to rely on inferring various types of network
	information such as topology, congestion status, cost, and policies.
	Reverse engineering of such information, in particular cost and policy
	information, is challenging if not impossible.
	
	ISP Approaches
		While ISPs have clear incentives to improve network
		efficiency, existing approaches have limitations. The traditional
		approach to improving network efficiency is traffic engineering
		(e.g., [2, 10]). However, an implicit assumption of traditional
		traffic engineering is that the end-to-end traffic pattern is not fungible,
		in the sense that one cannot change the source or the destination
		of a traffic flow. In our project, we consider the fact that the same
		data may be available from multiple sources and that emerging applications
		such as P2P may have tremendous flexibility in rewiring
		their traffic patterns to improve network efficiency.
		
		There are several possibilities on how to control the traffic patterns
		of P2P by ISPs. One proposal is to deploy P2P caching devices
		to cut down bandwidth consumed by P2P applications (e.g., [8,
		12, 16, 27, 29, 32, 36]). However, P2P caches need to be designed
		for specific applications and speak the appropriate protocols, which
		limit their generality and applicability to proprietary protocols. In
		addition, ISPs may not want to bear the costs of caches if they
		consider that P2P is a mechanism for content providers to shift distribution
		costs to ISPs. Furthermore, caching contents may lead to
		legal liability.
		
		A widely used ISP approach is to use traffic shaping devices to
		rate limit P2P (e.g., [6, 7, 19, 20, 28, 33]). These devices rely on
		deep packet inspection or other P2P traffic identification schemes
		(e.g., [11, 31]). Unilateral rate limiting by ISPs can be considered
		strong handed and may lead to P2P reactions such as encryption
		and dynamic ports to avoid being identified. Furthermore, techniques
		such as rate limiting, end-point usage-based charging, or
		priority are mainly for controlling edge traffic demands, not for improving
		network efficiency.
		
	P2P Approaches
		A few P2P applications have developed techniques
		to localize traffic, and there are many techniques for identifying
		locality (e.g., same AS, low latency, closeness to some landmarks).
		Several commercial P2P applications also claim using locality
		in peer selection. Karagiannis et al. [12] and Madhyastha et
		al. [17] have observed that locality of P2P connections indeed reduces
		the download time of users. However, as we discussed, there
		are many limitations on P2P determining locality. In our project,
		we target a fundamental solution and leverage the fact that the ISPs
		are best-positioned to determine locality and to direct applications
		to not only nearby peers but also to peers that are accessible over
		well-provisioned links.
		
		There is also previous work on how to design P2P applications
		that limit their own transfer rates to share network resources with
		other traffic (e.g., [15, 34]). However, these approaches, similar to
		the ISP rate limiting approaches, are mainly for controlling traffic
		demands, instead of for improving network efficiency.
		
	Network Architecture
		There are previous proposals on introducing
		network intermediates and middlewares into the Internet
		architecture (e.g., [25]). However, we are not aware of any previous
		proposals on ISP interfaces to achieve higher network efficiency
		except [1], in which Aggarwal et al. independently proposed
		a scheme in which each ISP provides an oracle. When a
		new node/peer joins a P2P application, the oracle is presented with
		a list of IP addresses to be sorted. As we discussed in ISP use
		cases in Section 4, the design of [1] can be considered as a special
		case of the p4p-distance interface when a PID represents
		a single IP address and distances are only ranks. Some advantages
		that the p4p-distance style interface has over the IP sorting
		style include (1) better scalability through aggregation using PIDs;
		(2) better P2P client and P2P vendor privacy as no individual client
		information is sent to ISPs; and (3) flexibility, richer semantics, and
		precision of p-distances over the limited scope of only ranking preferences.
		We believe that scalability and flexibility are important for
		Internet architecture design.

	Viitatut artikkelit:
		[1] Can ISPs and P2P systems cooperate for improved performance?
		[2] Making intra-domain routing robust to changing and uncertain traffic demands: Understanding fundamental tradeoffs
		[4] Improving traffic locality in Bittorrent via biased neighbor selection
		[6] Cisco. Network-based application recognition (NBAR). https://www.cisco.com/univercd/cc/td/doc/product/software/ios122/122newft/122t/122t8/dtnbarad.html
		[7] F5 White Paper. Bandwidth management for peer-to-peer applications. http://www.f5.com/solutions/technology/rateshaping_wp.html
		[8] Measurement, modeling, and analysis of a peer-to-peer file-sharing workload
		[9] Joost. http://www.joost.org/whatsjoost.html (ei kunnon bittorret client, vaikutti aika härskiltä, ei hyödyllinen)
		[10] Walking the tightrope: Responsive yet stable traffic engineering
		[11] BLINC: Multilevel traffic classification in the dark
		[12] Should internet service providers fear peer-assisted content distribution?
		[13] Can ISPs take the heat from overlay networks?
		[14] Kontiki. http://www.kontiki.com. (Ei hyödyllinen)
		[15] TCP-LP: Low-priority service via end-point congestion control.
		[16] Are file swapping networks cacheable? characterizing P2P traffic.
		[17] iPlane: An information plane for distributed services
		[19] P-Cube. P-Cube. http://www.p-cube.net/indexold.shtml
		[20] Packeteer. Packeteer PacketShaper. http://www.packeteer.com/products/packetshaper
		[24] On Selfish routing in Internet-like environments
		[25] A system for authenticated policy-compliant routing
		[27] Modeling and caching of peer-to-peer traffic. Technical Report TR 2006-11
		[28] Sandvine. Intelligent broadband network management. http://www.sandvine.com
		[29] An analysis of internet content delivery systems
		[30] Characterizing and mitigating inter-domain policy violations in overlay routes
		[31] Accurate, scalable in-network identification of P2P traffic using application signatures
		[32] HPTP: Relieving the tension between ISPs and P2P
		[33] Statelog White Paper. Peer-to-peer and bandwidth management. http://www.staselog.com/whitepaper-p2p.pdf, Mar. 2004
		[34] TCP Nice: A mechanism for background transfers
		[36] Cache Replacement Policies Revisited: The Case of P2P Traffic 
		
	Viittaavat artikkelit
		Taming the torrent: a practical approach to reducing cross-isp traffic in peer-to-peer systems
		A survey on content-centric technologies for the current Internet: CDN and P2P solutions
		MultiCache: An overlay architecture forinformation-centric networking
		Pushing bittorrent locality to the limit
		Traffic localization for P2P-applications: The ALTO approach
		Pitfalls for ISP-friendly P2P design.
		TopBT: A topology-aware and infrastructure-independent BitTorrent client
		Deep diving into bittorrent locality
		Locality-awareness in BitTorrent-like P2P applications
		Cache-to-cache: Could ISPs cooperate to decrease peer-to-peer content distribution costs?
		ISP-friendly live P2P streaming
		
Taming the Torrent A Practical Approach to Reducing Cross-ISP Traffic in Peer-to-Peer Systems
	Peer-to-peer (P2P) systems use decentralization to enable a
	wide range of important, scalable and reliable services such as
	data sharing, voice-over-IP (VoIP) and video streaming. These
	systems are so prevalent that reports indicate they generate as much
	as 70% of Internet traffic worldwide [14].
	
	Current P2P implementations, however, are oblivious to the
	underlying Internet topology and ISP link costs. By making
	peering decisions independently of these factors, P2P systems
	have significantly increased ISPs’ operational costs, particularly
	in terms of cross-ISP traffic. This has driven service providers to
	the unfavorable solution of forcefully reducing a user’s P2P traffic
	at the expense of unhappy subscribers and the risk of government
	investigations [11].
	
	Recently, some ISPs have attempted to reduce P2P
	traffic by placing caches at the ISP’s gateway to the Internet or
	by using network appliances (e.g., Sandvine [28]) for spoofing
	TCP RST messages, which trick clients into closing connections
	to remote peers [28, 31].
		The legality of these approaches is
		questionable. By caching content, ISPs may become participants in
		illegal distribution of copyrighted material, while interfering with
		P2P flows in a non-transparent way may not only break the law
		but also lead to significant backlash [11].
		
	Two recent simulation-based studies have suggested an alternative
	solution in which ISPs and P2P users cooperate to reduce
	cross-ISP traffic. In particular, if a P2P client biases its connections
	to peers in the same ISP, the peer could receive near-optimal
	performance while significantly reducing the number of times the
	same data item enters the ISP [3, 8].
		Both studies discuss an
		approach that requires an oracle to provide knowledge about which
		peers are in the same ISP. Whereas Bindal et al. [8] do not focus on
		any particular oracle implementation, Aggarwal et al. [3] suggest
		that ISPs themselves could provide such a service and demonstrate
		through simulation that this is an effective solution. While the basic
		idea of an oracle to solve the P2P conundrum is appealing, tasking
		ISPs with the job requires P2P users and ISPs to cooperate and to
		trust each other, neither of which is likely to occur.
		
	We chose BitTorrent for its popularity, as it has been
	reported to account for over 66% of the P2P user population [14].

	Most P2P systems employ an arbitrary peer selection policy
	that ignores the underlying Internet topology and ISP link costs,
	establishing connections between randomly chosen subsets of cooperating
	peers from around the world. Such a policy results in
	P2P traffic that often crosses network boundaries multiple times to
	reach content that could have been more speedily obtained from
	nearby peers [2, 8, 17].
	
	Several proposals have suggested using AS
	numbers in peer selection (e.g., [18, 23]) to improve performance
	and reduce cross-network traffic, and this approach has even been
	adopted by several P2P applications (e.g., Neokast and Joost).
	
	The protocol [BitTorrent] has been well documented
	in the literature (e.g., in [13, 15, 25, 26]), thus our brief description
	focuses only on aspects relevant to this work.
	
	Aggarwal et al. [3] and Bindal et
	al. [8] have recently suggested the idea of ISP-supported oracles
	for biased-peer selection. Rather than recommending peers for
	performance improvement [1, 12, 20, 30], these oracles would bias
	peer selection toward nodes in the same ISP to reduce service
	providers’ costs without affecting peers’ performance.
		Similar
		in spirit to this work, the P4P [37] project attempts to address
		the problem through custom trackers, both for ISPs and P2P
		systems, using an interface based on a primal-dual decomposition
		of an optimization problem.
	
	Further, we expect that these peers
	will be mostly within the same ISP, thus avoiding cross-ISP traffic
	and optimizing clients’ performance by avoiding most network
	bottlenecks [7].

		
	Viitatut artikkelit:
		[1]: Optimal peer selection for P2P downloading and streaming
		[2]: Methodology for estimating network distances of Gnutella neighbors
		[3]: Can ISPs and P2P users cooperate for improvedperformance?
		[7]: An empirical evaluation of wide-area internet bottlenecks.
		[8]: Improving traffic locality in BitTorrent via biased neighbor selection
		[11]: FCC seeks comment in Comcast P2P investigation, January 2007. http://yro.slashdot.org/yro/08/01/16/0238244.shtml. (joku härsi bbs sivu, ei vissiin legitti lähde)
		[12]: The impact of DHT routing geometry on resilience and proximity
		[13]: Measurements, analysis, and modeling of BitTorrent-like systems
		[14]: IPOQUE. Internet Study 2007: Data about P2P, VoIP, Skype, file hosters like RapidShare and streaming services like YouTube, November 2007.
			https://web.archive.org/web/20071201162213/http://www.ipoque.com/media/internet_studies/internet_study_2007
			
		[15]: Dissecting BitTorrent: Five months in a torrent’s lifetime
		[17]: Should internet service providers fear peer-assisted content distribution?
		[18]: Exploiting autonomous system information in structured peer-to-peer networks
		[20]: iPlane: an information plane for distributed systems
		[23]: A routing underlay for overlay networks
		[25]: The Bittorrent P2P file-sharing system: Measurements and analysis
		[26]: Modeling and performance analysis of BitTorrent-like peer-to-peer networks.
		[28]: SANDVINE. Sandvine incorporated: Peer-to-peer policy management, 2008. http://www.sandvine.com/solutions/p2p_policy_mngmt.asp
		[30]: Locality prediction for oblivious clients
		[31]: HPTP: Relieving the tension between ISPs and P2P
		[37]: P4P: Provider portal for (P2P) applications
		
	Viittaavat artikkelit
		Pushing bittorrent locality to the limit
		Traffic localization for P2P-applications: The ALTO approach
		Pitfalls for ISP-friendly P2P design.
		Revisiting Cacheability in Times of User Generated Content
		TopBT: A topology-aware and infrastructure-independent BitTorrent client
		Deep diving into bittorrent locality
		Locality-awareness in BitTorrent-like P2P applications
		Cache-to-cache: Could ISPs cooperate to decrease peer-to-peer content distribution costs?
		Can p2p-users benefit from locality-awareness?
		Improvement of bittorrent performance and inter-domain traffic by inserting isp-owned peers
		Deep diving into bittorrent locality
		The impact of caching on BitTorrent-like peer-to-peer systems
		Traffic Localization for DHT-BasedBitTorrent Networks
		ISP-friendly peer matching without ISP collaboration
		Mitigating unfairness in locality‐aware peer‐to‐peer networks
		Cache Bandwidth Allocation for P2P File SharingSystems to Minimize Inter-ISP Traffic
		Caching for BitTorrent-like P2P Systems:A Simple Fluid Model and its Implications
	
Improving Traffic Locality in BitTorrent via Biased Neighbor Selection
	Mielenkiintoiset kohdat jossa viitattiin
		P2P content distribution applications such as BitTorrent
		[5] have fundamental advantages over the traditional
		client-server model (i.e. web sites) and the fixedinfrastructure
		content distribution networks (i.e. Akamai)
		as the supply of bandwidth grows linearly with the demand.
	
		BitTorrent is therefore
		wildly popular and a major constituent of traffic on the
		Internet [7, 2].
		
		An ISP typically pays a tier-1 “core” ISP for connectivity
		to the broad Internet, and traffic between the ISP and the
		outside world is costly for the ISP [18].
		
		ISPs often control BitTorrent traffic by “throttling”, or
		bandwidth limiting. Since BitTorrent traffic typically runs
		over a fixed range of ports (6881 to 6889) [6] and is easily
		decoded, traffic shaping devices such as [20, 13, 19, 23] are
		deployed to limit the amount of bandwidth consumed by the
		BitTorrent protocol. However, this mainly slows down the
		content transfer and worsens the user download experience,
		not addressing the fundamental concern of the ISP, which is
		to improve the locality (i.e. reduce the cross-ISP traffic) of
		those transfers.
		
		Many analytical and simulation studies [16, 1, 25, 22]
		have shown that the existing BitTorrent algorithm is nearly
		optimal in terms of user experienced download time.
		
		In addition to bandwidth limiting, two other obvious
		methods for reducing cross-ISP traffic are caches [2], and
		“gateway peers” (a gateway peer is the only node inside 
		an ISP that can connect to external peers) [15].
			A recent
			trace-driven study examined the cross-ISP traffic of the two
			approaches and found that they are comparable [15]. However,
			the study did not look into peer download performance
			
		Measurement studies of BitTorrent traffic on the Internet
		[8, 14, 12] show that a BitTorrent network typically goes
		through three stages in its life: flash crowd, steady state
		and winding down [14], and the peer join rate decreases
		exponentially with time [12].
		
		In recent years, the need
		of ISPs to control P2P traffic has given rise to a new
		category of devices that we call P2P shaping devices.
		Situated along side the edge routers of the ISPs, these
		devices use deep packet inspection to identify P2P traffic
		and manipulate them. Representative vendors include
		CacheLogic [2], Sandvine [23] and Cisco’s PCube
		appliances [19].
		
		The above discussions show that biased neighbor selection
		performs much better than bandwidth throttling, and
		the two techniques can be combined for best results. This
		section examines two other techniques to reduce cross-ISP
		traffic: using a single peer, called “gateway peer”, to connect
		to the external world [15], and using a cache to store
		blocks sent to the ISP [2].
			An ISP can designate a single node inside it as the gateway
			peer. All peers inside the ISP can only connect to each
			other and to the gateway peer, but only the gateway peer
			can connect to the external world. However, as results from
			Table 6 show, gateway peers need to have an upload bandwidth
			that is at least 4x that of normal nodes in the in ISP to
			avoid increasing download times. Moreover, since the gateway
			peer has nothing to gain from the internal peers, because
			of the tit-for-tat mechanism it would rather exchange
			blocks with external peers, benefitting peers in other ISP’s,
			causing them to finish faster (by as much as 20 % in one
			experiment). Finally, this approach is not scalable as the
			gateway requires 400KBps of upload bandwidth for each
			BitTorrent network that nodes from the ISP participate in.
			
		Another approach to eliminate traffic redundancy is to
		use caches. Positioned at the ISP’s gateway to the Internet,
		a cache stores blocks sent by external peers to internal
		peers, and when an internal peer wants to fetch a block from
		an external node, the cache intervenes transparently [2] and
		sends a locally-stored copy to the internal peer.
			Caches also need a high upload bandwidth to avoid increasing
			download times The estimated peak and average
			upload bandwidth needs of caches were obtained by summing
			up the bandwidth of flows crossing the ISP boundary
			that are “intervened” by the cache (see Table 7). Under
			regular BitTorrent, both the peak and average upload
			bandwidths of the cache are high. However, ISPs that deploy
			caches should instead use biased neighbor selection as
			the bandwidth needs of the cache are significantly reduced
			and furthermore, this can still be combined with bandwidth
			throttling.
			
	Viitatut artikkelit
		[1]: Understanding and deconstructing bittorrent performance (the existing BitTorrent algorithm is nearl optimal in terms of user experienced download time)
		[2]: CacheLogic. Cachelogic - advanced solutions for peer-topeer networks. http://www.cachelogic.com (ei enää toiminnassa) (cache-ratkaisu)
		[5]: Incentives build robustness in bittorrent (BitTorrentin tekijän paperi)
		[6]: Bittorrent documentation: Protocol, 2005. http://www.bittorrent.com/protocol.html.
		[8]: The bittorrent p2p file-sharing system: Measurements and analysis (p2p liikenteen määrä) (bittorrent elinkaari)
		[12]: Measuremsnts, analysis and modeling of bittorrent-like systems (bittorrent elinkaari)
		[13]: C. S. Incorporated. Network based application recognition (keino jolla ispt haittaavat p2ps)
		[14]: Dissecting bittorrent: Five months in a torrent’s lifetime (bittorrent elinkaari)
		[15]: Should internet service providers fear peer-assisted content distribution
		[16]: Coupon replication systems (the existing BitTorrent algorithm is nearl optimal in terms of user experienced download time)
		[18]: The bittorrent p2p file-sharing system: Measurements and analysis (white paper)
		[19]: P-Cube. P-cube: Ip service control. http://www.pcube.net/indexold.shtml. (keino jolla ispt haittaavat p2ps)
		[20]: Packeteer. Packetshaper. http://www.packeteer.com/prodsol/products/packetshaper.cfm.  (keino jolla ispt haittaavat p2ps)
		[22]: Modeling and performance analysis of bittorrent-like peer-to-peer networks ((the existing BitTorrent algorithm is nearl optimal in terms of user experienced download time))
		[23]: Sandvine. Sandvine: Intelligent broadband network management www.sandvine.com (keino jolla ispt haittaavat p2ps)
		[25]: Service capacity of peer to peer networks (the existing BitTorrent algorithm is nearl optimal in terms of user experienced download time)
		
	Viittaavat artikkelit
		P4P: Provider portal for applications
		Taming the torrent: a practical approach to reducing cross-isp traffic in peer-to-peer systems
		Can ISPs and P2P users cooperate for improved performance?
		Pushing bittorrent locality to the limit
		Traffic localization for P2P-applications: The ALTO approach
		Pitfalls for ISP-friendly P2P design.
		TopBT: A topology-aware and infrastructure-independent BitTorrent client
		Improving user and ISP experience through ISP-aided P2P locality
		Locality-awareness in BitTorrent-like P2P applications
		Cache-to-cache: Could ISPs cooperate to decrease peer-to-peer content distribution costs?
		A game–theoretic analysis of the implications of overlay network traffic on ISP peering
		Can p2p-users benefit from locality-awareness?
		Improvement of bittorrent performance and inter-domain traffic by inserting isp-owned peers
		Deep diving into bittorrent locality
		The impact of caching on BitTorrent-like peer-to-peer systems
		Traffic localization for DHT-based BitTorrent networks
		ISP-friendly peer selection in P2P networks
		Cache bandwidth allocation for P2P file-sharing systems to minimize inter-ISP traffic
		Caching for bittorrent-like P2P systems: A simple fluid model and its implications
		The disparity between P2P overlays and ISP underlays: issues, existing solutions, and challenges
		Cache capacity allocation for BitTorrent-like systems to minimize inter-ISP traffic
	
An adaptable and ISP-friendly multicast overlay network (2019 artsa)
	-Moreover, as their [P2P] implementation happens at
	the application level, their deployment does not depend
	on the ISP technological support. 
	
	Also in the subject of P2P overlay systems and their
	lack of knowledge of the physical network and associated
	routing strategies, an argument can be made as to the
	system’s inefficiency [22]. In fact, the overlay operates on a
	more abstract level, not considering peers placement in the
	network, which may lead data to traverse specific network
	links more than once or even generating excessive inter
	Autonomous System (AS) traffic, where most of the traffic
	bottlenecks are assumed to be in. 
		-Related with this topic,
		in 2008, the IETF created the IETF ALTO working group
		[23], tasked with optimizing the performance of P2P overlay
		systems. This allows, for instance, the ISP to provide the
		overlay system with the physical network topology, via a
		topology graph, enabling the overlay network to perform
		smart decisions. Similarly, this also allows the ISP to 
		better control the overlay traffic in accordance with specific
		traffic engineering policies. 
		-Additional research works also
		involving collaborative efforts between the P2P application
		level and ISPs can be also found in [24–26].
		
	Additional research works also
	involving collaborative efforts between the P2P application
	level and ISPs can be also found in [24–26].
		
	Viitatut artikkelit
		[22]: Can ISPs and P2P users cooperate for improved performance?
		[23]: ALTO Status Page, IETF Group, https://datatracker.ietf.org/wg/alto/charter/
		[24]: Sousa P (2015) Towards effective control of P2P traffic aggregates in network infrastructures. J Commun Soft Syst 11(1):37–47
		[25]: Sousa P (2013) A framework for highly reconfigurable P2P trackers. J Commun Soft Syst 9(4):236–246
		[26]: Sousa P (2013) Traffic engineering approaches in P2P environments. In: 5th international conference on advanced infocomm technology (ICAIT 2012), vol 7593. Springer, Paris, pp 61–74. LNCS
		
Traffic Management with Bloom-Filter Based Flow Classification
	-P2P networks have also demonstrated considerable potential
	to become a popular network tool for use not only in file
	sharing but also in video streaming [4] or to act as contents
	delivery networks (CDNs) [5] on the Internet
	
	-While there
	is a prediction that P2P traffic for file sharing applications
	will not increase in the future [6], it still represents today a
	significant fraction of the Internet traffic in Asia at present
	[7]
	
	-To remove the redundancy from P2P traffic, we have proposed
	a method to control P2P traffic through a packet-level
	data cache located on the router [ 1], [8]
	
	-The Bloom filter [ 12] has already had various applications
	in SDN [ 17], content-centric networks [ 18], P2P networks [ 19]
	and various network applications [20].
	
	Viitatut artikkelit
		[1]: A remedy for network operators against increasing P2P traffic: Enabling packet cache for P2P applications (edeltävä paperi)
		[4]: ISP-friendly live P2P streaming
		[5]: A first look at a commercial hybrid content delivery system
		[6]: Cisco Visual Networking Index: Forecast and methodology, 2013-2018 (White paper)
		[7]: Sandvine. (2015) Global Internet Phenomena Asia-Pacific & Europe. [Online]. Available: http://www.sandvine.com/trends/global-internet -phenomenal
		[8]: P2P packet cache router for networkwide traffic redundancy elimination (edeltävä paperi)
		[19]: Survey of research towards robust peer-topeer networks: search methods
		
A Novel Optimization Scheme for Caching in Locality-aware P2P Networks (tallennettu pdf ei toimi oikein)
	-However, the hugevolumes of traffic generated by various of P2P applications
	accounts for a large part of the overall Internet traffic and
	is expected to remain a significant source of traffic in thefuture [1].
	
	-Deploying P2P cache [2], [3], [4] is one of the most
	effective way to decrease costly inter-ISP traffic and improve
	users experience since contents in P2P systems are always
	immutable and requests are highly repetitive [5].
	
	-Traditionally, P2P caching algorithms are intended for
	locality-unaware P2P networks, which mainly consider the
	requested frequency of contents as the principle of replacement
	and allocation policies. However, as locality-awareness mech-anisms 
	are generally applied [6], [7], [8], the existing caching
	schemes can hardly optimize the situation.
	
	-In locality-awareconditions, requesting peers always prefer getting connection
	with nearby peers selected by neighbor-selection policies,
	which save the cost of P2P traffic. Nevertheless, if the re-quested 
	contents has not been widely distributed in local area
	yet or the peers possessing the requested contents are in
	poor bandwidths, biased neighbor selection will degrade the
	performance and the robustness of a P2P application [9], [10].
		-Therefore, what need to be cached in locality-aware conditions
		is the content that can not be well provided by local neighbors,
		rather than the content which is requested most frequently
	
	-But according to traditional caching schemes, even though some
	contents have already been widely distributed in local peers,
	they may still be cached due to their high request frequency.
	Apparently, caching these contents is not cost-efficient because
	utilizing plenty of nearby neighbors can get the similar results.
	What’s worse, current bandwidth management of P2P cache
	tends to allocate less bandwidth to swarms (all peers that
	distribute the same content called a swarm) with a high rate
	of local peers [9], [10], which means requesting peers have to
	choose cache with low bandwidth instead of local neighbors
	with high bandwidth. 
		-In this situation, traditional schemes ofP2P cache are causing new congestion
		
	-Moreover, the actual efficiency of a cache depends on
	two factors: storage and bandwidth, but most former studies
	consider these two crucial factors separately. They focus on
	either storage management of cache [5], [11], or bandwidth
	allocation of cache [9], [10] to reduce the inter-ISP traffic.
	However, if storage and bandwidth are allocated dispropor-tionally, 
	one of them will constrain the other, which may cause
	waste of cache resources.
	
	-We carry out series of simulations to
	evaluate the performance of the proposed algorithm 
	by con-trast with two representative caching algorithms: Proportional
	Partial Caching algorithm presented in [5] and Smallest-ratio
	Priority algorithm presented in [10]
	
	-Minimizing the negative impact of P2P traffic has drawn 
	significant attentions of networking researchers, which can be
	generally categorized into three classes: traffic limiting, traffic
	caching and traffic localizing
	
	-Traffic limiting mechanism
	imposes bandwidth constraints on P2P traffic once they are
	identified, which highly degrades the performance of P2P
	systems and hence stimulates customers to change their ISPs[12].
	
	-P2P cache has been researched in lots of studies. Storage
	management is the first aspect optimized by researchers.
	M. Hefeedaet al.[5] use a Zipf-Mandelbrot distribution to
	simulate the requested frequency of contents according to theirp
	opularity.
	
	-Based on popularity of contents, various caching
	replacement policies are provided [13], [5], [11]. The biggest
	difference between our work and all other former works is
	that we use not only popularity, but also locality information
	to guide behaviors of cache in locality-aware conditions.
	
	-Bandwidth is another important factor of cache. [14] and
	[15] consider bandwidth management of P2P video streaming
	systems to decrease the incoming traffic.
	
	-More related to ourwork are [9] and [10], in which authors propose series of
	schemes of bandwidth allocation in locality-aware conditions.
	They all conclude that more bandwidth should be allocated to
	the swarm which has less local peers.
	
	-According to previous studies, 86% of requested contents
	are downloaded from peers outside the local network even
	though they were locally available [16].
	
	-Traffic localizing
	attempts to guide peers to get connection with local neighbors.
	Traffic localizing can be organized as peer-driven and ISP-driven. 
	
	-Peer-driven solutions let peers detect unaware local
	information by themselves. TopBT [6] assesses distances be-
	tween peers based on hops of routers obtained from
	traceroute and pingtools. The weakness of peer-driven solutions is that
	they can not guarantee the accuracy, so ISP-driven is proposed
	to get the precise networks information
	
	-Oracle [7] presented
	by Deutsche Telekom Laboratories can collect various topol-
	ogy information of ISP networks, such as AS number, AS-level topology, 
	POP-level topology, even city-level topology
	and so on.
	
	-Although traffic localizing is expected to reach a
	win-win situation for both ISPs and users, 
	Lehriederet al.[17] point out that users experience can hardly get improved
	in realistic conditions. Skewed peer distributions and hetero-
	geneous access bandwidths of swarms have significant impact
	on effectiveness of traffic localizing. In this paper, we show
	that this drawback of locality-aware selection can be made up
	by cache.
	
	-In summary, traffic caching and traffic localizing are two
	main approaches to decrease the high cost of tremendous
	P2P traffic. In terms of caching, locality information is rarely
	considered. Two crucial factors of cache, storage and band-
	width, are always allocated separately. Traffic localizing can
	collect various of locality information to recommend optimal
	neighbors for requesting peers, but skewed peer distributions
	and heterogeneous access bandwidths will highly degrade
	users experience. These problems are also the motivation of
	our work.
	
	Viitatut artikkelit
		[1]: C. V. N. Index, “Forecast and methodology, 2014-2019 white paper,”Technical Report, Cisco, Tech. Rep., 2015.
		[2]: Peerapp ultraband,” http://www.peerapp.com/.
		[3]: Cachelogic,” http://www.cachelogic.com/
		[4]: Sandvine,” http://www.sandvine.com/.
		[5]: Traffic modeling and proportional partialcaching for peer-to-peer systems
		[6]: Topbt: a topology-aware and infrastructure-independent bittorrent client
		[7]: Can isps and p2p users cooperate for improved performance?
		[8]: P4p: Provider portal for applications
		[9]: Cache capacity allocation to overlay swarms
		[10]: Cache bandwidth allocationfor p2p file sharing systems to minimize inter-isp traffic
		[11]: Cache replacement policies for p2p file sharing protocols
		[12]: The local and global effects of traffic shaping in the internet
		[13]: Cache replacement policies revisited: The case of p2p traffic
		[14]: Cooperative caching and relaying strategies for peer-to-peer content delivery
		[15]: Interaction patterns between p2p content distribution systems and isps
		[16]: Measurement, modeling, and analysis of a peer-to-peer file-sharing workload
		[20]: On the efficiency of collaborative caching in isp-aware p2p networks


Network pricing: can both ISP and P2P benefit?
    Internet service providers offer users access to the Internet and related services. 
	There are roughly twotiers of ISPs according to the range of services provided:
	localISPs that provide services in smallregions to end-users and
	transitISPs that transfer data between local ISPs [1].

    In recent years,although  easily  accessible  streaming  media  such  as  Netflix  
	and  YouTube  have  led  to  a  downward
	trend in P2P file sharing of movie and music, P2P systems such as BitTorrent 
	still dominate upstream traffic with36:35% as of 2013 [5].

    Some recent findings show signs ofthe resurgence of P2P while moving P2P service to the cloud via the notion of a ‘seedbox’ [9].

    Because of theincreased load and changing traffic patterns resulting from the large amount of traffic generated [6],especially the upstream bandwidth requirements by P2P, ISPs have been under significant pressure ontheir maximum link capacity to domains outside of their local networks, that is, their bottleneck linkcapacity

    ISPs’ common actions to block or degrade certain applications (e.g. BitTorrent) [10,11] andattempts to differentiate traffic [12] are all signalling the bandwidth scarcity suffered by ISPs.

    This leaves the ISPs with few choices: they are either forced to expand capacities, to throttle certaintypes of traffic, or to change their business model (including the introduction of bandwidth caps andtiered-usage pricing). In recent years, ISPs have begun shifting towards usage-based pricing that offerscustomers a fixed amount of data each month for a fee. On average, less than 2% of users exceedthe  most  commonly  used  tier  of  300 GB;  nearly  80%  of  consumers  never  exceed  even  50 GB  permonth [15].

    There has been research about the rising tension between P2P and ISPs. Peer Coordination Protocol[27] was developed for ISP-compliant P2P systems, which puts a dynamic rate limit on P2P trafficbased on an ISPs’ constraint.
    
    Application-layer traffic optimization studies how to provide the righttype  of  network  layer  topology  information  to  the  requesting  peer  to  enable  P2P  data  structure  toimprove performance while reducing the utilization of the underlying network infrastructure [32,33].

    In [34], researchers conducted a simulation study to examine how localizing P2P traffic within networkboundaries impacts the profitability of ISPs. They found that the benefits of localization must not betaken for granted.

    Wanget al. [35] modelled the peering and routing tussle between ISPs and P2Papplications  and  analysed  the  economic  implications  of  overlay  traffic  on  ISPs’  peering  decisions.
    Viitatut artikkelit
        [1]: Economics of network pricing with multiple ISPs
        [5]: Sandvine. Global internet phenomena report, 2013. 2H.
        [6]: On the feasibility of commercial, legal P2P content distribution
        [9]: The  rise  and  fall  of  P2P.  DeepField  Networks,  2012. (blogi)
        [10]: EU telecoms regulators find ISP blocking of P2P and VoIP is common (uutinen)
        [11]: The Internet’s not a big truck: toward quantifying network neutrality.
        [12]: The economics of network neutrality
        [27]: Towards an ISP-compliant, peer-friendly design for peer-to-peer networks
        [32]: A survey of research on the application-layer traffic optimization problem and the need for layer cooperation
        [33]: Traffic localization for P2P-applications: the ALTO approach
        [34]: The Internet-wide impact of P2P traffic localization on ISP profitability.
        [35]: Modeling the peering and routing tussle between ISPs and P2P applications



The Performance and Locality Tradeoff inBitTorrent-like P2P File-Sharing Systems
    The large volumes of P2P traffic in today’s Internet have sig-
	nificantly changed the Internet traffic pattern and dramatically
	increased the traffic-relay cost at the ISPs. Such a cost threat
	has led to ISPs’ packet filtering and rate throttling towards
	P2Ptraffic [1], while on the other hand P2P application providers
	react  by  encrypting  data  and  communicating  with  dynamic
	ports to prevent from being recognized [2].

    There have recently
	emerged  hot  arguments  that  such  a  conflict  cannot  lead  to
	desirable outcomes for both parties. Instead, traffic localization
	designs  have  been  proposed  that  connect  peers  to  nearby
	(local) neighbors in terms of delay, routing hop count, etc.,by
	approaches  at  either  the  P2P  application  side  [3],  [4]  or  ISP
	side [5], or based on collaborations between both parties [6]

    While such local peer selection is effective in reducing P2P
	traffic across network boundaries, it may unfavorably degrade
	the downloading performance at peers in a BitTorrent-like 
	file-sharing system [7], as local peers may not necessarily be ones
	that  can  supply  large  upload  bandwidths.  In  another  word,  a
	non-negligible  tradeoff  may  exist  between  the  downloading
	performance and the traffic localization in the system.
	
	Viittaavat artikkelit:
		Can p2p-users benefit from locality-awareness?
		

    Viitatut artikkelit:
        [1]: ComcastisUsingSandvinetoManageP2PConnections,http://www.dslreports.com/forum/r18323368-Comcast-is-using-Sandvine-to-manage-P2P-Connections (uutisartsa)
        [2]: BitTorrentDevelopersIntroduceComcastBustingEncryption,http://torrentfreak.com/bittorrent-devs-introduce-comcast-busting-encryption-080215 (uutisartsa)
        [3]: Should content providers fear jne…
        [4]: Improving Traffic Locality in BitTorrent via Biased NeighborSelection
        [5]: Modeling  and  Caching  of  Peer-to-Peer Traffic
        [6]: P4P: Provider for Portal Applications
        [7]: PushingBitTorrent  Locality  to  the  Limit
		
Pushing BitTorrent locality to the limit
	Therefore, even if current P2P content replication
	solutions significantly reduce content provider costs, they
	cannot be promoted as a global solution for content replication
	as they induce huge costs for ISPs. In particular, the
	current trend for ISPs is to block P2P traffic [2].
	
	In
	particular, whereas all the torrents crawled generated
	11.6 petabytes of inter-ISP traffic, high locality
	could have saved up to 40%, i.e., 4.6 petabytes, of
	inter-ISP traffic. This result is significantly different
	from the inter-ISP bandwidth savings reported by
	Xie et al. [3]. Indeed, they reported a reduction of
	inter-ISP traffic with P4P around 60%, but for a single
	ISP with a single large torrent. Thus, they did not
	evaluate the reduction of BitTorrent traffic at the
	scale of the Internet, but for a single ISP.
	
	For instance, a tracker can
	use information offered by a dedicated infrastructure like
	the P4P infrastructure [3].

	In this section, we want to estimate the benefits our
	locality policy would have had on the torrents we crawled.
	In our crawl, 117,677 torrents and 6643 ASes cannot benefit
	from a locality policy, because there is at most one peer
	per AS per torrent. However, we want to show that despite
	most of the torrents and ASes cannot benefit from a locality
	policy, the implementation of a locality policy at the scale
	of the Internet would be highly beneficial.
	
	Moreover, the clustering observed by Legout et al. [12]
	appears only when there is high piece diversity. As soon
	as piece diversity becomes lower, there is no more clustering
	even if the efficiency of BitTorrent is preserved
		-This is
		this kind of phenomenon we observe with locality. Indeed,
		even if upload distribution is supposed to foster communications
		among peers with the same upload capacity, this is
		by no mean an absolute constraint because, as soon as
		piece diversity decreases, clusters among peers are broken
		and any peer can communicate with any other peer [12].
		
	P4P [3] is a project whose aim is to provide a lightweight
	infrastructure to allow cooperation between P2P
	applications and ISPs. Xie et al. presented small scalel
	experiments (with between 53 and 160 PlanetLab nodes)
	on two specific scenarios. They also reported on a field test
	experiment around 60% of inter-ISP traffic savings with
	P4P for a single ISP and a single large torrent.
	
	Aggarwal et al. [20] present an architecture that is similar
	by some aspects to P4P. The authors define the notion
	of oracle that are supplied by ISPs in order to propose a list
	of neighbors to peers. They perform their evaluation on
	Gnutella using simulations and small scale experiments
	with 45 Gnutella nodes.
	
	Another approach that requires no dedicated infrastructure
	is Ono [4]. Ono clusters users based on the assumption
	that clients redirected to a same CDN server are close. The
	authors have developed an Ono plugin for the Vuze client.
	The authors reported measurement results collected from
	120,000 users of the Ono plugin over a 10 month period.
	They reported up to 207% performance increase in average
	peer download completion time. However, the authors did
	not give an explicit inter-ISP traffic reduction, but showed
	a reduction of the path length between peers in terms of IP
	and AS hops.
	
	Bindal et al. [21] present the impact of a deterministic
	locality policy on ISPs’ peering links load and on end-users
	experience. The authors considered simulations on a scenario
	with 14 ISPs with 50 peers each, thus a torrent of
	700 peers.
	
	Lin et al. [22] introduce ELP that aims to keep traffic local
	to ISPs. They provide a model that gives bounds on the
	inter-ISP traffic, and they validate ELP experimentally on
	PlanetLab with a maximum of 60 peers.
	
	In contrast to previous works like P4P [3] and Ono [4]
	that provide very valuable results focusing on in the wild
	measurements or deployments, our work fills a gap by providing
	a systematic and rigorous evaluation of BitTorrent
	by doing controlled experiments. Indeed, our work significantly
	differs from those previous ones, by being the first
	one to extensively evaluate the impact of key parameters
	like the number of inter-ISP connections, the torrent size,
	the distribution of peers per ISP, the inter-ISP bottlenecks,
	the churn rate, and the peers upload capacity using large
	scale experiments and real world data. In particular, we
	considered 214,443 real torrents spread across 9605 ASes
	(it was a single large torrent and a single AS for the P4P
	field test [3]) and showed that using only four inter-ISP
	connections (it was 20% of inter-ISP connections for the
	P4P field tests) we could reduce the inter-ISP traffic at
	the scale of the Internet by up to 40%.
	
	Piatek et al. [23] discuss pitfalls for an ISP-friendly
	locality policy and ISPs traffic engineering constraints. In
	particular, Piatek et al. discuss three main issues: client
	side only localization might not work, localization might
	adversely impact robustness and efficiency, ISPs have conflicting
	interests. The two first issues do not apply to our
	work as we consider a tracker based locality policy, and
	as we have designed and evaluated the partition merging
	strategy to prevent robustness issues. Concerning the last
	issue on ISPs conflicting interests, it is beyond the scope of
	this study to evaluate the economical benefit for tier-1
	ISPs to keep traffic local. Our work shows that if ISPs want
	to apply a locality policy to BitTorrent traffic, it is doable
	and it will significantly reduce the traffic on inter-ISP
	links.
	
	Cuevas et al. [24] is by several aspects close to our work.
	Indeed, the authors also collected a large BitTorrent trace
	and explored the impact of high locality. However, their
	work significantly differs by other aspects. The core of their
	evaluation study is a mathematical model, whereas we
	performed extensive large scale experiments. They specifically
	focused on peers upload distribution, whereas we
	focused on the systematic evaluation of fundamental
	parameters like torrent size, or inter-ISP bottlenecks. Finally,
	they do not explore the second question of this work
	What is, at the scale of the Internet, the reduction of traffic
	that can be achieved with locality? In summary, our work
	is complementary to the one of Cuevas et al., as it validates
	some of the assumptions they made in the modeling of Bit-
	Torrent locality, in particular the good piece diversity with
	locality, which is fundamental to observe stratification in
	their model.
	
	Our work is intended to be complimentary to previous
	works [1,3,4,23] by answering the two fundamental questions:
	(1) How far can we push BitTorrent locality? (2)
	What is at the scale of the Internet the reduction of inter-
	ISP traffic that can be achieved with locality?
	
	Viitatut artikkelit
		[1]: Should internet service providers fear peer-assisted content distribution?
		[2]: Detecting BitTorrent blocking
		[3]: P4p: provider portal for applications
		[4]: Taming the torrent: a practical approach to reducing cross-isp traffic in p2p systems
		[10]: Incentives to build robustness in Bittorrent
		[12]: Clustering and sharing incentives in BitTorrent systems
		[13]: Pushing BitTorrent Locality to the Limit, Technical Report inria-00343822, version 1, 2 December, 2008, INRIA Sophia Antipolis, France, 2008
		[14]: Rarest first and choke algorithms are enough
		[19]: Dissecting BitTorrent: five months in a torrent’s lifetime
		[20]: Can ISPs and p2p users cooperate for improved performance?
		[21]: Improving traffic locality in BitTorrent via biased neighbor selection
		[22]: An ISP-friendly file distribution protocol: analysis, design and implementation
		[23]: Pitfalls for ISP-friendly p2p design
		[24]: Deep diving into BitTorrent locality
		
A Survey of Research on the Application-Layer Traffic Optimization Problem and the Need for Layer Cooperation
	Most distributed hash tables (DHTs) — the
	data structure that imposes a specific ordering for
	P2P overlays — use greedy forwarding algorithms
	to reach their destination, making locally optimal
	decisions that may not turn to be globally optimized
	[1].
	
	One way to solve the ALTO problem is to
	build distributed application-layer services for
	location and path selection [2–7] in order to
	enable peers to estimate their position in the
	network and efficiently select their neighbors.
		Similar solutions have been embedded into P2P
		applications such as Azureus.1
		
	A slightly different
	approach is to have the Internet service
	provider (ISP) take a proactive role in the routing
	of P2P application traffic; the means by
	which this can be achieved have been proposed
	[8–10].
	
	There is an intrinsic struggle between
	the layers — P2P overlay and network underlay
	— when performing the same service (routing);
	however, there are strategies to mitigate this
	dichotomy [11].
	
	Francis et al. proposed IDMaps [2], a system
	where one or more special hosts called tracers are
	deployed near an autonomous system
	
	To aid in scalability beyond that provided
	by the client-server design of IDMaps, Ng et
	al. proposed a P2P-based global network positioning
	(GNP) architecture [3].
		GNP was a network
		coordinate system based on absolute coordinates
		computed from modeling the Internet as a geometric
		space.
		
	Both IDMaps and GNP require fixed network
	network
	infrastructure support in the form of tracers
	or landmark hosts; this often introduces a
	single point of failure and inhibits scalability. To
	combat this, new techniques were developed that
	embedded the network topology in a low-dimensional
	coordinate space to enable network distance
	estimation through vector analysis. Costa
	et al. introduced Practical Internet Coordinates
	(PIC) [5]. While PIC uses the notion of landmark
	hosts, it does not require explicit network
	support to designate specific landmark hosts.
	
	Like PIC, Vivaldi [4] proposed a fully distributed
	network coordinate system without any
	distinguished hosts.
			
	Vivaldi is now used
	in the popular P2P application Azureus, and
	studies indicate that it scales well to very large
	networks [12].
	
	Network coordinate systems require the embedding
	of the Internet topology into a coordinate system.
	This is not always possible without errors,
	which impacts the accuracy of distance estimations.
	In particular, it has proven to be difficult to embed
	the triangular inequalities found in Internet path
	distances [12]. Thus, Meridian [6] abandons the
	generality of network coordinate systems and provides
	specific distance evaluation services.
	
	The Ono project [13] takes a different
	approach and uses network measurements from
	a content distribution network (CDN) like Akamai
	to find nearby peers. Used as a plug-in to
	the Azureus BitTorrent client, Ono provides 31
	percent average download rate improvement.
	
	One system providing such a service is iPlane
	[7], which aims at creating an annotated atlas of
	the Internet that contains information about
	latency, bandwidth, capacity, and loss rate.
	
	The architecture proposed
	by Xie et al. [8] has been adopted by the DCIA
	P4P Working Group ,2 an open group established
	by ISPs, P2P software distributors, and technology
	researchers with the dual goal of defining mechanisms
	to accelerate content distribution and optimize
	utilization of network resources.
	
	The P4P architecture is under evaluation
	through simulations and experiments on the PlanetLab
	distributed testbed, and field tests with real
	users. Initial simulations and PlanetLab experimental
	results indicate that improvements in Bit-
	Torrent download completion time and link
	utilization in the range of 50–70 percent are possible.
	Results observed in field tests conducted
	with a modified version of the software used by
	the Pando content delivery network show
	improvements in download rate of 23 percent and
	a significant drop in data delivery average hop
	count (from 5.5 to 0.89) in certain scenarios [8].
	
	ISP-Driven Informed Path Selection (IDIPS) Service
	— The solution proposed by Saucez et al. [10] is
	essentially a modified version of the oracle-based
	approach described above, and is intended to provide
	a network-layer service for finding best source
	and destination addresses when establishing a connection
	between two endpoints in multihomed environments
	(which are common in IPv6 networking).
	
	Some features of the network topology are
	hard to infer through application-level techniques,
	and it may not be possible to infer them at all.
	Examples of such features are service provider
	policies and preferences such as the state and cost
	associated with interdomain peering and transit
	links. Another example is the traffic engineering
	policy of a service provider, which may counteract
	the routing objective of the overlay network, leading
	to poor overall performance [11].
	
	Undoubtedly, it is hard to foresee
	how proposed systems will perform in the Internet.
	Simulations and testbed emulations are in most
	cases the only options available for benchmarking
	the performance of a system. However, these have
	often proven inadequate; in at least one particular
	case [12], they have only provided rough optimistic
	approximations of what would be measured in the
	real world.
	
	-Viitatut artikkelit
		[1]: The Impact of DHT Routing Geometry on Resilience and Proximity
		[2]: A Global Internet Host Distance Estimation Service (IPmaps)
		[3]: Predicting Internet Network Distance with Coordinates-Based Approaches
		[4]: Vivaldi: A Decentralized Network Coordinate System
		[5]: PIC: Practical Internet Coordinates for Distance Estimation
		[6]: Meridian: A Lightweight Network Location Service Without Virtual Coordinates
		[7]: iPlane: An Information Plane for Distributed Services
		[8]: P4P: Provider Portal for Applications
		[9]: Can ISPs and P2P Systems Co-Operate for Improved Performance?
		[10]: Implementation and Preliminary Evaluation of an ISP-Driven Informed Path Selection
		[11]: Preemptive Strategies to Improve Routing Performance of Native and Overlay Layers
		[12]: Network Coordinates in the Wild
		[13]: Taming the Torrent: A Practical Approach to Reducing Cross-ISP Traffic in P2P Systems
		
Traffic Localization for P2P-Applications: The ALTO Approach
	For instance, peers can measure
	message delay to other peers themselves or exploit existing
	content distribution networks to infer network layer topology
	distance [1].
	
	One promising approach for P2P traffic localization is
	to have ISPs or third parties convey information regarding
	the underlying network topology to P2P-clients through a
	special service. To this end, the EU FP7 project Napa-Wine
	[2] is investigating solutions for providing network layer
	information to peers through such a dedicated service.
	
	In
	addition, the IETF has recently formed a working group
	for Application-Layer Traffic Optimization (ALTO) [3].
		This
		working group has the intention of developing Internet standards
		which will help P2P-clients choose better neighbors
		in terms of mapping the overlay topology to the underlying
		IP network.
		
	Specifically, the main goal of the ALTO WG
	is to design a query-response protocol for an ALTO service
	which P2P-applications can query for information to achieve
	better-than-random neighbor peer selection [3] [4] [5].
	
	One of the first works to consider locality information
	provided by the ISP in order to improve P2P-traffic has
	been [6]. 
		This work studies regular BitTorrent and shows
		that it is very inefficient from an ISP’s perspective, i.e.,
		regular BitTorrent is locality-unaware. To circumvent this,
		the authors briefly sketch a solution where ISPs intercept
		P2P-traffic at edge routers and redirect them to P2P-clients
		within the same ISP. However, they do not investigate such
		a solution in detail.
		
	A more concrete proposal to improve P2P-locality through
	network layer topology information has been proposed in
	[7]. The overall idea is simple: Instead of random peer
	selection, peers are supposed to select all but k peers from
	their ISP. For instance, if peers have a connectivity degree d
	(i.e., they are connected to d peers on the overlay layer), d−k
	neighbours for each peer are supposed to be located within
	the same ISP while k links exist to peers in different ISPs for
	each peer.
		This is called biased neighbour selection. In [7] the authors
		envision two ways to implement biased neighbour selection:
		Either by using a modified tracker or by modifying traffic
		shaping devices which intercept P2P traffic at edge routers
		of each ISP. Both solutions assume a way (for trackers or
		traffic shaping devises) to access information regarding ISP
		locality.
		
	A similar approach has been presented in [8]. This approach
	is more general and in principle enables neighbour
	selection on other criteria than network locality. The authors
	propose to have an oracle to be operated by each ISP, which
	the P2P-clients in the ISP’s network can query to obtain
	information about the underlying network. The overall idea
	is that instead of choosing their neighbours randomly, P2P
	clients can use the ISP oracle in order to choose neighbours
	with care and insight. More specifically, the oracle ranks a
	list of potential neighbours based on the ISP’s preferences.
	Such a list can be obtained by the P2P-client through
	regular P2P operations and then sent to the oracle for
	guidance on which peers to prefer. The authors evaluate
	this sorting oracle approach through simulation as well as
	actual implementation. Their results demonstrate that this
	approach can increase locality of P2P-traffic with respect to
	AS diameter, while not increasing the average hop count or
	node degree.
	
	A decentralized alternative for conveying network layer
	information to P2P-clients is proposed in [1]. This approach
	re-uses information provided by content delivery networks
	(CDNs) to guide peer selection for P2P-applications. This
	idea is based on the fact that CDNs try to minimise download
	latency. To achieve this, clients are directed to CDN replica
	servers via dynamic DNS. It is reasonable to assume that
	if two clients are sent to the same CDN replica server they
	are likely to be located close to each other on the network
	topology. As a metric to express network layer locality
	between peers based on CDN redirection, using the cosine
	similarity of the replication server ratio maps between two
	peers is proposed [1].
	
	More recently, [9] investigated what extent of locality
	is beneficial to P2P-applications in general. Clearly, some
	degree of inter-ISP links needs to be preserved in order
	to guarantee robustness and prevent network partitioning
	in the case of node failure. The authors define locality as
	the percentage of intra-ISP connections over all connections
	with respect to the average peer. Their study concludes that
	compared to the regular BitTorrent protocol up to two orders
	of magnitude can be saved on inter-ISP traffic if locality is
	used. Further, they show in a test environment with modified
	BitTorrent implementations that the capacity of the initial
	content-seed has strong implications on the potential benefit
	of employing locality-biased neighbor selection.
	
	The P4P [10] research project has developed a framework
	which ISPs can use to convey network information to P2P
	applications [10] [11]. The framework of the P4P project
	is based on two main architectural entities: the itracker
	and the p-distance. P4P envisions each network provider
	to operate a so-called itracker. This itracker serves as the
	portal to be used by P2P applications within this network
	provider’s network to acquire network layer information.
	Such an itracker can either communicate with the P2P-client
	directly or indirectly via a P2P-application tracker. At the
	heart of the P4P framework lies the notion of the p-distance.
	An itracker can be queried by P2P applications about
	the p-distance between peers. This p-distance is computed
	by the network provider (e.g., based on routing policies,
	topology information, inter-ISP cost agreements, etc.). For
	instance, an ISP could compute p-distances in such a way
	that connections with higher financial costs for the ISP
	result in a higher p-distance.
	
	The P4P framework has been
	evaluated through simulation and PlanetLab experiments
	[11]. In addition, several ISPs have conducted field tests
	[12]. All these studies provide strong indication that the P4P
	architecture is suitable for improving download speeds for
	P2P users while decreasing inter-ISP traffic caused by P2Papplications.
	
	In summary, research indicates that improved peer selection
	algorithms based on information provided by an
	ISP, such as network layer topology or maximum available
	access bandwidth at a peer, can indeed help in reducing
	costs for ISPs as well as increase overall download rates
	for P2P applications1.
		1A good survey on related work can also be found in [13].
		
	[1]: Taming the Torrent: A practical approach to reducing cross-isp traffic in peer-topeer systems
	[2]: EU FP7 Project NAPA-WINE, http://www.napa-wine.eu.
	[3]: J. Peterson, V. Gurbani, E. Marocco et al., “ALTO Working Group Charter,” http://www.ietf.org/html.charters/alto-charter.html.
	[4]: J. Seedorf and E. Burger, “Application-Layer Traffic Optimization (ALTO) Problem Statement,” Internet Engineering Task Force, Internet-Draft draft-ietf-alto-problem-statement- 01, May 2009, work in Progress. [Online]. Available: http://tools.ietf.org/html/draft-ietf-alto-problem-statement
	[5]: S. Kiesel, L. Popkin, S. Previdi, R. Woundy, and Y. R. Yang, “Application-Layer Traffic Optimization (ALTO) Requirements,” Internet Engineering Task Force, Internet-Draft draft-ietf-alto-reqs-00, Apr. 2009, work in Progress. [Online].  Available: http://tools.ietf.org/html/draft-ietf-alto-reqs
	[6]: Should Internet Service Providers Fear Peer-Assisted Content Distribution?
	[7]: Improving Traffic Locality in BitTorrent via Biased Neighbor Selection
	[8]: Can ISPs and P2P Systems Co-operate for Improved Performance?
	[9]: Pushing BitTorrent Locality to the Limit
	[10]: R. Alimi, D. Pasko, L. Popkin, Y. Wang, and Y. Yang, “P4P: Provider Portal for P2P Application,” Internet Engineering Task Force, Internet-Draft draft-p4p-framework-00, Nov. 2008, work in Progress. [Online]. Available: http://www-net.cs.yale.edu/projects/p4p/draft-p4p-framework.txt
	[11]: P4P: Provider Portal for Applications
	[12]: C. Griffiths, J. Livingood, and R. Woundy, “Comcast’s ISP Experiences In a Recent P4P Technical Trial,”Internet Engineering Task Force, Internet-Draft draftlivingood-woundy-p4p-experiences-07, May 2009, workin Progress. [Online]. Available: http://tools.ietf.org/html/draft-livingood-woundy-p4p-experiences
	[13]: A Survey on Research on the Application-Layer Traffic Optimization (ALTO) Problem
		-Sama papru kun tätä paprua ylläoleva papru tässä tiedostossa
		¨
Peer-to-Peer Systems
	Viitatut Artikkelit
		[10] Incentives build robustness in BitTorrent
		[14] Detecting BitTorrent blocking
		[20] Should Internet service providers fear peer-assisted content distribution?
		
Rarest First and Choke Algorithms Are Enough
	Viitatut artikkelit
		[2] http://www.bittorrent.com/.
		[3] Bittorrent protocol specification v1.0. http://wiki.theory.org/BitTorrentSpecification, June 2005.
		[4] Understanding availability
		[5] Analysing and improving bittorrent performance
		[6] Performance analysis of peer-to-peer networks for file distribution
		[7] Making gnutella-like p2p systems scalable
		[8] Incentives build robustness in bittorrent
		[13] Measurements, analysis, and modeling of bittorrent-like systems. 
		[14] Dissecting bittorrent: Five months in a torrent’s lifetime
		[15] Incentives in bittorrent induce freeriding
		[16] Is p2p dying or just hiding?
		[17] Transport layer identification of p2p traffic
		[19] Rarest first and choke algorithms are enough. Technical Report
		[20] The true picture of peer-to-peer filesharing. http://www.cachelogic.com/, July 2004.
		[21] The bittorrent p2p file-sharing system: Measurements and analysis.
		[22] Modeling and performance analysis of bittorrent-like peer-to-peer networks
		
Pushing the Performance of Biased Neighbor Selection through Biased Unchoking
	ithBNS,thepeerstryto adjusttheirsetofneighborssothatit containsatleasta certainfractionoflocalpeers.However, sinceonlythecompositionoftheneighborsetisinuencedbythisstrategy,  thereisnohardpreferenceforlocalpeersinthedataexchangeprocess.
	
	Viitatut artikkelit
		[1] "Bittorrent". http://www.bittorrent.com/
		[2] B.Cohen, "Bittorrentprotocolspecification" , February 2005.
		[4] Pushing BitTorrent Locality to the Limit
		[5] Improving traffic locality in bittorrent via biased neighbor selection
		[6] Can ISPs and P2P systems cooperate for improved performance?
		[7] P4P: Provider portal for applications
		[8] A New Approach for Managing Traffic of Overlay Applications of the SmoothIT Project
		[9] "Application-layer traffic optimization (alto)." http://www.ietf.org/html.charters/alto-charter.html.
		[10] Taming the torrent: a practical approach to reducing cross-ISP traffic in Peer-to-Peer systems
		[11] "Comcast throttles bittorrent traffic, seeding impossible." http://torrentfreak.com/comcast-throttles-bittorrent-traffic-seeding-impossible/, 2007.
		[12] Should internet service providers fear peer-assisted content distribution?
		[13] Modeling and caching of peer-to-peer traffic
		[14] Rarest first and choke algorithms are enough
		[15] "Bittorrent specification." http://wiki.theory.org/BitTorrentSpecification. 